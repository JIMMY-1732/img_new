# LECTURE DESIGN PHILOSOPHY

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PEDAGOGICAL APPROACH                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  ARCHITECTURE BEFORE CODE                                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                       â”‚
â”‚  Students must see the DISTRIBUTED SYSTEM before writing a      â”‚
â”‚  single line of Celery code. Three processes, not one.          â”‚
â”‚                                                                 â”‚
â”‚  THE FACTORY FLOOR ANALOGY                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚
â”‚  Every Celery concept maps to a factory that receives orders,   â”‚
â”‚  builds products, and reports completion. Tangible.             â”‚
â”‚                                                                 â”‚
â”‚  THE SYNC SURPRISE                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                              â”‚
â”‚  After 10 weeks of async/await, students will instinctively     â”‚
â”‚  write "async def" for tasks. Celery tasks are SYNC.            â”‚
â”‚  We confront this head-on and explain WHY.                      â”‚
â”‚                                                                 â”‚
â”‚  CONNECT TO PRIOR KNOWLEDGE                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚
â”‚  Redis (Week 10) â†’ Celery uses it as the message broker         â”‚
â”‚  Decorators (Week 1) â†’ @app.task is another decorator           â”‚
â”‚  Retry patterns (Week 8) â†’ Same concept, new mechanism          â”‚
â”‚  Idempotent APIs (Week 4) â†’ Same principle, higher stakes       â”‚
â”‚  BackgroundTasks (Lecture 1) â†’ The problem Celery solves        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# LECTURE OUTLINE

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CELERY FUNDAMENTALS                          â”‚
â”‚                     (3-4 Hour Lecture)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  PART 1: THE DEATH TEST (25 min)                                â”‚
â”‚  â”œâ”€ 1.1 Killing Your Server Mid-Task (Demonstration)            â”‚
â”‚  â”œâ”€ 1.2 What We Actually Need                                   â”‚
â”‚  â””â”€ 1.3 Enter Celery: Work That Survives                        â”‚
â”‚                                                                 â”‚
â”‚  PART 2: THE FACTORY FLOOR (35 min)                             â”‚
â”‚  â”œâ”€ 2.1 The Factory Analogy                                     â”‚
â”‚  â”œâ”€ 2.2 Three Components: Client, Broker, Worker                â”‚
â”‚  â”œâ”€ 2.3 Message Flow (How an Order Becomes a Product)           â”‚
â”‚  â”œâ”€ 2.4 Redis as Broker (Your Week 10 Knowledge Pays Off)       â”‚
â”‚  â””â”€ 2.5 The Sync Surprise                                       â”‚
â”‚                                                                 â”‚
â”‚  PART 3: YOUR FIRST CELERY TASK (55 min)                        â”‚
â”‚  â”œâ”€ 3.1 Creating the Celery App                                 â”‚
â”‚  â”œâ”€ 3.2 Project Structure (Two Processes, One Codebase)         â”‚
â”‚  â”œâ”€ 3.3 Defining Tasks with @app.task                           â”‚
â”‚  â”œâ”€ 3.4 Running the Worker                                      â”‚
â”‚  â”œâ”€ 3.5 Calling Tasks: .delay() and .apply_async()              â”‚
â”‚  â””â”€ 3.6 Serialization: Tasks Are Messages, Not Function Calls   â”‚
â”‚                                                                 â”‚
â”‚  PART 4: TRACKING WORK â€” RESULTS & STATES (25 min)             â”‚
â”‚  â”œâ”€ 4.1 AsyncResult â€” Your Tracking Number                      â”‚
â”‚  â”œâ”€ 4.2 The Task State Machine                                  â”‚
â”‚  â”œâ”€ 4.3 Checking Status from FastAPI                            â”‚
â”‚  â””â”€ 4.4 When You Don't Need Results                             â”‚
â”‚                                                                 â”‚
â”‚  PART 5: WHEN THINGS GO WRONG â€” RETRIES (45 min)               â”‚
â”‚  â”œâ”€ 5.1 What Happens When a Task Fails?                         â”‚
â”‚  â”œâ”€ 5.2 bind=True â€” Giving the Task Self-Awareness              â”‚
â”‚  â”œâ”€ 5.3 Manual Retry with self.retry()                          â”‚
â”‚  â”œâ”€ 5.4 Declarative Retry with autoretry_for                    â”‚
â”‚  â”œâ”€ 5.5 Exponential Backoff (Week 8 Callback)                   â”‚
â”‚  â””â”€ 5.6 After Max Retries: Accepting Failure                    â”‚
â”‚                                                                 â”‚
â”‚  PART 6: THE NON-NEGOTIABLE â€” IDEMPOTENCY (30 min)             â”‚
â”‚  â”œâ”€ 6.1 At-Least-Once Delivery (The Uncomfortable Truth)        â”‚
â”‚  â”œâ”€ 6.2 How Duplicates Happen                                   â”‚
â”‚  â”œâ”€ 6.3 Making Tasks Idempotent (Patterns)                      â”‚
â”‚  â””â”€ 6.4 Database-Backed Idempotency Keys                        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# PART 1: THE DEATH TEST

## 1.1 Killing Your Server Mid-Task

**Last lecture, you learned WHY background processing matters and saw BackgroundTasks. Now watch what happens when the real world intervenes.**

```python
# demo_fragile.py â€” A FastAPI server with BackgroundTasks
from fastapi import FastAPI, BackgroundTasks
import time
import uvicorn

app = FastAPI()

emails_sent: list[str] = []

def send_email_slowly(to: str, subject: str) -> None:
    """Simulate sending an email (takes 3 seconds)"""
    print(f"ğŸ“§ Sending email to {to}...")
    time.sleep(3)  # Simulate SMTP connection + send
    emails_sent.append(to)
    print(f"âœ… Email sent to {to}! (Total sent: {len(emails_sent)})")

@app.post("/notify-all")
async def notify_all_users(background_tasks: BackgroundTasks):
    users = [
        "alice@example.com",
        "bob@example.com",
        "charlie@example.com",
        "diana@example.com",
        "eve@example.com",
    ]
    for user in users:
        background_tasks.add_task(send_email_slowly, user, "Important Update")
    
    return {"message": f"Queued {len(users)} emails", "status": "accepted"}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

**Run it. Hit the endpoint. Then kill the server after 5 seconds.**

```
Terminal 1:                          Terminal 2:
$ python demo_fragile.py             $ curl -X POST localhost:8000/notify-all
                                     {"message":"Queued 5 emails","status":"accepted"}

ğŸ“§ Sending email to alice@example.com...
âœ… Email sent to alice@example.com! (Total sent: 1)
ğŸ“§ Sending email to bob@example.com...

  *** You press Ctrl+C here ***

^C  Shutting down...
```

**Now ask the class:**

> "Five emails were queued. Alice got hers. Bob's was in progress. Charlie, Diana, Eve â€” never started. How many actually sent? You don't know for certain. Bob's might be half-sent. And here's the real question: **when you restart the server, do those 3 unsent emails come back?**"

Answer: **No. They're gone. Forever.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  THE DEATH TEST RESULT                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  BEFORE CRASH:                                                  â”‚
â”‚  â”œâ”€ alice@example.com    âœ… Sent                                â”‚
â”‚  â”œâ”€ bob@example.com      âš ï¸  In progress (corrupted?)           â”‚
â”‚  â”œâ”€ charlie@example.com  âŒ Never started                       â”‚
â”‚  â”œâ”€ diana@example.com    âŒ Never started                       â”‚
â”‚  â””â”€ eve@example.com      âŒ Never started                       â”‚
â”‚                                                                 â”‚
â”‚  AFTER RESTART:                                                 â”‚
â”‚  â”œâ”€ emails_sent = []     â† Memory wiped                        â”‚
â”‚  â”œâ”€ No record of what was queued                                â”‚
â”‚  â”œâ”€ No record of what succeeded                                 â”‚
â”‚  â””â”€ No way to resume                                            â”‚
â”‚                                                                 â”‚
â”‚  BackgroundTasks live in YOUR PROCESS MEMORY.                   â”‚
â”‚  When the process dies, the tasks die with it.                  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1.2 What We Actually Need

**BackgroundTasks has three fatal limitations for work that matters:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                THREE FATAL LIMITATIONS                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. NO PERSISTENCE                                              â”‚
â”‚     Tasks live in RAM. Process dies â†’ tasks vanish.             â”‚
â”‚     You can't restart and resume.                               â”‚
â”‚                                                                 â”‚
â”‚  2. NO DISTRIBUTION                                             â”‚
â”‚     All tasks run in the SAME process as your web server.       â”‚
â”‚     100 emails to send? Your API slows down for everyone.       â”‚
â”‚     Can't spread work across multiple machines.                 â”‚
â”‚                                                                 â”‚
â”‚  3. NO VISIBILITY                                               â”‚
â”‚     Is the task running? Failed? Stuck? No way to know.         â”‚
â”‚     No retry. No monitoring. No status checking.                â”‚
â”‚                                                                 â”‚
â”‚  BackgroundTasks is fine for: "log this request" (fire-forget)  â”‚
â”‚  BackgroundTasks BREAKS for: "send this invoice" (must happen)  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1.3 Enter Celery: Work That Survives

**Celery is a distributed task queue. The key word is DISTRIBUTED â€” the work doesn't live in your web server.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚    BackgroundTasks                    Celery                     â”‚
â”‚    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”‚
â”‚                                                                 â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚    â”‚   FastAPI        â”‚               â”‚ FastAPI  â”‚               â”‚
â”‚    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚               â”‚ (sends   â”‚               â”‚
â”‚    â”‚   â”‚ Backgroundâ”‚ â”‚               â”‚  message)â”‚               â”‚
â”‚    â”‚   â”‚ Tasks     â”‚ â”‚               â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜               â”‚
â”‚    â”‚   â”‚ (in RAM)  â”‚ â”‚                    â”‚                      â”‚
â”‚    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                    â–¼                      â”‚
â”‚    â”‚   Process dies â†’ â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚    â”‚   Tasks die      â”‚               â”‚  Redis   â”‚ â† persisted  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚  (broker)â”‚   on disk     â”‚
â”‚                                       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜              â”‚
â”‚    One process.                            â”‚                    â”‚
â”‚    One machine.                            â–¼                    â”‚
â”‚    No persistence.                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚    No visibility.                     â”‚  Celery  â”‚              â”‚
â”‚                                       â”‚  Worker  â”‚ â† separate  â”‚
â”‚                                       â”‚ (does    â”‚   process    â”‚
â”‚                                       â”‚  work)   â”‚              â”‚
â”‚                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                                 â”‚
â”‚                                       Separate process.         â”‚
â”‚                                       Can be separate machine.  â”‚
â”‚                                       Tasks survive crashes.    â”‚
â”‚                                       Full visibility.          â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> "Celery separates the REQUEST for work from the EXECUTION of work. Your web server says 'do this,' writes it down in a durable place, and walks away. A completely different process picks it up and does it. If either process crashes, the work order still exists."

---

# PART 2: THE FACTORY FLOOR

## 2.1 The Factory Analogy

**This analogy will carry us through the entire lecture.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   THE FACTORY FLOOR                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Imagine a factory that builds custom furniture.                â”‚
â”‚                                                                 â”‚
â”‚  THE SALES OFFICE (FastAPI)                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚  Customers walk in and place orders.                            â”‚
â”‚  The sales office does NOT build furniture.                     â”‚
â”‚  They write an ORDER FORM and put it in the factory's inbox.    â”‚
â”‚  Then they immediately help the next customer.                  â”‚
â”‚                                                                 â”‚
â”‚  THE INBOX CONVEYOR BELT (Redis Broker)                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”‚
â”‚  A conveyor belt carries order forms to the factory floor.      â”‚
â”‚  Orders sit in the queue until a worker picks one up.           â”‚
â”‚  If the sales office closes for the night, orders stay          â”‚
â”‚  on the belt â€” they don't disappear.                            â”‚
â”‚                                                                 â”‚
â”‚  THE FACTORY WORKERS (Celery Workers)                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”‚
â”‚  Workers stand at the belt, grab the next order form,           â”‚
â”‚  and build the product. One worker, one order at a time.        â”‚
â”‚  When finished, they put the product on the "completed" shelf   â”‚
â”‚  and grab the next order.                                       â”‚
â”‚                                                                 â”‚
â”‚  THE COMPLETED SHELF (Redis Result Backend)                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                     â”‚
â”‚  Finished products sit on a shelf with their order number.      â”‚
â”‚  The sales office can check: "Is order #472 done yet?"          â”‚
â”‚                                                                 â”‚
â”‚  THE ORDER NUMBER (task_id / AsyncResult)                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”‚
â”‚  Every order gets a unique tracking number.                     â”‚
â”‚  Check status anytime: pending, in progress, done, failed.     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Map the analogy to Celery:**

```
Factory                 â”‚  Celery
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Sales office            â”‚  FastAPI (your web server)
Customer order          â”‚  Task call (send_email.delay(...))
Order form              â”‚  Serialized message (JSON in Redis)
Inbox conveyor belt     â”‚  Redis broker queue
Factory worker          â”‚  Celery worker process
Building the product    â”‚  Executing the task function
Order tracking number   â”‚  task_id (UUID)
Completed shelf         â”‚  Redis result backend
Checking order status   â”‚  AsyncResult.status
Defective â†’ redo        â”‚  Task retry
Worker calls in sick    â”‚  Worker process crashes (others continue)
```

---

## 2.2 Three Components: Client, Broker, Worker

**Every Celery system has exactly three components:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               THE THREE COMPONENTS                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚   CLIENT    â”‚      â”‚   BROKER    â”‚      â”‚   WORKER    â”‚    â”‚
â”‚   â”‚  (FastAPI)  â”‚â”€â”€â”€â”€â”€â–¶â”‚   (Redis)   â”‚â”€â”€â”€â”€â”€â–¶â”‚  (Celery)   â”‚    â”‚
â”‚   â”‚             â”‚      â”‚             â”‚      â”‚             â”‚    â”‚
â”‚   â”‚ "Do this    â”‚      â”‚ "I'll hold  â”‚      â”‚ "I'll do    â”‚    â”‚
â”‚   â”‚  task"      â”‚      â”‚  the order" â”‚      â”‚  the work"  â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                     â”‚           â”‚
â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚           â”‚
â”‚                         â”‚   RESULT    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                         â”‚  BACKEND    â”‚                         â”‚
â”‚                         â”‚   (Redis)   â”‚  "Here's the result"   â”‚
â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                                                                 â”‚
â”‚   PROCESS 1             SERVICE              PROCESS 2          â”‚
â”‚   (your API)           (already running)     (separate!)        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Each component is INDEPENDENT:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              INDEPENDENCE MATTERS                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  FastAPI crashes?                                               â”‚
â”‚  â””â”€ Workers keep processing. Queued tasks are safe in Redis.    â”‚
â”‚                                                                 â”‚
â”‚  A worker crashes?                                              â”‚
â”‚  â””â”€ The task it was running goes back to the queue.             â”‚
â”‚     Other workers (or the restarted one) pick it up.            â”‚
â”‚                                                                 â”‚
â”‚  Redis restarts?                                                â”‚
â”‚  â””â”€ Problem â€” but Redis persists to disk (AOF/RDB),            â”‚
â”‚     so queued tasks can survive. (You configured this Week 10.) â”‚
â”‚                                                                 â”‚
â”‚  Each piece can crash, restart, or scale INDEPENDENTLY.         â”‚
â”‚  That's the power of distributed systems.                       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2.3 Message Flow (How an Order Becomes a Product)

**Follow one task through the entire lifecycle:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LIFECYCLE OF A SINGLE TASK                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Step 1: CLIENT SENDS MESSAGE                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â”‚
â”‚                                                                 â”‚
â”‚  Your FastAPI code:                                             â”‚
â”‚      send_email.delay("alice@test.com", "Welcome!")             â”‚
â”‚                                                                 â”‚
â”‚  What actually happens:                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ {                                        â”‚                   â”‚
â”‚  â”‚   "id": "a1b2c3d4-...",                  â”‚                   â”‚
â”‚  â”‚   "task": "tasks.send_email",            â”‚ â† JSON message   â”‚
â”‚  â”‚   "args": ["alice@test.com", "Welcome!"],â”‚   pushed to      â”‚
â”‚  â”‚   "kwargs": {},                          â”‚   Redis queue     â”‚
â”‚  â”‚   "retries": 0                           â”‚                   â”‚
â”‚  â”‚ }                                        â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚         â”‚                                                       â”‚
â”‚         â–¼                                                       â”‚
â”‚  Step 2: BROKER HOLDS THE MESSAGE                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                               â”‚
â”‚                                                                 â”‚
â”‚  Redis receives the JSON and stores it in a list (queue).       â”‚
â”‚  The message sits there until a worker picks it up.             â”‚
â”‚  (This is LPUSH/BRPOP â€” Redis lists you know from Week 10.)    â”‚
â”‚         â”‚                                                       â”‚
â”‚         â–¼                                                       â”‚
â”‚  Step 3: WORKER PICKS UP THE MESSAGE                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                           â”‚
â”‚                                                                 â”‚
â”‚  A Celery worker process is listening on the queue.             â”‚
â”‚  It pops the message, reads: "task = tasks.send_email"          â”‚
â”‚  It IMPORTS the function, passes in the arguments, and runs it. â”‚
â”‚         â”‚                                                       â”‚
â”‚         â–¼                                                       â”‚
â”‚  Step 4: WORKER EXECUTES THE FUNCTION                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”‚
â”‚                                                                 â”‚
â”‚  The worker calls: send_email("alice@test.com", "Welcome!")     â”‚
â”‚  This is a normal, synchronous Python function call.            â”‚
â”‚  The worker is BLOCKED while it runs (and that's fine).         â”‚
â”‚         â”‚                                                       â”‚
â”‚         â–¼                                                       â”‚
â”‚  Step 5: RESULT STORED IN BACKEND                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                              â”‚
â”‚                                                                 â”‚
â”‚  When the function returns, the result (or exception) is        â”‚
â”‚  serialized to JSON and stored in Redis (result backend).       â”‚
â”‚  The client can check this anytime using the task_id.           â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2.4 Redis as Broker (Your Week 10 Knowledge Pays Off)

**You already know Redis. Celery just uses it differently.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             REDIS: TWO ROLES IN CELERY                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  ROLE 1: MESSAGE BROKER (redis://localhost:6379/0)              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”‚
â”‚  Uses Redis LISTS as queues.                                    â”‚
â”‚  Producer (FastAPI) does LPUSH â†’ pushes task to list.           â”‚
â”‚  Consumer (Worker) does BRPOP â†’ blocks until task available.    â”‚
â”‚                                                                 â”‚
â”‚  You know these data types from Week 10.                        â”‚
â”‚  Celery just automates the push/pop pattern.                    â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  ROLE 2: RESULT BACKEND (redis://localhost:6379/1)              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”‚
â”‚  Uses Redis STRINGS with TTL.                                   â”‚
â”‚  Key: "celery-task-meta-{task_id}"                              â”‚
â”‚  Value: JSON with status + result                               â”‚
â”‚  TTL: auto-expires (no stale results eating memory)             â”‚
â”‚                                                                 â”‚
â”‚  You've done this exact pattern â€” cache with TTL â€” in Week 10.  â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  WHY TWO DIFFERENT DATABASES? (db 0 vs db 1)                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”‚
â”‚  Separation of concerns. Broker data is transient (consumed     â”‚
â”‚  and deleted). Result data is read-back (queried by client).    â”‚
â”‚  Different access patterns, different databases.                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2.5 The Sync Surprise

**This will feel wrong after 10 weeks of async. It's not.**

```python
# âŒ What you EXPECT to write (after 10 weeks of async):
@app.task
async def send_email(to: str, subject: str) -> dict:
    await smtp_client.send(to, subject)
    return {"status": "sent"}

# âœ… What you ACTUALLY write in Celery:
@app.task
def send_email(to: str, subject: str) -> dict:
    smtp_client.send(to, subject)  # Regular sync call
    return {"status": "sent"}
```

**"Wait â€” we've been writing async for months. Why is this sync?"**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   THE SYNC SURPRISE                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Remember the Async lecture in Week 1?                          â”‚
â”‚                                                                 â”‚
â”‚  ASYNC (Event Loop):                                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                             â”‚
â”‚  ONE process handles MANY tasks by switching between them.      â”‚
â”‚  When Task A waits for I/O, Task B runs. Cooperative.           â”‚
â”‚                                                                 â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚     â”‚  FastAPI Process                   â”‚                      â”‚
â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚                      â”‚
â”‚     â”‚  â”‚      Event Loop             â”‚   â”‚                      â”‚
â”‚     â”‚  â”‚  Req A â”€â”€â”   â”Œâ”€â”€ Req C     â”‚   â”‚                      â”‚
â”‚     â”‚  â”‚  Req B â”€â”€â”¤   â”œâ”€â”€ Req D     â”‚   â”‚                      â”‚
â”‚     â”‚  â”‚  (juggling all at once)     â”‚   â”‚                      â”‚
â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚                      â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚     One waiter serving many tables.                             â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  CELERY (Worker Pool):                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚
â”‚  MANY processes each handle ONE task. True parallelism.         â”‚
â”‚  Each worker is DEDICATED to its current task.                  â”‚
â”‚                                                                 â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚     â”‚  Celery Worker Pool                          â”‚            â”‚
â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚            â”‚
â”‚     â”‚  â”‚ Worker 1   â”‚ â”‚ Worker 2   â”‚ â”‚ Worker 3   â”‚â”‚            â”‚
â”‚     â”‚  â”‚ (email     â”‚ â”‚ (report    â”‚ â”‚ (idle,     â”‚â”‚            â”‚
â”‚     â”‚  â”‚  task)     â”‚ â”‚  task)     â”‚ â”‚  waiting)  â”‚â”‚            â”‚
â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚            â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚     Multiple workers, each building one product.                â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  WHY SYNC MAKES SENSE FOR WORKERS:                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                             â”‚
â”‚  A factory worker doesn't need to juggle. They pick up ONE      â”‚
â”‚  order, build it start to finish, then pick up the next.        â”‚
â”‚  You scale by hiring MORE workers, not by making one worker     â”‚
â”‚  juggle. That's the Celery model.                               â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The decision framework you already know from Week 1:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  CONCURRENCY MODEL           â”‚  WHERE IT'S USED                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€               â”‚
â”‚  async/await (event loop)    â”‚  FastAPI â€” handle many requests  â”‚
â”‚  multiprocessing (prefork)   â”‚  Celery â€” execute many tasks     â”‚
â”‚                                                                 â”‚
â”‚  Same goal (do more work), different mechanism.                 â”‚
â”‚  FastAPI juggles. Celery hires more hands.                      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> "Think back to Week 1: concurrency (one worker switching between tasks) vs parallelism (multiple workers, truly simultaneous). FastAPI is concurrency. Celery is parallelism. You need both â€” FastAPI to handle thousands of incoming requests, Celery to grind through thousands of background jobs."

---

# PART 3: YOUR FIRST CELERY TASK

## 3.1 Creating the Celery App

**The Celery app is the equivalent of `FastAPI()` â€” the central object everything attaches to.**

```python
# celery_app.py
from celery import Celery

celery = Celery(
    "worker",                                  # Name of the worker module
    broker="redis://localhost:6379/0",         # Where to SEND messages
    backend="redis://localhost:6379/1",        # Where to STORE results
)

# Configuration â€” sensible defaults for production
celery.conf.update(
    task_serializer="json",          # Serialize task arguments as JSON
    accept_content=["json"],         # Only accept JSON (security)
    result_serializer="json",        # Serialize results as JSON
    timezone="UTC",                  # All timestamps in UTC
    enable_utc=True,                 # Enforce UTC
    task_track_started=True,         # Report when a task starts running
    task_acks_late=True,             # Acknowledge AFTER completion (crash safety)
    worker_prefetch_multiplier=1,    # Don't grab extra tasks (fair distribution)
)
```

**What each configuration does:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CONFIGURATION EXPLAINED                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  task_serializer = "json"                                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚
â”‚  Task arguments get converted to JSON before going to Redis.    â”‚
â”‚  This means: only JSON-serializable data can be passed.         â”‚
â”‚  (strings, numbers, lists, dicts â€” NOT objects, NOT models)     â”‚
â”‚                                                                 â”‚
â”‚  task_acks_late = True          â† CRITICAL FOR CRASH SAFETY     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                         â”‚
â”‚  Default behavior: worker acknowledges (removes from queue)     â”‚
â”‚  the task BEFORE running it. If it crashes mid-task â†’ lost.     â”‚
â”‚                                                                 â”‚
â”‚  With acks_late: worker acknowledges AFTER completing.          â”‚
â”‚  If it crashes mid-task â†’ task goes back to the queue.          â”‚
â”‚                                                                 â”‚
â”‚  This is why we said "work that survives." The order form       â”‚
â”‚  stays on the conveyor belt until the product is FINISHED.      â”‚
â”‚                                                                 â”‚
â”‚  task_track_started = True                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚  Adds a STARTED state to the lifecycle.                         â”‚
â”‚  Without it: PENDING â†’ SUCCESS. You can't tell "waiting"        â”‚
â”‚  from "running." With it: PENDING â†’ STARTED â†’ SUCCESS.          â”‚
â”‚                                                                 â”‚
â”‚  worker_prefetch_multiplier = 1                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚
â”‚  Each worker grabs only 1 task at a time from the queue.        â”‚
â”‚  Prevents one greedy worker from hoarding all the orders.       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3.2 Project Structure (Two Processes, One Codebase)

**This is the mental shift: your project now runs as TWO separate processes.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PROJECT STRUCTURE                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  project/                                                       â”‚
â”‚  â”œâ”€â”€ app/                                                       â”‚
â”‚  â”‚   â”œâ”€â”€ main.py              â† FastAPI app (Process 1)         â”‚
â”‚  â”‚   â”œâ”€â”€ routers/                                               â”‚
â”‚  â”‚   â”‚   â”œâ”€â”€ users.py                                           â”‚
â”‚  â”‚   â”‚   â””â”€â”€ reports.py                                         â”‚
â”‚  â”‚   â”œâ”€â”€ services/                                              â”‚
â”‚  â”‚   â”‚   â””â”€â”€ user_service.py                                    â”‚
â”‚  â”‚   â””â”€â”€ schemas/                                               â”‚
â”‚  â”‚       â””â”€â”€ user.py                                            â”‚
â”‚  â”œâ”€â”€ worker/                                                    â”‚
â”‚  â”‚   â”œâ”€â”€ celery_app.py        â† Celery instance                 â”‚
â”‚  â”‚   â””â”€â”€ tasks/                                                 â”‚
â”‚  â”‚       â”œâ”€â”€ __init__.py                                        â”‚
â”‚  â”‚       â”œâ”€â”€ email_tasks.py   â† Task definitions                â”‚
â”‚  â”‚       â””â”€â”€ report_tasks.py  â† Task definitions                â”‚
â”‚  â”œâ”€â”€ docker-compose.yml       â† Runs everything together        â”‚
â”‚  â””â”€â”€ requirements.txt                                           â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Two terminals, two processes:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  Terminal 1 (FastAPI):                                          â”‚
â”‚  $ uvicorn app.main:app --reload                                â”‚
â”‚                                                                 â”‚
â”‚  Terminal 2 (Celery Worker):                                    â”‚
â”‚  $ celery -A worker.celery_app worker --loglevel=info           â”‚
â”‚                                                                 â”‚
â”‚  (Redis is already running â€” you've had it since Week 10.)      â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  They share the SAME CODEBASE but run as SEPARATE processes.    â”‚
â”‚  They communicate ONLY through Redis.                           â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ Terminal 1â”‚    â”‚  Redis   â”‚    â”‚ Terminal 2â”‚                  â”‚
â”‚  â”‚ FastAPI   â”‚â”€â”€â”€â–¶â”‚ (broker) â”‚â”€â”€â”€â–¶â”‚ Celery   â”‚                  â”‚
â”‚  â”‚ :8000     â”‚    â”‚ :6379    â”‚    â”‚ Worker   â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3.3 Defining Tasks with @app.task

**A task is a regular Python function with a decorator. You've used decorators since Week 1.**

```python
# worker/tasks/email_tasks.py
import smtplib
from email.message import EmailMessage
from worker.celery_app import celery

@celery.task
def send_welcome_email(user_email: str, username: str) -> dict:
    """Send a welcome email to a newly registered user.
    
    This is a regular sync function. NOT async.
    The worker runs it in its own process.
    """
    msg = EmailMessage()
    msg["Subject"] = f"Welcome, {username}!"
    msg["From"] = "noreply@ourapp.com"
    msg["To"] = user_email
    msg.set_content(f"Hello {username}, welcome to our platform!")

    # This is a blocking call â€” and that's perfectly fine.
    # This worker process has nothing else to do right now.
    with smtplib.SMTP("smtp.mailserver.com", 587) as server:
        server.starttls()
        server.login("noreply@ourapp.com", "password")
        server.send_message(msg)

    return {"status": "sent", "to": user_email}
```

**What `@celery.task` actually does:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             WHAT THE DECORATOR DOES                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  You learned in Week 1 that decorators wrap functions.          â”‚
â”‚  @celery.task wraps your function with task-sending machinery.  â”‚
â”‚                                                                 â”‚
â”‚  BEFORE decorator:                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                              â”‚
â”‚  send_welcome_email is just a function.                         â”‚
â”‚  You can only call it directly: send_welcome_email("a@b.com")  â”‚
â”‚                                                                 â”‚
â”‚  AFTER decorator:                                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                               â”‚
â”‚  send_welcome_email is now a Task object with extra methods:    â”‚
â”‚                                                                 â”‚
â”‚  send_welcome_email("a@b.com", "alice")                         â”‚
â”‚  â””â”€ Still works! Runs the function directly (useful for tests)  â”‚
â”‚                                                                 â”‚
â”‚  send_welcome_email.delay("a@b.com", "alice")                   â”‚
â”‚  â””â”€ NEW! Sends a message to Redis. Returns immediately.         â”‚
â”‚                                                                 â”‚
â”‚  send_welcome_email.apply_async(args=["a@b.com", "alice"])      â”‚
â”‚  â””â”€ NEW! Same as delay but with more options.                   â”‚
â”‚                                                                 â”‚
â”‚  send_welcome_email.name                                        â”‚
â”‚  â””â”€ "worker.tasks.email_tasks.send_welcome_email"               â”‚
â”‚     (The full import path â€” this is how the worker finds it.)   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Another task example â€” a heavy report:**

```python
# worker/tasks/report_tasks.py
import csv
import io
from datetime import datetime
from worker.celery_app import celery

@celery.task
def generate_monthly_report(org_id: int, month: int, year: int) -> dict:
    """Generate a CSV report for an organization.
    
    This might take 30 seconds â€” way too long for an API response.
    Perfect candidate for a background task.
    """
    # Connect to DB (sync driver â€” NOT async SQLAlchemy)
    # Workers have their OWN database connections.
    from sqlalchemy import create_engine, text
    engine = create_engine("postgresql://user:pass@localhost/mydb")
    
    with engine.connect() as conn:
        rows = conn.execute(
            text("""
                SELECT task_name, status, completed_at 
                FROM tasks 
                WHERE org_id = :org_id 
                  AND EXTRACT(MONTH FROM created_at) = :month
                  AND EXTRACT(YEAR FROM created_at) = :year
            """),
            {"org_id": org_id, "month": month, "year": year}
        ).fetchall()
    
    # Build CSV in memory
    output = io.StringIO()
    writer = csv.writer(output)
    writer.writerow(["Task", "Status", "Completed At"])
    for row in rows:
        writer.writerow(row)
    
    csv_content = output.getvalue()
    
    # In reality: upload to S3, save path to DB, etc.
    # For now, return metadata
    return {
        "status": "completed",
        "org_id": org_id,
        "period": f"{year}-{month:02d}",
        "row_count": len(rows),
        "generated_at": datetime.utcnow().isoformat(),
    }
```

> "Notice: we're using a **sync** database driver (`create_engine`, not `create_async_engine`). The worker is its own process â€” it doesn't share FastAPI's async engine or session. It creates its own connections. This is a completely separate world."

---

## 3.4 Running the Worker

**Start the worker and watch it come alive:**

```bash
$ celery -A worker.celery_app worker --loglevel=info
```

**What you'll see:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   WORKER STARTUP                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  -------------- celery@your-machine v5.4.0 (opalescent)        â”‚
â”‚  --- ***** -----                                                â”‚
â”‚  -- ******* ---- Linux-5.15.0-x86_64-with-glib2.35             â”‚
â”‚  - *** --- * ---                                                â”‚
â”‚  - ** ---------- [config]                                       â”‚
â”‚  - ** ---------- .> app:         worker:0x7f4a...               â”‚
â”‚  - ** ---------- .> transport:   redis://localhost:6379/0  â† â‘   â”‚
â”‚  - ** ---------- .> results:     redis://localhost:6379/1  â† â‘¡  â”‚
â”‚  - *** --- * --- .> concurrency: 4 (prefork)              â† â‘¢  â”‚
â”‚  -- ******* ---- .> task events: OFF                            â”‚
â”‚  --- ***** -----                                                â”‚
â”‚   -------------- [queues]                                       â”‚
â”‚                  .> celery  exchange=celery(direct) key=celery   â”‚
â”‚                                                                 â”‚
â”‚  [tasks]                                                        â”‚
â”‚    . worker.tasks.email_tasks.send_welcome_email          â† â‘£   â”‚
â”‚    . worker.tasks.report_tasks.generate_monthly_report          â”‚
â”‚                                                                 â”‚
â”‚  [... INFO/MainProcess] Connected to redis://localhost:6379/0   â”‚
â”‚  [... INFO/MainProcess] celery@your-machine ready.        â† â‘¤  â”‚
â”‚                                                                 â”‚
â”‚  â‘  Broker: where it listens for new tasks                       â”‚
â”‚  â‘¡ Backend: where it stores results                             â”‚
â”‚  â‘¢ Concurrency: 4 worker processes (one per CPU core)           â”‚
â”‚  â‘£ Registered tasks: the functions this worker knows about      â”‚
â”‚  â‘¤ Ready: now waiting for messages on the queue                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**If your task doesn't appear in [tasks], the worker can't run it:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  COMMON ISSUE: Task not registered                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                              â”‚
â”‚                                                                 â”‚
â”‚  If you don't see your task in the [tasks] list:                â”‚
â”‚                                                                 â”‚
â”‚  1. Check imports â€” Celery must discover your task modules      â”‚
â”‚                                                                 â”‚
â”‚  # In celery_app.py, tell Celery where to find tasks:           â”‚
â”‚  celery.autodiscover_tasks(["worker.tasks"])                    â”‚
â”‚                                                                 â”‚
â”‚  2. Or import tasks explicitly:                                 â”‚
â”‚  import worker.tasks.email_tasks    # Force import              â”‚
â”‚  import worker.tasks.report_tasks                               â”‚
â”‚                                                                 â”‚
â”‚  The worker can only run functions it has IMPORTED.              â”‚
â”‚  No import â†’ not in [tasks] list â†’ task will be UNREGISTERED.   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Updated celery_app.py with autodiscovery:**

```python
# worker/celery_app.py
from celery import Celery

celery = Celery(
    "worker",
    broker="redis://localhost:6379/0",
    backend="redis://localhost:6379/1",
)

celery.conf.update(
    task_serializer="json",
    accept_content=["json"],
    result_serializer="json",
    timezone="UTC",
    enable_utc=True,
    task_track_started=True,
    task_acks_late=True,
    worker_prefetch_multiplier=1,
)

# Automatically find all @celery.task decorated functions
# in the listed packages
celery.autodiscover_tasks(["worker.tasks"])
```

---

## 3.5 Calling Tasks: .delay() and .apply_async()

**Two ways to send work to the factory. Both put an order on the conveyor belt.**

### .delay() â€” The Simple Way

```python
# app/routers/users.py
from fastapi import APIRouter, Depends
from worker.tasks.email_tasks import send_welcome_email

router = APIRouter()

@router.post("/users/", status_code=201)
async def create_user(user_data: UserCreate, db: AsyncSession = Depends(get_db)):
    # 1. Create user in database (fast, < 50ms)
    new_user = await user_service.create_user(db, user_data)
    
    # 2. Send welcome email in background (slow, 2-5 seconds)
    #    .delay() sends the message and returns IMMEDIATELY
    task_result = send_welcome_email.delay(new_user.email, new_user.username)
    
    # 3. Return response to the client NOW â€” don't wait for email
    return {
        "id": new_user.id,
        "email": new_user.email,
        "email_task_id": task_result.id,  # Client can check status later
    }
```

**What happens at `.delay()`:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            WHAT .delay() DOES                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  send_welcome_email.delay("alice@test.com", "alice")            â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚  1. Serializes arguments to JSON:                               â”‚
â”‚     {"args": ["alice@test.com", "alice"], "kwargs": {}}         â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚  2. Generates a unique task_id:                                 â”‚
â”‚     "f47ac10b-58cc-4372-a567-0e02b2c3d479"                      â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚  3. Pushes message to Redis queue:                              â”‚
â”‚     LPUSH "celery" <full message JSON>                          â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚  4. Returns immediately with an AsyncResult object:             â”‚
â”‚     AsyncResult(id="f47ac10b-...")                               â”‚
â”‚                                                                 â”‚
â”‚  TIME SPENT: ~1-5 milliseconds (just a Redis write)             â”‚
â”‚  The email hasn't been sent yet. A worker will do that later.   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### .apply_async() â€” The Powerful Way

```python
# .delay(arg1, arg2) is shorthand for:
# .apply_async(args=[arg1, arg2])

# But apply_async gives you control:

# 1. Delay execution by 60 seconds (send email in 1 minute)
send_welcome_email.apply_async(
    args=["alice@test.com", "alice"],
    countdown=60,
)

# 2. Schedule for a specific time
from datetime import datetime, timedelta

send_welcome_email.apply_async(
    args=["alice@test.com", "alice"],
    eta=datetime.utcnow() + timedelta(hours=1),
)

# 3. Set a hard expiration (don't run if too old)
send_welcome_email.apply_async(
    args=["alice@test.com", "alice"],
    expires=300,  # Expire after 5 minutes
)

# 4. Route to a specific queue
send_welcome_email.apply_async(
    args=["alice@test.com", "alice"],
    queue="high_priority",
)

# 5. Custom task_id (useful for idempotency â€” more in Part 6)
send_welcome_email.apply_async(
    args=["alice@test.com", "alice"],
    task_id=f"welcome-email-{user_id}",
)
```

**When to use which:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  .delay()                â”‚  .apply_async()                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€                â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”‚
â”‚  Simple. Just run it.    â”‚  Need control over WHEN/WHERE/HOW.   â”‚
â”‚                          â”‚                                      â”‚
â”‚  send_email.delay(       â”‚  send_email.apply_async(             â”‚
â”‚      "a@b.com", "hi"    â”‚      args=["a@b.com", "hi"],         â”‚
â”‚  )                       â”‚      countdown=60,                   â”‚
â”‚                          â”‚      queue="emails",                 â”‚
â”‚                          â”‚      expires=600,                    â”‚
â”‚                          â”‚  )                                   â”‚
â”‚                          â”‚                                      â”‚
â”‚  Use for: fire and       â”‚  Use for: delayed, scheduled,        â”‚
â”‚  forget, run ASAP.       â”‚  prioritized, or expiring tasks.     â”‚
â”‚                          â”‚                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3.6 Serialization: Tasks Are Messages, Not Function Calls

**This is the most common source of bugs for beginners. Understand it now.**

When you call `.delay()`, you are NOT calling the function. You are putting a **message in a queue**. That message is **JSON**. The worker in a completely different process reads that JSON, imports the function, and calls it with the deserialized arguments.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         TASKS ARE MESSAGES, NOT CALLS                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  What you THINK happens:                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚
â”‚  FastAPI calls send_email("alice@test.com", "alice")            â”‚
â”‚  in another thread or something.                                â”‚
â”‚                                                                 â”‚
â”‚  What ACTUALLY happens:                                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚  FastAPI writes JSON â†’ Redis â†’ Worker reads JSON â†’ Worker       â”‚
â”‚  imports function â†’ Worker calls function with parsed args.     â”‚
â”‚                                                                 â”‚
â”‚  The arguments travel as JSON through Redis.                    â”‚
â”‚  EVERYTHING must survive JSON serialization.                    â”‚
â”‚                                                                 â”‚
â”‚  âœ… CAN pass as arguments:                                      â”‚
â”‚  â”œâ”€ str, int, float, bool, None                                 â”‚
â”‚  â”œâ”€ list, dict (with JSON-safe contents)                        â”‚
â”‚  â”œâ”€ Nested combinations of the above                            â”‚
â”‚  â””â”€ Anything json.dumps() can handle                            â”‚
â”‚                                                                 â”‚
â”‚  âŒ CANNOT pass as arguments:                                   â”‚
â”‚  â”œâ”€ SQLAlchemy model instances (User object)                    â”‚
â”‚  â”œâ”€ Pydantic model instances (UserSchema object)                â”‚
â”‚  â”œâ”€ Database sessions / connections                             â”‚
â”‚  â”œâ”€ File objects                                                â”‚
â”‚  â”œâ”€ FastAPI Request objects                                     â”‚
â”‚  â”œâ”€ datetime objects (pass ISO string instead)                  â”‚
â”‚  â””â”€ Any custom class instance                                   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The pattern: pass IDs, not objects:**

```python
# âŒ WRONG: Passing a SQLAlchemy model
@router.post("/users/")
async def create_user(user_data: UserCreate, db: AsyncSession = Depends(get_db)):
    user = await user_service.create_user(db, user_data)
    send_welcome_email.delay(user)  # TypeError! Can't serialize User object
    return user

# âŒ WRONG: Passing a Pydantic model
@router.post("/users/")
async def create_user(user_data: UserCreate, db: AsyncSession = Depends(get_db)):
    user = await user_service.create_user(db, user_data)
    send_welcome_email.delay(user_data)  # Can't serialize Pydantic model
    return user

# âœ… CORRECT: Pass primitive values the task needs
@router.post("/users/")
async def create_user(user_data: UserCreate, db: AsyncSession = Depends(get_db)):
    user = await user_service.create_user(db, user_data)
    send_welcome_email.delay(user.email, user.username)  # Strings â€” JSON safe
    return user

# âœ… ALSO CORRECT: Pass the ID, let the task fetch what it needs
@router.post("/reports/")
async def request_report(org_id: int, db: AsyncSession = Depends(get_db)):
    task = generate_monthly_report.delay(org_id, 1, 2025)  # Ints â€” JSON safe
    return {"task_id": task.id}

# The task fetches data itself using the ID:
@celery.task
def generate_monthly_report(org_id: int, month: int, year: int) -> dict:
    # Worker creates its OWN database connection
    # and fetches the data it needs using the ID
    ...
```

**Think of it this way:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  Factory analogy:                                               â”‚
â”‚                                                                 â”‚
â”‚  The order form says: "Build a chair for Customer #472"         â”‚
â”‚  The order form does NOT contain the customer standing there.   â”‚
â”‚  The order form does NOT contain the wood and nails.            â”‚
â”‚                                                                 â”‚
â”‚  It contains: instructions and identifiers.                     â”‚
â”‚  The factory worker gets their OWN wood and nails.              â”‚
â”‚                                                                 â”‚
â”‚  Same with Celery:                                              â”‚
â”‚  Pass IDs and simple values.                                    â”‚
â”‚  The worker fetches its own data, opens its own connections.    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Also: NO FastAPI context inside tasks.**

```python
# âŒ WRONG: Using FastAPI's Depends() inside a task
@celery.task
def bad_task(user_id: int):
    db = Depends(get_db)  # This is meaningless here â€” no FastAPI request
    ...

# âŒ WRONG: Using the same async session from FastAPI
@celery.task
def bad_task(user_id: int):
    session = get_async_session()  # Worker doesn't have FastAPI's event loop
    await session.execute(...)     # Can't await in sync function anyway
    ...

# âœ… CORRECT: Task creates its own resources
@celery.task
def good_task(user_id: int) -> dict:
    # Sync engine â€” the worker's own connection
    engine = create_engine("postgresql://user:pass@localhost/mydb")
    with Session(engine) as session:
        user = session.query(User).filter_by(id=user_id).first()
        if not user:
            return {"error": "user_not_found"}
        # ... do work ...
        return {"status": "done"}
```

> "The worker is a completely separate process. It has no idea FastAPI exists. It doesn't share memory, sessions, or context. If the task needs something, it gets it itself â€” its own database connection, its own HTTP client, its own everything."

---

# PART 4: TRACKING WORK â€” RESULTS & STATES

## 4.1 AsyncResult â€” Your Tracking Number

**When you send a task, you get back a tracking number (AsyncResult). You can check it anytime.**

```python
from worker.tasks.email_tasks import send_welcome_email

# Send the task
result = send_welcome_email.delay("alice@test.com", "alice")

# result is an AsyncResult object
print(result.id)       # "f47ac10b-58cc-4372-a567-0e02b2c3d479"
print(result.status)   # "PENDING" (just queued, not started yet)
print(result.ready())  # False (not done yet)
```

**You can also reconstruct an AsyncResult from just the task_id:**

```python
from celery.result import AsyncResult
from worker.celery_app import celery

# If you saved the task_id earlier (e.g., in a database or returned to client)
task_id = "f47ac10b-58cc-4372-a567-0e02b2c3d479"

# Reconstruct the result object
result = AsyncResult(task_id, app=celery)
print(result.status)   # Check current state
print(result.result)   # Get the return value (if done)
```

> "This is like entering a tracking number on a shipping website. You don't need the original receipt â€” just the number."

---

## 4.2 The Task State Machine

**Every task moves through a defined set of states:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  TASK STATE MACHINE                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚                      â”‚ PENDING â”‚  Task is in the queue.          â”‚
â”‚                      â”‚         â”‚  No worker has picked it up.    â”‚
â”‚                      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                â”‚
â”‚                           â”‚                                     â”‚
â”‚                    Worker picks it up                            â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚                      â”‚ STARTED â”‚  Worker is executing the        â”‚
â”‚                      â”‚         â”‚  function right now.            â”‚
â”‚                      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                â”‚
â”‚                           â”‚                                     â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚              â”‚            â”‚            â”‚                         â”‚
â”‚         Returned      Exception    self.retry()                 â”‚
â”‚         a value       raised       called                       â”‚
â”‚              â”‚            â”‚            â”‚                         â”‚
â”‚              â–¼            â–¼            â–¼                         â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚         â”‚ SUCCESS â”‚ â”‚ FAILURE â”‚ â”‚  RETRY  â”‚                     â”‚
â”‚         â”‚         â”‚ â”‚         â”‚ â”‚         â”‚                     â”‚
â”‚         â”‚ .result â”‚ â”‚ .result â”‚ â”‚ Goes    â”‚                     â”‚
â”‚         â”‚ = returnâ”‚ â”‚ = the   â”‚ â”‚ back to â”‚â”€â”€â–¶ back to PENDING  â”‚
â”‚         â”‚   value â”‚ â”‚ Exceptionâ”‚ â”‚ queue   â”‚                    â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  Special state:                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                    â”‚
â”‚  â”‚ REVOKED â”‚  Task was cancelled before/during execution.       â”‚
â”‚  â”‚         â”‚  (task.revoke() was called)                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Inspecting each state:**

```python
from celery.result import AsyncResult
from worker.celery_app import celery

def check_task(task_id: str) -> dict:
    """Check the current state of any task."""
    result = AsyncResult(task_id, app=celery)
    
    response = {
        "task_id": task_id,
        "status": result.status,
        "ready": result.ready(),       # True if SUCCESS or FAILURE
        "successful": result.successful() if result.ready() else None,
    }
    
    if result.status == "SUCCESS":
        response["result"] = result.result       # The return value
    elif result.status == "FAILURE":
        response["error"] = str(result.result)   # The exception
        response["traceback"] = result.traceback  # Full traceback string
    elif result.status == "RETRY":
        response["retry_info"] = str(result.info) # Why it's retrying

    return response
```

---

## 4.3 Checking Status from FastAPI

**Common pattern: client submits work, polls for status.**

```python
# app/routers/reports.py
from fastapi import APIRouter
from celery.result import AsyncResult
from worker.celery_app import celery
from worker.tasks.report_tasks import generate_monthly_report

router = APIRouter(prefix="/reports", tags=["reports"])

@router.post("/", status_code=202)  # 202 Accepted â€” work is queued, not done
async def request_report(org_id: int, month: int, year: int):
    """Request a report generation. Returns immediately."""
    task = generate_monthly_report.delay(org_id, month, year)
    
    return {
        "task_id": task.id,
        "status": "accepted",
        "check_url": f"/reports/status/{task.id}",
    }

@router.get("/status/{task_id}")
async def get_report_status(task_id: str):
    """Poll this endpoint to check if the report is ready."""
    result = AsyncResult(task_id, app=celery)

    if result.status == "PENDING":
        return {"task_id": task_id, "status": "pending", "message": "In queue"}
    elif result.status == "STARTED":
        return {"task_id": task_id, "status": "processing"}
    elif result.status == "SUCCESS":
        return {
            "task_id": task_id,
            "status": "completed",
            "result": result.result,
        }
    elif result.status == "FAILURE":
        return {
            "task_id": task_id,
            "status": "failed",
            "error": str(result.result),
        }
    elif result.status == "RETRY":
        return {"task_id": task_id, "status": "retrying"}
    
    return {"task_id": task_id, "status": result.status}
```

**The HTTP flow:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               CLIENT POLLING PATTERN                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Client                  FastAPI                 Celery Worker   â”‚
â”‚    â”‚                       â”‚                         â”‚          â”‚
â”‚    â”‚ POST /reports/        â”‚                         â”‚          â”‚
â”‚    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚                         â”‚          â”‚
â”‚    â”‚                       â”‚â”€â”€ delay() â”€â”€â–¶ Redis â”€â”€â–¶ â”‚          â”‚
â”‚    â”‚  202 Accepted         â”‚                         â”‚          â”‚
â”‚    â”‚  {task_id: "abc"}     â”‚                         â”‚          â”‚
â”‚    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                         â”‚          â”‚
â”‚    â”‚                       â”‚                    (working...)     â”‚
â”‚    â”‚ GET /reports/status/abc                         â”‚          â”‚
â”‚    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚                         â”‚          â”‚
â”‚    â”‚  {"status": "pending"}â”‚                         â”‚          â”‚
â”‚    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                         â”‚          â”‚
â”‚    â”‚                       â”‚                    (still working)  â”‚
â”‚    â”‚ GET /reports/status/abc                         â”‚          â”‚
â”‚    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚                         â”‚          â”‚
â”‚    â”‚  {"status":"processing"}                        â”‚          â”‚
â”‚    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                         â”‚          â”‚
â”‚    â”‚                       â”‚                    (done!)          â”‚
â”‚    â”‚ GET /reports/status/abc                         â”‚          â”‚
â”‚    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚                         â”‚          â”‚
â”‚    â”‚  {"status":"completed",                         â”‚          â”‚
â”‚    â”‚   "result": {...}}    â”‚                         â”‚          â”‚
â”‚    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                         â”‚          â”‚
â”‚    â”‚                       â”‚                         â”‚          â”‚
â”‚                                                                 â”‚
â”‚  202 Accepted â†’ "I received your order."                        â”‚
â”‚  Status endpoint â†’ "Check the tracking page."                   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> "Notice the 202 status code â€” not 200 or 201. 202 means 'Accepted â€” I've received your request and I'll process it, but it's not done yet.' You learned status code semantics in Week 3. This is where it matters."

---

## 4.4 When You Don't Need Results

**Not every task needs a return value. Fire-and-forget is often enough.**

```python
# If you never check the result, don't store it.
# It wastes Redis memory.

@celery.task(ignore_result=True)  # â† Don't store result in backend
def log_user_activity(user_id: int, action: str, metadata: dict) -> None:
    """Write to audit log. We don't need to check the result."""
    engine = create_engine(DATABASE_URL)
    with Session(engine) as session:
        session.add(AuditLog(
            user_id=user_id,
            action=action,
            metadata=metadata,
        ))
        session.commit()

# When calling â€” you can still get the task_id, but .result will be None
log_user_activity.delay(42, "login", {"ip": "1.2.3.4"})
```

**When to ignore results:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  KEEP RESULTS (default):           IGNORE RESULTS:              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”‚
â”‚  â€¢ Report generation               â€¢ Logging / auditing         â”‚
â”‚    (client needs the output)        (write-and-forget)          â”‚
â”‚  â€¢ File processing                 â€¢ Sending notifications      â”‚
â”‚    (need download URL)              (no response expected)       â”‚
â”‚  â€¢ Data import                     â€¢ Cache warming              â”‚
â”‚    (need success/row count)         (just populate cache)        â”‚
â”‚  â€¢ Any task where the caller       â€¢ Cleanup jobs               â”‚
â”‚    checks status or result          (delete old files)           â”‚
â”‚                                                                 â”‚
â”‚  ignore_result=True saves Redis memory and reduces overhead.    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# PART 5: WHEN THINGS GO WRONG â€” RETRIES

## 5.1 What Happens When a Task Fails?

**By default: the exception is captured, the task is marked FAILURE, and life moves on.**

```python
@celery.task
def fragile_task(url: str) -> dict:
    import httpx
    response = httpx.get(url, timeout=5)  # Might timeout!
    response.raise_for_status()           # Might be 500!
    return response.json()

# If this task raises an exception:
# 1. The worker catches it
# 2. Task state â†’ FAILURE
# 3. result.result = the Exception object
# 4. result.traceback = full traceback string
# 5. The task is NOT retried (by default)
# 6. Worker moves on to the next task
```

**The worker log shows:**

```
[... ERROR/ForkPoolWorker-1] Task worker.tasks.fragile_task[abc-123] 
raised unexpected: ConnectTimeout('Connection timed out')
Traceback (most recent call last):
  File ".../worker/tasks/example.py", line 4, in fragile_task
    response = httpx.get(url, timeout=5)
  ...
httpx.ConnectTimeout: Connection timed out
```

> "The task fails. The worker logs the error. Nobody retries it. For some tasks, that's fine â€” if a cache warm fails, whatever. But for sending an invoice? You need retries."

---

## 5.2 bind=True â€” Giving the Task Self-Awareness

**Before we can retry, the task needs access to its own task object. That's what `bind=True` does.**

```python
# Without bind: the function is just a function
@celery.task
def simple_task(x: int, y: int) -> int:
    return x + y

# With bind: the function receives 'self' â€” the Task instance
@celery.task(bind=True)
def aware_task(self, x: int, y: int) -> int:
    print(f"Task ID: {self.request.id}")
    print(f"Retry count: {self.request.retries}")
    return x + y
```

**What `self` gives you access to:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             WHAT bind=True UNLOCKS                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  self.request.id          â†’ The unique task ID                  â”‚
â”‚  self.request.retries     â†’ How many times this task retried    â”‚
â”‚  self.request.args        â†’ The positional arguments            â”‚
â”‚  self.request.kwargs      â†’ The keyword arguments               â”‚
â”‚  self.request.delivery_info â†’ Queue info                        â”‚
â”‚                                                                 â”‚
â”‚  self.retry()             â†’ Re-queue this task (retry it)       â”‚
â”‚  self.max_retries         â†’ Max retry count from config         â”‚
â”‚  self.name                â†’ Full task name string               â”‚
â”‚                                                                 â”‚
â”‚  Think of bind=True as giving the factory worker an employee    â”‚
â”‚  badge. Now they know their name, can check how many times      â”‚
â”‚  they've tried this order, and can officially request a redo.   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> "Notice that `self` is the **first** parameter, before your actual arguments. When calling with `.delay()`, you still pass only your arguments â€” Celery injects `self` automatically. This is the same pattern as instance methods on classes."

```python
# Calling a bound task â€” same as before, 'self' is invisible to callers
aware_task.delay(3, 5)        # Just pass x and y â€” self is automatic
```

---

## 5.3 Manual Retry with self.retry()

**You decide WHEN to retry and with what delay.**

```python
@celery.task(bind=True, max_retries=3)
def send_notification(self, user_id: int, message: str) -> dict:
    """Send a push notification. Retry on transient failures."""
    import httpx
    
    try:
        response = httpx.post(
            "https://push-service.example.com/send",
            json={"user_id": user_id, "message": message},
            timeout=10,
        )
        response.raise_for_status()
        return {"status": "sent", "user_id": user_id}
    
    except httpx.TimeoutException:
        # Transient error â€” retry after a delay
        raise self.retry(
            countdown=60,  # Wait 60 seconds before retrying
            exc=httpx.TimeoutException("Push service timed out"),
        )
    
    except httpx.HTTPStatusError as exc:
        if exc.response.status_code == 503:
            # Service temporarily unavailable â€” retry
            raise self.retry(countdown=120, exc=exc)
        
        elif exc.response.status_code == 400:
            # Bad request â€” OUR fault, retrying won't help
            return {"status": "failed", "reason": "invalid_request"}
        
        else:
            # Unknown error â€” let it fail
            raise
```

**Critical pattern: raise self.retry(), do NOT call and ignore it:**

```python
# âŒ WRONG: calling self.retry() without raise
except TimeoutError:
    self.retry(countdown=60)  # This works but is confusing
    # Code below this STILL RUNS in some edge cases!
    print("This might execute!")

# âœ… CORRECT: raise self.retry()
except TimeoutError:
    raise self.retry(countdown=60)  # Raises Retry exception â€” clear exit
    # Code below this NEVER runs
```

**What self.retry() does internally:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               self.retry() INTERNALS                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  raise self.retry(countdown=60, exc=original_exception)         â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚  1. Checks: retries < max_retries?                              â”‚
â”‚     â”œâ”€ YES: Continue to step 2                                  â”‚
â”‚     â””â”€ NO: Raise MaxRetriesExceededError                        â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚  2. Sends a NEW message to the broker                           â”‚
â”‚     with same args/kwargs but incremented retry count           â”‚
â”‚     and ETA = now + countdown                                   â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚  3. Raises celery.exceptions.Retry                              â”‚
â”‚     (this stops the current execution cleanly)                  â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚  4. Task state â†’ RETRY                                          â”‚
â”‚     The new message sits in the queue until countdown expires.   â”‚
â”‚     Then a worker picks it up and runs the function AGAIN.      â”‚
â”‚                                                                 â”‚
â”‚  It's like the factory worker saying: "This piece is defective. â”‚
â”‚  Put the order back on the belt. I'll try again in an hour."    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Retry with different arguments (advanced):**

```python
@celery.task(bind=True, max_retries=3)
def process_with_fallback(self, url: str, use_backup: bool = False) -> dict:
    try:
        response = httpx.get(url, timeout=10)
        return response.json()
    except httpx.TimeoutException:
        if not use_backup:
            # Retry with the backup URL flag
            raise self.retry(
                countdown=30,
                kwargs={"url": url, "use_backup": True},
            )
        else:
            # Already tried backup â€” give up
            raise
```

---

## 5.4 Declarative Retry with autoretry_for

**For simpler cases, you don't need the try/except at all. Declare which exceptions should trigger a retry.**

```python
@celery.task(
    bind=True,
    autoretry_for=(ConnectionError, TimeoutError, IOError),
    max_retries=5,
    retry_backoff=True,       # Exponential backoff (next section)
    retry_jitter=True,        # Add randomness to prevent thundering herd
)
def sync_external_data(self, source_id: int) -> dict:
    """Fetch data from external source and store locally.
    
    If ConnectionError, TimeoutError, or IOError is raised,
    Celery automatically retries â€” no try/except needed.
    """
    import httpx
    
    response = httpx.get(f"https://api.source.com/data/{source_id}", timeout=15)
    response.raise_for_status()
    data = response.json()
    
    engine = create_engine(DATABASE_URL)
    with Session(engine) as session:
        session.merge(ExternalData(source_id=source_id, payload=data))
        session.commit()
    
    return {"source_id": source_id, "records": len(data)}
```

**Comparison â€” same behavior, two styles:**

```python
# MANUAL RETRY (verbose but full control):
@celery.task(bind=True, max_retries=5)
def fetch_data_manual(self, url: str) -> dict:
    try:
        response = httpx.get(url, timeout=10)
        return response.json()
    except (ConnectionError, TimeoutError) as exc:
        raise self.retry(exc=exc, countdown=2 ** self.request.retries)

# DECLARATIVE RETRY (concise, less control):
@celery.task(
    autoretry_for=(ConnectionError, TimeoutError),
    max_retries=5,
    retry_backoff=True,
)
def fetch_data_declarative(url: str) -> dict:
    response = httpx.get(url, timeout=10)
    return response.json()

# Same result. Choose based on whether you need custom logic per exception.
```

**When to use which:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  autoretry_for:                  â”‚  self.retry():               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                   â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€               â”‚
â”‚  Same handling for all listed    â”‚  Different handling per       â”‚
â”‚  exceptions. Retry all of them   â”‚  exception type. Custom       â”‚
â”‚  with the same strategy.         â”‚  countdown. Different args.   â”‚
â”‚                                  â”‚                               â”‚
â”‚  Use for: network errors,        â”‚  Use for: partial failures,   â”‚
â”‚  timeouts, external services     â”‚  fallback logic, conditional  â”‚
â”‚  that are reliably transient.    â”‚  retry decisions.             â”‚
â”‚                                  â”‚                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5.5 Exponential Backoff (Week 8 Callback)

**You implemented this with tenacity in Week 8 for HTTP clients. Celery has it built in.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             EXPONENTIAL BACKOFF IN CELERY                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  retry_backoff=True means:                                      â”‚
â”‚                                                                 â”‚
â”‚  Attempt 1 fails â†’ wait 1 second                                â”‚
â”‚  Attempt 2 fails â†’ wait 2 seconds                               â”‚
â”‚  Attempt 3 fails â†’ wait 4 seconds                               â”‚
â”‚  Attempt 4 fails â†’ wait 8 seconds                               â”‚
â”‚  Attempt 5 fails â†’ wait 16 seconds                              â”‚
â”‚  ...                                                            â”‚
â”‚                                                                 â”‚
â”‚  Formula: delay = backoff_base ** retry_number                  â”‚
â”‚  Default backoff_base = 2 (doubles each time)                   â”‚
â”‚                                                                 â”‚
â”‚  Or specify a fixed base:                                       â”‚
â”‚  retry_backoff=3 â†’ wait 3, 9, 27, 81, 243...                   â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  retry_backoff_max=600 â†’ Cap the delay at 600s (10 minutes)     â”‚
â”‚  Without a cap, delay grows forever. Don't wait 3 hours.        â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  retry_jitter=True â†’ Adds random Â±variation to each delay       â”‚
â”‚  WHY? If 100 tasks all fail at the same time (e.g., DB is       â”‚
â”‚  down), they'd all retry at the same time â†’ same overload.      â”‚
â”‚  Jitter spreads them out. Same reason as Week 8 tenacity.       â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  Attempt timeline with jitter (approximate):                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                     â”‚
â”‚  0s      1.3s    3.7s      11.2s           42.1s                â”‚
â”‚  â”‚ fail  â”‚ fail  â”‚ fail    â”‚ fail          â”‚ success!           â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”¤â”€â”€â”€â”€â”€â”€â”€â”¤â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                    â”‚
â”‚  try 1   try 2   try 3    try 4           try 5                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The production-ready pattern:**

```python
@celery.task(
    bind=True,
    autoretry_for=(ConnectionError, TimeoutError),
    max_retries=5,
    retry_backoff=2,          # Base: 2 seconds
    retry_backoff_max=600,    # Cap: 10 minutes
    retry_jitter=True,        # Random spread
)
def resilient_task(self, data_id: int) -> dict:
    """A task that handles transient failures gracefully."""
    # ... do work ...
    pass
```

> "Same exponential backoff pattern from Week 8 with tenacity. There it was for HTTP client retries. Here it's for background task retries. Same principle: give the failing service time to recover, with increasing patience."

---

## 5.6 After Max Retries: Accepting Failure

**What happens when all retries are exhausted?**

```python
@celery.task(bind=True, max_retries=3)
def send_critical_email(self, to: str, subject: str, body: str) -> dict:
    try:
        smtp_send(to, subject, body)
        return {"status": "sent"}
    except SMTPConnectionError as exc:
        try:
            raise self.retry(exc=exc, countdown=60)
        except self.MaxRetriesExceededError:
            # All retries exhausted. This is our LAST CHANCE to handle it.
            # Log it, alert someone, save to a dead letter table.
            
            log_failed_email(to, subject, body, error=str(exc))
            notify_ops_team(f"Email to {to} failed after {self.max_retries} retries")
            
            # Return failure info instead of raising
            return {
                "status": "permanently_failed",
                "to": to,
                "error": str(exc),
                "retries_attempted": self.request.retries,
            }
```

**Or use a callback for failure handling:**

```python
def handle_task_failure(self, exc, task_id, args, kwargs, einfo):
    """Called when a task fails permanently (after all retries)."""
    # self = task instance, exc = exception, einfo = traceback
    print(f"Task {task_id} permanently failed: {exc}")
    # Log to database, send alert, etc.

@celery.task(
    bind=True,
    autoretry_for=(ConnectionError,),
    max_retries=5,
    retry_backoff=True,
    on_failure=handle_task_failure,  # â† Called after final failure
)
def task_with_failure_hook(self, item_id: int) -> dict:
    # ... do work ...
    pass
```

**The decision: retry or don't?**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             RETRY OR DON'T? DECISION GUIDE                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  âœ… RETRY (transient â€” might work next time):                   â”‚
â”‚  â”œâ”€ ConnectionError         (network blip)                      â”‚
â”‚  â”œâ”€ TimeoutError            (slow response)                     â”‚
â”‚  â”œâ”€ HTTP 502, 503, 504      (server temporarily down)           â”‚
â”‚  â”œâ”€ Database connection lost (pool exhausted, restart)           â”‚
â”‚  â””â”€ Rate limit hit (429)    (wait and try again)                â”‚
â”‚                                                                 â”‚
â”‚  âŒ DO NOT RETRY (permanent â€” will NEVER work):                 â”‚
â”‚  â”œâ”€ ValueError              (bad data, won't change)            â”‚
â”‚  â”œâ”€ HTTP 400, 401, 403, 404 (client error, our fault)           â”‚
â”‚  â”œâ”€ ValidationError         (invalid input)                     â”‚
â”‚  â”œâ”€ IntegrityError          (duplicate key, constraint)         â”‚
â”‚  â””â”€ PermissionError         (wrong credentials)                 â”‚
â”‚                                                                 â”‚
â”‚  Retrying a permanent error wastes resources and delays the     â”‚
â”‚  inevitable. Fail fast on errors that won't fix themselves.     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# PART 6: THE NON-NEGOTIABLE â€” IDEMPOTENCY

## 6.1 At-Least-Once Delivery (The Uncomfortable Truth)

**Remember idempotency from Week 4's API design lecture? You learned that PUT and DELETE are idempotent â€” calling them multiple times has the same effect as calling them once. Now idempotency becomes critical, because Celery delivers tasks AT LEAST ONCE.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           DELIVERY GUARANTEES                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Three possible guarantees:                                     â”‚
â”‚                                                                 â”‚
â”‚  AT-MOST-ONCE:   Message delivered 0 or 1 time.                 â”‚
â”‚                  Might lose messages. Never duplicates.          â”‚
â”‚                                                                 â”‚
â”‚  AT-LEAST-ONCE:  Message delivered 1 or MORE times.  â† CELERY  â”‚
â”‚                  Never loses messages. Might duplicate.          â”‚
â”‚                                                                 â”‚
â”‚  EXACTLY-ONCE:   Message delivered exactly 1 time.              â”‚
â”‚                  The holy grail. Extremely hard in distributed   â”‚
â”‚                  systems. Celery does NOT guarantee this.        â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  Celery with acks_late=True gives you AT-LEAST-ONCE.            â”‚
â”‚  Your task WILL run. But it might run MORE THAN ONCE.           â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6.2 How Duplicates Happen

**This isn't theoretical. It WILL happen in production.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              HOW TASKS GET DUPLICATED                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  SCENARIO 1: Worker crashes after completing, before acking     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”‚
â”‚                                                                 â”‚
â”‚  Worker picks up task â†’ Sends email â†’ CRASH before acknowledge  â”‚
â”‚  Broker thinks task wasn't done â†’ Redelivers to another worker  â”‚
â”‚  Second worker sends the email AGAIN.                           â”‚
â”‚                                                                 â”‚
â”‚     Worker 1: [pick up] â†’ [send email] â†’ [CRASH]               â”‚
â”‚     Broker:   "Task not acknowledged, redelivering..."          â”‚
â”‚     Worker 2: [pick up] â†’ [send email] â†’ [ack] âœ…              â”‚
â”‚     Result:   Customer gets TWO emails.                         â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  SCENARIO 2: Visibility timeout expires                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”‚
â”‚                                                                 â”‚
â”‚  Worker picks up a long task â†’ Takes too long â†’ Broker assumes  â”‚
â”‚  the worker is dead â†’ Redelivers to another worker.             â”‚
â”‚  Now TWO workers are running the same task.                     â”‚
â”‚                                                                 â”‚
â”‚     Worker 1: [pick up] â†’ [still running..........]             â”‚
â”‚     Broker:   "Too slow, must be dead. Redelivering..."         â”‚
â”‚     Worker 2: [pick up] â†’ [running too...]                      â”‚
â”‚     Result:   Task runs TWICE concurrently.                     â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  SCENARIO 3: Network partition                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â”‚
â”‚                                                                 â”‚
â”‚  Worker completes task â†’ Sends ACK â†’ Network drops ACK          â”‚
â”‚  Broker never receives ACK â†’ Redelivers.                        â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  YOU CANNOT PREVENT DUPLICATES in a distributed system.         â”‚
â”‚  You can only make duplicates HARMLESS.                         â”‚
â”‚  That's idempotency.                                            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6.3 Making Tasks Idempotent (Patterns)

**An idempotent task produces the same result whether it runs 1 time or 10 times.**

```python
# âŒ NOT IDEMPOTENT: Charges the customer again on every run
@celery.task
def charge_customer_bad(order_id: int, amount: float) -> dict:
    payment_gateway.charge(amount)  # Runs again on duplicate!
    return {"status": "charged"}

# Running twice = customer charged twice. Disaster.


# âœ… IDEMPOTENT: Checks if already charged before charging
@celery.task
def charge_customer_good(order_id: int, amount: float) -> dict:
    engine = create_engine(DATABASE_URL)
    with Session(engine) as session:
        # Check: has this order already been charged?
        existing = session.query(Payment).filter_by(
            order_id=order_id,
            status="completed",
        ).first()
        
        if existing:
            # Already charged â€” return the existing result
            return {
                "status": "already_charged",
                "payment_id": existing.id,
            }
        
        # Not yet charged â€” proceed
        result = payment_gateway.charge(amount)
        
        # Record the charge
        session.add(Payment(
            order_id=order_id,
            amount=amount,
            status="completed",
            gateway_id=result.transaction_id,
        ))
        session.commit()
        
        return {"status": "charged", "payment_id": result.transaction_id}

# Running twice = second run returns "already_charged." Customer charged once.
```

**Three idempotency patterns:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              IDEMPOTENCY PATTERNS                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  PATTERN 1: CHECK-THEN-ACT                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚
â”‚  Before doing work, check if it was already done.               â”‚
â”‚  "Has this email been sent?" â†’ If yes, skip.                    â”‚
â”‚  Best for: operations with observable side effects.             â”‚
â”‚                                                                 â”‚
â”‚  PATTERN 2: DATABASE UNIQUE CONSTRAINTS                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”‚
â”‚  Use a unique constraint to prevent duplicate records.          â”‚
â”‚  INSERT fails on duplicate â†’ catch IntegrityError â†’ return.     â”‚
â”‚  Best for: data creation tasks.                                 â”‚
â”‚                                                                 â”‚
â”‚  PATTERN 3: IDEMPOTENCY KEY IN REDIS                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                           â”‚
â”‚  Use SET NX (set-if-not-exists) to claim a lock before work.    â”‚
â”‚  If the key already exists, another run already did it.         â”‚
â”‚  Best for: quick checks before expensive operations.            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6.4 Database-Backed Idempotency Keys

**The most robust pattern for production: a dedicated table that records completed work.**

```python
# Pattern 3 in practice â€” Redis-backed idempotency

import redis

redis_client = redis.Redis(host="localhost", port=6379, db=2)

@celery.task(bind=True)
def send_welcome_email(self, user_id: int) -> dict:
    """Send welcome email â€” guaranteed to send at most once."""
    
    idempotency_key = f"task:welcome_email:{user_id}"
    
    # Try to claim this task. SET NX = Set if Not eXists.
    # TTL of 86400 = key expires after 24 hours (cleanup).
    was_set = redis_client.set(idempotency_key, "processing", nx=True, ex=86400)
    
    if not was_set:
        # Key already existed â€” this task was already processed (or is in progress)
        return {"status": "already_processed", "user_id": user_id}
    
    try:
        # We claimed the key. Do the work.
        engine = create_engine(DATABASE_URL)
        with Session(engine) as session:
            user = session.query(User).filter_by(id=user_id).first()
            if not user:
                return {"status": "user_not_found"}
            
            smtp_send(to=user.email, subject="Welcome!", body="...")
            
            # Mark as completed
            redis_client.set(idempotency_key, "completed", ex=86400)
            return {"status": "sent", "to": user.email}
    
    except Exception:
        # If we fail, DELETE the key so a retry can try again
        redis_client.delete(idempotency_key)
        raise  # Let Celery's retry mechanism handle it
```

**How this prevents duplicates:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           IDEMPOTENCY KEY FLOW                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Run 1 (first execution):                                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚
â”‚  SET NX "task:welcome_email:42" â†’ True (key created)            â”‚
â”‚  Send email â†’ Success                                           â”‚
â”‚  SET "task:welcome_email:42" = "completed"                      â”‚
â”‚                                                                 â”‚
â”‚  Run 2 (duplicate delivery):                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚  SET NX "task:welcome_email:42" â†’ False (key already exists!)   â”‚
â”‚  Return {"status": "already_processed"}                         â”‚
â”‚  Email NOT sent again. âœ…                                       â”‚
â”‚                                                                 â”‚
â”‚  Run after failure + retry:                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚  SET NX "task:welcome_email:42" â†’ True (key was deleted on fail)â”‚
â”‚  Send email â†’ Success                                           â”‚
â”‚  Retry works correctly. âœ…                                      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The database version â€” for when you need a permanent audit trail:**

```python
# In your models (sync SQLAlchemy, used by workers)
class ProcessedTask(Base):
    __tablename__ = "processed_tasks"
    
    id: Mapped[int] = mapped_column(primary_key=True)
    idempotency_key: Mapped[str] = mapped_column(String(255), unique=True, index=True)
    task_name: Mapped[str] = mapped_column(String(255))
    result: Mapped[dict] = mapped_column(JSONB, nullable=True)
    processed_at: Mapped[datetime] = mapped_column(default=datetime.utcnow)


@celery.task(bind=True)
def process_invoice(self, invoice_id: int) -> dict:
    """Process an invoice â€” exactly once, with database proof."""
    
    idempotency_key = f"invoice:process:{invoice_id}"
    
    engine = create_engine(DATABASE_URL)
    with Session(engine) as session:
        # Check if already processed
        existing = session.query(ProcessedTask).filter_by(
            idempotency_key=idempotency_key
        ).first()
        
        if existing:
            return existing.result  # Return the cached result
        
        # Do the actual work
        invoice = session.query(Invoice).filter_by(id=invoice_id).first()
        result = billing_service.process(invoice)
        
        # Record completion (unique constraint prevents races)
        try:
            session.add(ProcessedTask(
                idempotency_key=idempotency_key,
                task_name="process_invoice",
                result=result,
            ))
            session.commit()
        except IntegrityError:
            # Another worker beat us (race condition) â€” that's fine
            session.rollback()
            existing = session.query(ProcessedTask).filter_by(
                idempotency_key=idempotency_key
            ).first()
            return existing.result
        
        return result
```

> "Idempotency isn't optional. It's not a 'nice to have.' In a distributed system, tasks WILL be duplicated. The only question is whether you handle it gracefully or your users get charged twice."

---

## Quick Reference Card

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  CELERY QUICK REFERENCE                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  CREATE CELERY APP:                                             â”‚
â”‚      celery = Celery("worker",                                  â”‚
â”‚          broker="redis://localhost:6379/0",                      â”‚
â”‚          backend="redis://localhost:6379/1")                     â”‚
â”‚                                                                 â”‚
â”‚  DEFINE A TASK:                                                 â”‚
â”‚      @celery.task                                               â”‚
â”‚      def my_task(arg1: str, arg2: int) -> dict:                 â”‚
â”‚          return {"result": "done"}                              â”‚
â”‚                                                                 â”‚
â”‚  DEFINE A BOUND TASK (for retries):                             â”‚
â”‚      @celery.task(bind=True, max_retries=3)                     â”‚
â”‚      def my_task(self, arg1: str) -> dict:                      â”‚
â”‚          ...                                                    â”‚
â”‚                                                                 â”‚
â”‚  CALL A TASK (async/background):                                â”‚
â”‚      result = my_task.delay(arg1, arg2)                         â”‚
â”‚      result = my_task.apply_async(args=[...], countdown=60)     â”‚
â”‚                                                                 â”‚
â”‚  CALL A TASK (sync/direct â€” for testing):                       â”‚
â”‚      result = my_task(arg1, arg2)                               â”‚
â”‚                                                                 â”‚
â”‚  CHECK RESULT:                                                  â”‚
â”‚      result = AsyncResult(task_id, app=celery)                  â”‚
â”‚      result.status    â†’ "PENDING" / "STARTED" / "SUCCESS" /... â”‚
â”‚      result.ready()   â†’ True if done (success or failure)       â”‚
â”‚      result.result    â†’ Return value (if SUCCESS)               â”‚
â”‚                       â†’ Exception (if FAILURE)                  â”‚
â”‚                                                                 â”‚
â”‚  RETRY (manual):                                                â”‚
â”‚      raise self.retry(countdown=60, exc=original_error)         â”‚
â”‚                                                                 â”‚
â”‚  RETRY (declarative):                                           â”‚
â”‚      @celery.task(                                              â”‚
â”‚          autoretry_for=(ConnectionError,),                      â”‚
â”‚          retry_backoff=True,                                    â”‚
â”‚          retry_backoff_max=600,                                 â”‚
â”‚          retry_jitter=True,                                     â”‚
â”‚          max_retries=5,                                         â”‚
â”‚      )                                                          â”‚
â”‚                                                                 â”‚
â”‚  RUN THE WORKER:                                                â”‚
â”‚      celery -A worker.celery_app worker --loglevel=info         â”‚
â”‚                                                                 â”‚
â”‚  TASK ARGUMENTS â€” MUST be JSON-serializable:                    â”‚
â”‚      âœ… str, int, float, bool, None, list, dict                 â”‚
â”‚      âŒ Objects, models, sessions, file handles, datetime       â”‚
â”‚      â†³ Pass IDs. Let the task fetch its own data.               â”‚
â”‚                                                                 â”‚
â”‚  COMMON MISTAKES:                                               â”‚
â”‚      âŒ async def task     â†’ Use regular def (sync)             â”‚
â”‚      âŒ Pass SQLAlchemy    â†’ Pass the ID, query in the task     â”‚
â”‚         model as argument                                       â”‚
â”‚      âŒ Use Depends()      â†’ Task has no FastAPI context         â”‚
â”‚         in a task                                               â”‚
â”‚      âŒ Forget to run      â†’ celery -A ... worker is required   â”‚
â”‚         the worker                                              â”‚
â”‚      âŒ Non-idempotent     â†’ Always check before acting         â”‚
â”‚         task                                                    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Summary: The Key Mental Model

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  CELERY = WORK THAT LIVES OUTSIDE YOUR WEB SERVER               â”‚
â”‚                                                                 â”‚
â”‚  Your FastAPI server's job:                                     â”‚
â”‚      Accept requests â†’ Respond fast â†’ Delegate heavy work       â”‚
â”‚                                                                 â”‚
â”‚  Celery workers' job:                                           â”‚
â”‚      Pick up work â†’ Execute it â†’ Report results                 â”‚
â”‚                                                                 â”‚
â”‚  They communicate through Redis.                                â”‚
â”‚  They don't share memory, connections, or context.              â”‚
â”‚                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚   â”‚  FastAPI  â”‚â”€â”€â”€â”€â–¶â”‚  Redis   â”‚â”€â”€â”€â”€â–¶â”‚  Celery  â”‚               â”‚
â”‚   â”‚  "Do this"â”‚     â”‚ "Holding â”‚     â”‚ "Done.   â”‚               â”‚
â”‚   â”‚          â”‚â—€â”€ â”€ â”€â”‚  it"     â”‚â—€â”€ â”€ â”‚  Here's  â”‚               â”‚
â”‚   â”‚          â”‚      â”‚          â”‚     â”‚  result" â”‚               â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚   Process 1         Service          Process 2                  â”‚
â”‚   (async)           (persists)       (sync)                     â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  THE FACTORY ANALOGY:                                           â”‚
â”‚  â”œâ”€ Sales office (FastAPI) takes orders                         â”‚
â”‚  â”œâ”€ Conveyor belt (Redis) carries order forms                   â”‚
â”‚  â”œâ”€ Factory workers (Celery) build products                     â”‚
â”‚  â”œâ”€ Order number (task_id) tracks progress                      â”‚
â”‚  â”œâ”€ Defective â†’ redo (retry with backoff)                       â”‚
â”‚  â””â”€ Stamp each order "DONE" only once (idempotency)             â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  THREE RULES TO REMEMBER:                                       â”‚
â”‚                                                                 â”‚
â”‚  1. Tasks are SYNC functions (workers don't need event loops)   â”‚
â”‚  2. Arguments must be JSON-serializable (pass IDs, not objects) â”‚
â”‚  3. Tasks MUST be idempotent (they WILL run more than once)     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Connection to Upcoming Lectures

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WHERE THIS LEADS                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  WEEK 11 LECTURE 3 (next lecture):                               â”‚
â”‚  â””â”€ Celery Beat â€” SCHEDULING tasks to run periodically          â”‚
â”‚     (cron-like: "run this report every Monday at 6 AM")         â”‚
â”‚     Flower â€” MONITORING your workers and tasks via web UI       â”‚
â”‚     You'll schedule and observe the tasks you defined today.    â”‚
â”‚                                                                 â”‚
â”‚  WEEK 11 LECTURE 4:                                             â”‚
â”‚  â””â”€ Event-Driven Architecture â€” Pub/Sub with Redis              â”‚
â”‚     Compare: task queue (Celery) vs event broadcast (pub/sub)   â”‚
â”‚     Different patterns for different problems.                  â”‚
â”‚                                                                 â”‚
â”‚  WEEK 11 PROJECT:                                               â”‚
â”‚  â””â”€ Background Processing Pipeline                              â”‚
â”‚     You'll build: scheduled data jobs, event-triggered          â”‚
â”‚     notifications, retry logic, idempotent tasks, monitoring.   â”‚
â”‚     Everything from this lecture, wired together.               â”‚
â”‚                                                                 â”‚
â”‚  WEEK 12 (WebSockets & Performance):                            â”‚
â”‚  â””â”€ Celery tasks triggering WebSocket notifications             â”‚
â”‚     "Report done!" â†’ push to connected clients in real-time     â”‚
â”‚                                                                 â”‚
â”‚  WEEK 13-14 (Capstone):                                         â”‚
â”‚  â””â”€ Background jobs in your SaaS: email on task assignment,     â”‚
â”‚     report generation, audit logging, cache warming.            â”‚
â”‚     Celery is a core component of your final project.           â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```