# LECTURE DESIGN PHILOSOPHY

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PEDAGOGICAL APPROACH                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  PRODUCTION FAILURE FIRST                                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                       â”‚
â”‚  Everything you built in Lecture 1 works perfectly â€” on your    â”‚
â”‚  laptop, with one server, on a stable network. This lecture     â”‚
â”‚  is about what happens when every one of those breaks.          â”‚
â”‚  We show the failure THEN the pattern that prevents it.         â”‚
â”‚                                                                 â”‚
â”‚  SYSTEM THINKING                                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                â”‚
â”‚  Students shift from "single-process on localhost" to           â”‚
â”‚  "distributed system with unreliable networks." This is a      â”‚
â”‚  mental shift, not just new API calls.                          â”‚
â”‚                                                                 â”‚
â”‚  RIGHT TOOL, RIGHT PROBLEM                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                       â”‚
â”‚  WebSocket, SSE, and polling each have their place.             â”‚
â”‚  The decision framework matters more than any implementation.   â”‚
â”‚                                                                 â”‚
â”‚  SYNTHESIS OF PRIOR KNOWLEDGE                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                   â”‚
â”‚  Redis pub/sub (Week 11), async tasks (Week 1),                â”‚
â”‚  auth dependencies (Week 9), testing (Week 2/4) â€”              â”‚
â”‚  this lecture ties them together under real-time architecture.  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# LECTURE OUTLINE

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     REAL-TIME PATTERNS                          â”‚
â”‚                     (3-4 Hour Lecture)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  PART 1: THE GHOST CONNECTION PROBLEM (45 min)                  â”‚
â”‚  â”œâ”€ 1.1 Ghosts in Your Server (Demonstration)                   â”‚
â”‚  â”œâ”€ 1.2 Why TCP Doesn't Save You                                â”‚
â”‚  â”œâ”€ 1.3 The Ping-Pong Protocol                                  â”‚
â”‚  â””â”€ 1.4 Building a Heartbeat Monitor                            â”‚
â”‚                                                                 â”‚
â”‚  PART 2: SURVIVING DISCONNECTIONS (30 min)                      â”‚
â”‚  â”œâ”€ 2.1 Why Connections Drop (The Real World)                    â”‚
â”‚  â”œâ”€ 2.2 Reconnection from the Server's Perspective              â”‚
â”‚  â”œâ”€ 2.3 Missed Message Recovery                                 â”‚
â”‚  â””â”€ 2.4 Grace Periods and State Cleanup                         â”‚
â”‚                                                                 â”‚
â”‚  PART 3: THE SCALING WALL (50 min)                              â”‚
â”‚  â”œâ”€ 3.1 One Server Works, Two Servers Break (Demonstration)     â”‚
â”‚  â”œâ”€ 3.2 The Architecture Shift                                  â”‚
â”‚  â”œâ”€ 3.3 Redis Pub/Sub as the Backbone (Connection to Week 11)   â”‚
â”‚  â””â”€ 3.4 Implementing Cross-Server Broadcasting                  â”‚
â”‚                                                                 â”‚
â”‚  PART 4: SERVER-SENT EVENTS â€” THE SIMPLER TOOL (30 min)         â”‚
â”‚  â”œâ”€ 4.1 Not Everything Needs WebSocket                          â”‚
â”‚  â”œâ”€ 4.2 How SSE Works (Protocol and Format)                     â”‚
â”‚  â”œâ”€ 4.3 SSE in FastAPI                                          â”‚
â”‚  â””â”€ 4.4 WebSocket vs SSE vs Polling (Decision Framework)        â”‚
â”‚                                                                 â”‚
â”‚  PART 5: TESTING REAL-TIME ENDPOINTS (30 min)                   â”‚
â”‚  â”œâ”€ 5.1 Why Real-Time Testing is Hard                           â”‚
â”‚  â”œâ”€ 5.2 Testing WebSocket Endpoints with TestClient             â”‚
â”‚  â”œâ”€ 5.3 Testing Heartbeat, Disconnect, and Authentication       â”‚
â”‚  â””â”€ 5.4 Mocking Redis for Cross-Server Tests                    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# PART 1: THE GHOST CONNECTION PROBLEM

## 1.1 Ghosts in Your Server

**Start with the scenario. Make them see the disaster unfolding.**

> "Your chat application from Lecture 1 is deployed. 200 users connected. You check your connection manager: it says 847 active connections. How?"

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   THE GHOST SCENARIO                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Monday 9:00 AM â€” 50 users connect                              â”‚
â”‚  âœ… ConnectionManager.active_connections: 50                    â”‚
â”‚                                                                 â”‚
â”‚  Monday 10:30 AM â€” 30 more connect                              â”‚
â”‚  âœ… ConnectionManager.active_connections: 80                    â”‚
â”‚                                                                 â”‚
â”‚  Monday 12:00 PM â€” lunch break                                  â”‚
â”‚  20 users close their laptops (wifi off, no close frame sent)   â”‚
â”‚  15 users' phones switch to cellular (TCP connection gone)      â”‚
â”‚  10 users walk into elevator (signal lost)                      â”‚
â”‚                                                                 â”‚
â”‚  âŒ ConnectionManager.active_connections: still 80              â”‚
â”‚                                                                 â”‚
â”‚  Monday 3:00 PM                                                 â”‚
â”‚  50 new users, 60 more ghosts accumulated                       â”‚
â”‚  âŒ ConnectionManager.active_connections: 190                   â”‚
â”‚  âŒ Real living connections: 95                                 â”‚
â”‚  âŒ Ghost connections eating memory: 95                         â”‚
â”‚                                                                 â”‚
â”‚  Wednesday:                                                     â”‚
â”‚  âŒ active_connections: 847                                     â”‚
â”‚  âŒ Real connections: ~200                                      â”‚
â”‚  âŒ Server: running out of memory, broadcast is slow            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Now show what happens when you broadcast to ghosts:**

```python
# This is your ConnectionManager from Lecture 1
# It looks correct. It IS correct â€” for a perfect network.

class ConnectionManager:
    def __init__(self):
        self.active_connections: list[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)

    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)

    async def broadcast(self, message: str):
        for connection in self.active_connections:
            await connection.send_text(message)
```

**The problem: `disconnect()` is only called when the client sends a proper close frame.** But what about:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              WAYS A CONNECTION DIES SILENTLY                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  âŒ User closes laptop lid (OS suspends network)                â”‚
â”‚     â†’ No close frame sent. Server doesn't know.                â”‚
â”‚                                                                 â”‚
â”‚  âŒ User walks out of wifi range                                â”‚
â”‚     â†’ TCP packets vanish. No RST, no FIN. Just silence.        â”‚
â”‚                                                                 â”‚
â”‚  âŒ User's phone switches from wifi to cellular                 â”‚
â”‚     â†’ New IP address. Old TCP connection is abandoned.          â”‚
â”‚                                                                 â”‚
â”‚  âŒ Intermediate proxy/NAT times out the connection             â”‚
â”‚     â†’ Proxy drops it after inactivity. Neither side knows.     â”‚
â”‚                                                                 â”‚
â”‚  âŒ Client-side crash or OOM kill                               â”‚
â”‚     â†’ Process died. No cleanup code ran.                        â”‚
â”‚                                                                 â”‚
â”‚  ALL OF THESE leave a GHOST CONNECTION on your server:          â”‚
â”‚  A WebSocket object in your list that is connected to nothing.  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**What does broadcasting to a ghost look like?**

```python
async def broadcast(self, message: str):
    for connection in self.active_connections:
        await connection.send_text(message)
        #     ^^^^^^^^^^^^^^^^^^^^^^^^^^
        #     For a ghost connection, this either:
        #
        #     1. HANGS for minutes (OS TCP timeout, often 15-30 min)
        #        Your broadcast loop is BLOCKED waiting for one ghost.
        #        All other users wait for their messages.
        #
        #     2. Eventually raises an exception (after the OS gives up)
        #        But by then, you've wasted minutes of wall-clock time.
        #
        #     3. Silently succeeds (data goes into OS send buffer)
        #        The ghost stays, memory leaks, buffer fills up.
```

**Ask the class:**

> "Your `broadcast()` iterates through 847 connections. 647 are ghosts. Some hang for 30 seconds each. How long does a single broadcast take?"

> "And this is a chat application â€” broadcasts happen constantly. Every message waits behind dead connections. What does the user experience look like?"

---

## 1.2 Why TCP Doesn't Save You

**Students might wonder: "Doesn't TCP detect dead connections?"**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 TCP KEEPALIVE â€” TOO LITTLE, TOO LATE            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  TCP has a keepalive mechanism. It's almost useless for us.     â”‚
â”‚                                                                 â”‚
â”‚  DEFAULT TCP KEEPALIVE SETTINGS (Linux):                        â”‚
â”‚  â”œâ”€ tcp_keepalive_time:     7200 seconds (2 HOURS!)             â”‚
â”‚  â”‚   "Wait 2 hours of silence before checking"                  â”‚
â”‚  â”œâ”€ tcp_keepalive_intvl:    75 seconds                          â”‚
â”‚  â”‚   "Then send a probe every 75 seconds"                       â”‚
â”‚  â””â”€ tcp_keepalive_probes:   9                                   â”‚
â”‚      "Give up after 9 failed probes"                            â”‚
â”‚                                                                 â”‚
â”‚  TOTAL TIME TO DETECT DEAD CONNECTION:                          â”‚
â”‚  7200 + (75 Ã— 9) = 7875 seconds â‰ˆ 2 hours 11 minutes           â”‚
â”‚                                                                 â”‚
â”‚  For a chat app, 2 hours to detect a ghost is useless.          â”‚
â”‚  You need seconds, not hours.                                   â”‚
â”‚                                                                 â”‚
â”‚  CAN YOU TUNE TCP KEEPALIVE?                                    â”‚
â”‚  Yes, but:                                                      â”‚
â”‚  â”œâ”€ Requires OS-level socket configuration                      â”‚
â”‚  â”œâ”€ Applies globally or per-socket (not per-WebSocket)          â”‚
â”‚  â”œâ”€ Doesn't work through some NATs and proxies                  â”‚
â”‚  â””â”€ Gives you no application-level information                  â”‚
â”‚                                                                 â”‚
â”‚  WE NEED AN APPLICATION-LEVEL SOLUTION.                         â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1.3 The Ping-Pong Protocol

**The solution: actively probe connections from your application code.**

Think of it like a phone call during a long silence:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                THE PHONE CALL ANALOGY                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  WITHOUT HEARTBEAT:                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                             â”‚
â”‚                                                                 â”‚
â”‚  You:    "So about the project..."                              â”‚
â”‚  Them:   "Yeah, let me look into it..."                         â”‚
â”‚  ...                                                            â”‚
â”‚  (45 minutes of silence)                                        â”‚
â”‚  ...                                                            â”‚
â”‚  You:    "Hello? Are you still there?"                          â”‚
â”‚  ...                                                            â”‚
â”‚  You:    "Hello???"                                             â”‚
â”‚  ...                                                            â”‚
â”‚  (They hung up 44 minutes ago.)                                 â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  WITH HEARTBEAT:                                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                               â”‚
â”‚                                                                 â”‚
â”‚  You:    "So about the project..."                              â”‚
â”‚  Them:   "Yeah, let me look into it..."                         â”‚
â”‚  (15 seconds of silence)                                        â”‚
â”‚  You:    "Still there?"                   â† PING                â”‚
â”‚  Them:   "Yep, still looking."            â† PONG                â”‚
â”‚  (15 seconds of silence)                                        â”‚
â”‚  You:    "Still there?"                   â† PING                â”‚
â”‚  ...     (no response for 30 seconds)                           â”‚
â”‚  You:    (hangs up, calls next person)    â† CLOSE               â”‚
â”‚                                                                 â”‚
â”‚  Dead connection detected in under 45 seconds. Not 2 hours.    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Two levels of ping-pong:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              TWO LEVELS OF HEARTBEAT                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  LEVEL 1: PROTOCOL-LEVEL (Uvicorn handles it)                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”‚
â”‚  The WebSocket protocol (RFC 6455) defines ping/pong FRAMES.    â”‚
â”‚  These are special control frames, not regular messages.        â”‚
â”‚  The client MUST respond automatically â€” browser handles it.    â”‚
â”‚                                                                 â”‚
â”‚  Configure in uvicorn:                                          â”‚
â”‚    uvicorn app:app --ws-ping-interval 20 --ws-ping-timeout 20   â”‚
â”‚                                                                 â”‚
â”‚  âœ… Simplest option. Zero application code.                     â”‚
â”‚  âœ… Browser clients respond automatically.                      â”‚
â”‚  âŒ No custom logic (can't track latency, can't log).           â”‚
â”‚  âŒ Not all WebSocket clients handle it correctly.              â”‚
â”‚  âŒ You can't react to a timeout in your code.                  â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  LEVEL 2: APPLICATION-LEVEL (You handle it)                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                     â”‚
â”‚  You send a regular JSON message: {"type": "ping"}              â”‚
â”‚  Client responds with: {"type": "pong"}                         â”‚
â”‚  You track timing yourself.                                     â”‚
â”‚                                                                 â”‚
â”‚  âœ… Full control: custom timeouts, latency tracking, logging.   â”‚
â”‚  âœ… Works with any client (just JSON messages).                 â”‚
â”‚  âœ… Can trigger cleanup logic on timeout.                       â”‚
â”‚  âŒ More code to write and maintain.                            â”‚
â”‚  âŒ Client must implement the pong response.                    â”‚
â”‚                                                                 â”‚
â”‚  IN PRODUCTION: Use BOTH. Uvicorn ping/pong as a safety net,    â”‚
â”‚  application-level heartbeat for control and observability.     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The heartbeat protocol flow:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 HEARTBEAT PROTOCOL                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Server                                            Client       â”‚
â”‚    â”‚                                                  â”‚         â”‚
â”‚    â”‚  (10 seconds of silence)                         â”‚         â”‚
â”‚    â”‚                                                  â”‚         â”‚
â”‚    â”‚â”€â”€â”€ {"type": "ping"} â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚         â”‚
â”‚    â”‚                                                  â”‚         â”‚
â”‚    â”‚â—€â”€â”€ {"type": "pong"} â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚         â”‚
â”‚    â”‚                                                  â”‚         â”‚
â”‚    â”‚  âœ… last_seen updated. Connection alive.         â”‚         â”‚
â”‚    â”‚                                                  â”‚         â”‚
â”‚    â”‚  (10 seconds of silence)                         â”‚         â”‚
â”‚    â”‚                                                  â”‚         â”‚
â”‚    â”‚â”€â”€â”€ {"type": "ping"} â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚         â”‚
â”‚    â”‚                                                  â”‚ â˜ ï¸      â”‚
â”‚    â”‚  (client crashed / lost network)                 â”‚         â”‚
â”‚    â”‚                                                  â”‚         â”‚
â”‚    â”‚  (30 second timeout passes, no pong received)    â”‚         â”‚
â”‚    â”‚                                                  â”‚         â”‚
â”‚    â”‚â”€â”€â”€ close(reason="heartbeat timeout") â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚         â”‚
â”‚    â”‚                                                  â”‚         â”‚
â”‚    â”‚  ğŸ§¹ Clean up: remove from manager, free memory   â”‚         â”‚
â”‚    â”‚                                                  â”‚         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The key insight:**

> "We don't wait for a specific pong message. ANY message from the client proves it's alive. A pong is just a nudge for quiet clients. If the client is actively sending chat messages, those count too â€” no need to wait for pong."

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  "Is the client alive?"                                         â”‚
â”‚                                                                 â”‚
â”‚  Evidence of life = ANY data received from client:              â”‚
â”‚  â”œâ”€ {"type": "pong"}              â† explicit heartbeat reply   â”‚
â”‚  â”œâ”€ {"type": "message", ...}       â† regular chat message      â”‚
â”‚  â”œâ”€ {"type": "typing"}            â† typing indicator            â”‚
â”‚  â””â”€ Any bytes at all               â† the connection is alive    â”‚
â”‚                                                                 â”‚
â”‚  The ping is just a PROMPT for idle connections.                â”‚
â”‚  Active connections prove themselves naturally.                  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1.4 Building a Heartbeat Monitor

**Let's build this into the connection manager from Lecture 1.**

First, a connection wrapper that tracks liveness:

```python
# heartbeat.py
import asyncio
import time
import logging
from fastapi import WebSocket

logger = logging.getLogger(__name__)


class HeartbeatConnection:
    """Wraps a WebSocket with heartbeat monitoring."""

    def __init__(
        self,
        websocket: WebSocket,
        *,
        ping_interval: float = 15.0,   # Send ping every 15s
        timeout: float = 45.0,         # Dead if silent for 45s
    ):
        self.websocket = websocket
        self.ping_interval = ping_interval
        self.timeout = timeout
        self.last_seen: float = time.time()
        self._heartbeat_task: asyncio.Task | None = None

    def mark_alive(self) -> None:
        """Call on ANY message received from client."""
        self.last_seen = time.time()

    @property
    def is_alive(self) -> bool:
        return (time.time() - self.last_seen) < self.timeout

    @property
    def latency(self) -> float:
        """Seconds since we last heard from this client."""
        return time.time() - self.last_seen

    async def start(self) -> None:
        """Start the background heartbeat loop."""
        self._heartbeat_task = asyncio.create_task(self._heartbeat_loop())

    async def stop(self) -> None:
        """Cancel the heartbeat loop."""
        if self._heartbeat_task is not None:
            self._heartbeat_task.cancel()
            try:
                await self._heartbeat_task
            except asyncio.CancelledError:
                pass

    async def _heartbeat_loop(self) -> None:
        """Periodically ping the client and check for timeout."""
        try:
            while True:
                await asyncio.sleep(self.ping_interval)

                # â”€â”€ Check: has client spoken recently? â”€â”€
                if not self.is_alive:
                    logger.warning(
                        "Heartbeat timeout for connection "
                        f"(silent for {self.latency:.1f}s)"
                    )
                    await self.websocket.close(
                        code=1000,
                        reason="Heartbeat timeout",
                    )
                    return  # Exit the loop â€” connection is dead

                # â”€â”€ Still alive: send a ping â”€â”€
                try:
                    await self.websocket.send_json({"type": "ping"})
                except Exception:
                    return  # Connection already broken

        except asyncio.CancelledError:
            pass  # Clean shutdown
```

**Walk through the design decisions:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 DESIGN DECISIONS EXPLAINED                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Q: Why ping_interval=15, timeout=45?                           â”‚
â”‚  A: Timeout should be > 2Ã— ping_interval.                       â”‚
â”‚     This gives the client at least 2 chances to respond.        â”‚
â”‚     If they miss one ping (network hiccup), they aren't         â”‚
â”‚     immediately killed. If they miss three, they're dead.       â”‚
â”‚                                                                 â”‚
â”‚       ping    ping    ping                                      â”‚
â”‚        â”‚       â”‚       â”‚                                        â”‚
â”‚     0s â”œâ”€â”€15sâ”€â”€â”œâ”€â”€30sâ”€â”€â”œâ”€â”€45s  â† timeout here                   â”‚
â”‚        â”‚       â”‚       â”‚       â”‚                                â”‚
â”‚        â””â”€â”€ 3 chances to respond before being declared dead      â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  Q: Why mark_alive() on ANY message, not just pong?             â”‚
â”‚  A: An active user sending chat messages IS alive.              â”‚
â”‚     Requiring a separate pong from active users is wasteful.    â”‚
â”‚     The ping is only needed to poke IDLE connections.           â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  Q: Why a separate asyncio.Task? (Connection to Week 1)         â”‚
â”‚  A: The main receive loop (while True: await ws.receive())      â”‚
â”‚     blocks until a message arrives. We can't also check         â”‚
â”‚     timeouts in that same loop. create_task() lets the          â”‚
â”‚     heartbeat run concurrently alongside the receive loop.      â”‚
â”‚     Same pattern as asyncio.gather â€” two tasks, one thread.     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Now integrate it into a WebSocket endpoint:**

```python
# main.py
from fastapi import FastAPI, WebSocket, WebSocketDisconnect

from heartbeat import HeartbeatConnection
from manager import ConnectionManager   # Your room-based manager from Lecture 1

app = FastAPI()
manager = ConnectionManager()


@app.websocket("/ws/{room}")
async def websocket_endpoint(websocket: WebSocket, room: str):
    await websocket.accept()

    # â”€â”€ Wrap connection with heartbeat monitoring â”€â”€
    conn = HeartbeatConnection(websocket, ping_interval=15.0, timeout=45.0)
    manager.add(room, conn)
    await conn.start()

    try:
        while True:
            data = await websocket.receive_json()

            # â”€â”€ ANY message proves the client is alive â”€â”€
            conn.mark_alive()

            # â”€â”€ Handle heartbeat pong (no further processing) â”€â”€
            if data.get("type") == "pong":
                continue

            # â”€â”€ Handle regular messages â”€â”€
            await manager.broadcast(room, data)

    except WebSocketDisconnect:
        pass
    finally:
        # â”€â”€ Always clean up, no matter how we exit â”€â”€
        await conn.stop()
        manager.remove(room, conn)
```

**Visualize the two concurrent tasks in the endpoint:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       TWO CONCURRENT TASKS PER CONNECTION                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  When a client connects, two tasks run concurrently:            â”‚
â”‚  (Remember asyncio.create_task from Week 1)                     â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  TASK 1: Message Receive Loop (the endpoint function)           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”‚
â”‚  while True:                                                    â”‚
â”‚      data = await websocket.receive_json()   â† paused here     â”‚
â”‚      conn.mark_alive()                                          â”‚
â”‚      if data["type"] == "pong": continue                        â”‚
â”‚      await manager.broadcast(room, data)                        â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  TASK 2: Heartbeat Loop (the background task)                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                     â”‚
â”‚  while True:                                                    â”‚
â”‚      await asyncio.sleep(15)                 â† paused here      â”‚
â”‚      if not self.is_alive:                                      â”‚
â”‚          await websocket.close()                                â”‚
â”‚          return                                                 â”‚
â”‚      await websocket.send_json({"type": "ping"})                â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  These alternate on the event loop:                             â”‚
â”‚                                                                 â”‚
â”‚  Time: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶             â”‚
â”‚  Task1: [await recv]          [recv,broadcast]  [await recv]    â”‚
â”‚  Task2:             [sleep 15s]               [check+ping]      â”‚
â”‚                                                                 â”‚
â”‚  Single thread, cooperative multitasking. Week 1 in action.     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Updated ConnectionManager that works with HeartbeatConnection:**

```python
# manager.py
import asyncio
import logging
from heartbeat import HeartbeatConnection

logger = logging.getLogger(__name__)


class ConnectionManager:
    """Room-based connection manager with ghost-safe broadcasting."""

    def __init__(self):
        self._rooms: dict[str, set[HeartbeatConnection]] = {}

    def add(self, room: str, conn: HeartbeatConnection) -> None:
        if room not in self._rooms:
            self._rooms[room] = set()
        self._rooms[room].add(conn)

    def remove(self, room: str, conn: HeartbeatConnection) -> None:
        if room in self._rooms:
            self._rooms[room].discard(conn)
            if not self._rooms[room]:
                del self._rooms[room]

    async def broadcast(self, room: str, message: dict) -> None:
        """Broadcast to all live connections in a room."""
        if room not in self._rooms:
            return

        dead: list[HeartbeatConnection] = []

        for conn in self._rooms[room]:
            try:
                await conn.websocket.send_json(message)
            except Exception:
                dead.append(conn)

        # â”€â”€ Clean up any ghosts discovered during broadcast â”€â”€
        for conn in dead:
            logger.info("Removing ghost connection found during broadcast")
            await conn.stop()
            self.remove(room, conn)

    @property
    def total_connections(self) -> int:
        return sum(len(conns) for conns in self._rooms.values())

    @property
    def room_count(self) -> int:
        return len(self._rooms)
```

**Before moving on, summarize what heartbeat solves:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              HEARTBEAT RESULTS                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  WITHOUT HEARTBEAT:                                             â”‚
â”‚  â”œâ”€ Ghost detection: 0 â€“ 2+ hours (TCP keepalive default)      â”‚
â”‚  â”œâ”€ Memory: unbounded growth from ghost connections             â”‚
â”‚  â”œâ”€ Broadcast: slows down, may hang on dead sockets             â”‚
â”‚  â””â”€ Connection count: unreliable (ghosts inflate the number)    â”‚
â”‚                                                                 â”‚
â”‚  WITH HEARTBEAT (15s interval, 45s timeout):                    â”‚
â”‚  â”œâ”€ Ghost detection: 45 seconds max                             â”‚
â”‚  â”œâ”€ Memory: bounded, dead connections cleaned promptly          â”‚
â”‚  â”œâ”€ Broadcast: fast, only reaches live connections              â”‚
â”‚  â””â”€ Connection count: accurate, trustworthy for monitoring      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# PART 2: SURVIVING DISCONNECTIONS

## 2.1 Why Connections Drop (The Real World)

**Heartbeat detects ghosts. But disconnections aren't always permanent.**

> "Your user is on a train. They go through a tunnel â€” connection drops. 10 seconds later, they're out of the tunnel and their client reconnects. In those 10 seconds, 15 messages were sent in their group chat. What do they see when they reconnect?"

> "Nothing. Those 15 messages are gone. Your server broadcast them to the old (now dead) connection object. The new connection starts fresh."

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            DISCONNECTIONS ARE NORMAL, NOT EXCEPTIONAL           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  TEMPORARY DISCONNECTIONS (seconds to minutes):                 â”‚
â”‚  â”œâ”€ Tunnel, elevator, parking garage (signal loss)              â”‚
â”‚  â”œâ”€ Wifi â†’ cellular handoff (new IP, old connection dead)       â”‚
â”‚  â”œâ”€ ISP hiccup (brief routing failure)                          â”‚
â”‚  â””â”€ Client-side JS garbage collection stall (rare, but real)    â”‚
â”‚                                                                 â”‚
â”‚  MEDIUM DISCONNECTIONS (minutes to hours):                      â”‚
â”‚  â”œâ”€ Laptop lid closed on commute (sleep mode)                   â”‚
â”‚  â”œâ”€ Phone screen off for a while (OS kills background sockets)  â”‚
â”‚  â””â”€ Network change (switching between wifi networks)            â”‚
â”‚                                                                 â”‚
â”‚  PERMANENT DISCONNECTIONS:                                      â”‚
â”‚  â”œâ”€ User navigates away / closes tab                            â”‚
â”‚  â”œâ”€ Client crash                                                â”‚
â”‚  â””â”€ User explicitly logs out                                    â”‚
â”‚                                                                 â”‚
â”‚  A ROBUST SYSTEM handles ALL of these gracefully.               â”‚
â”‚  Temporary drops should be INVISIBLE to the user.               â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2.2 Reconnection from the Server's Perspective

**Reconnection is a CLIENT-SIDE behavior. But the server must SUPPORT it.**

The client's job (you should know this exists, even though you're writing the backend):

```javascript
// CLIENT SIDE (JavaScript, for your awareness)
// A minimal reconnecting WebSocket â€” this is what your client does.

class ReconnectingSocket {
    constructor(url) {
        this.url = url;
        this.lastMessageId = null;  // Track the last message we saw
        this.attempt = 0;
        this.connect();
    }

    connect() {
        // On reconnect, tell the server what we last received
        const params = this.lastMessageId
            ? `?last_message_id=${this.lastMessageId}`
            : "";
        this.ws = new WebSocket(this.url + params);

        this.ws.onmessage = (event) => {
            const data = JSON.parse(event.data);
            if (data.id) this.lastMessageId = data.id;
        };

        this.ws.onclose = () => {
            // Exponential backoff: 1s, 2s, 4s, 8s, ..., max 30s
            const delay = Math.min(1000 * 2 ** this.attempt, 30000);
            this.attempt++;
            setTimeout(() => this.connect(), delay);
        };

        this.ws.onopen = () => {
            this.attempt = 0;  // Reset backoff on successful connect
        };
    }
}
```

**The server's job â€” what YOU build:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          SERVER'S RECONNECTION RESPONSIBILITIES                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. ACCEPT last_message_id from reconnecting clients            â”‚
â”‚     "Where did you leave off?"                                  â”‚
â”‚                                                                 â”‚
â”‚  2. REPLAY missed messages since that ID                        â”‚
â”‚     "Here's everything you missed."                             â”‚
â”‚                                                                 â”‚
â”‚  3. ASSIGN every message a sequential ID                        â”‚
â”‚     So clients can track their position.                        â”‚
â”‚                                                                 â”‚
â”‚  4. BUFFER recent messages (for replay on reconnection)         â”‚
â”‚     Can't replay if you didn't store them.                      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2.3 Missed Message Recovery

**Use Redis (Week 10) as a short-term message buffer.**

> "We're not building a permanent message history â€” that's your PostgreSQL database's job. We're building a SHORT-TERM buffer for reconnection recovery. Messages live in Redis for a few minutes, long enough for a tunnel or elevator ride."

```python
# message_buffer.py
import json
import redis.asyncio as redis      # Week 10 â€” you know this


class MessageBuffer:
    """
    Short-term message buffer in Redis for reconnection recovery.

    Uses a Redis Sorted Set per room:
      - Score  = message ID (auto-incrementing)
      - Value  = JSON message payload
    Automatically trims old messages to bound memory.
    """

    def __init__(
        self,
        redis_client: redis.Redis,
        max_messages: int = 500,     # Keep last 500 messages per room
        ttl: int = 300,              # Expire after 5 minutes
    ):
        self._redis = redis_client
        self._max_messages = max_messages
        self._ttl = ttl

    async def store(self, room: str, message: dict) -> int:
        """Store a message. Returns the assigned message ID."""
        key = f"buffer:{room}"

        # â”€â”€ Assign a sequential ID â”€â”€
        msg_id = await self._redis.incr(f"buffer:{room}:seq")
        message["id"] = msg_id

        # â”€â”€ Store in sorted set (score = ID for ordering) â”€â”€
        await self._redis.zadd(key, {json.dumps(message): msg_id})

        # â”€â”€ Trim to max_messages (remove oldest) â”€â”€
        await self._redis.zremrangebyrank(key, 0, -(self._max_messages + 1))

        # â”€â”€ Reset TTL (keep alive while room is active) â”€â”€
        await self._redis.expire(key, self._ttl)

        return msg_id

    async def get_since(self, room: str, since_id: int) -> list[dict]:
        """Get all messages with ID > since_id."""
        key = f"buffer:{room}"

        # Sorted set range by score: (since_id, +inf)
        raw_messages = await self._redis.zrangebyscore(
            key,
            min=since_id + 1,    # Exclusive of since_id
            max="+inf",
        )

        return [json.loads(msg) for msg in raw_messages]
```

**Integrate into the WebSocket endpoint:**

```python
@app.websocket("/ws/{room}")
async def websocket_endpoint(
    websocket: WebSocket,
    room: str,
    last_message_id: int | None = None,  # Query param from reconnecting client
):
    await websocket.accept()

    # â”€â”€ Replay missed messages on reconnection â”€â”€
    if last_message_id is not None:
        missed = await message_buffer.get_since(room, last_message_id)
        for msg in missed:
            await websocket.send_json(msg)

    conn = HeartbeatConnection(websocket)
    manager.add(room, conn)
    await conn.start()

    try:
        while True:
            data = await websocket.receive_json()
            conn.mark_alive()

            if data.get("type") == "pong":
                continue

            # â”€â”€ Store message in buffer BEFORE broadcasting â”€â”€
            msg_id = await message_buffer.store(room, data)

            # â”€â”€ Broadcast (now includes the "id" field) â”€â”€
            await manager.broadcast(room, data)

    except WebSocketDisconnect:
        pass
    finally:
        await conn.stop()
        manager.remove(room, conn)
```

**The reconnection flow, end to end:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              RECONNECTION FLOW                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  FIRST CONNECTION:                                              â”‚
â”‚                                                                 â”‚
â”‚  Client â”€â”€â”€â”€ ws://server/ws/room1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Server       â”‚
â”‚              (no last_message_id)                                â”‚
â”‚  Client â—€â”€â”€â”€â”€ messages: id=1, id=2, id=3 â”€â”€â”€â”€â”€â”€ Server         â”‚
â”‚                                                                 â”‚
â”‚  Client tracks: lastMessageId = 3                               â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  DISCONNECTION (tunnel):                                        â”‚
â”‚                                                                 â”‚
â”‚  Client â”€ â”€ â”€ â•³ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€   Server         â”‚
â”‚                                                                 â”‚
â”‚  Meanwhile, server broadcasts id=4, id=5, id=6 to others.      â”‚
â”‚  Messages are stored in Redis buffer.                           â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  RECONNECTION:                                                  â”‚
â”‚                                                                 â”‚
â”‚  Client â”€â”€â”€â”€ ws://server/ws/room1?last_message_id=3 â”€â”€â–¶ Server  â”‚
â”‚                                                                 â”‚
â”‚  Server: "Since ID 3? Let me check the buffer..."               â”‚
â”‚  Server: buffer.get_since("room1", 3) â†’ [msg4, msg5, msg6]     â”‚
â”‚                                                                 â”‚
â”‚  Client â—€â”€â”€â”€â”€ replay: id=4, id=5, id=6 â”€â”€â”€â”€â”€â”€â”€ Server          â”‚
â”‚  Client â—€â”€â”€â”€â”€ live: id=7, id=8, ... â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Server         â”‚
â”‚                                                                 â”‚
â”‚  SEAMLESS. User sees no gap.                                    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2.4 Grace Periods and State Cleanup

**Don't immediately destroy user state on disconnect.**

> "When a connection drops, you don't know yet if it's temporary or permanent. Don't erase the user's room memberships, cursor position, or typing status instantly. Give them a grace period to come back."

```python
# graceful_state.py
import asyncio
import time
import logging

logger = logging.getLogger(__name__)


class UserPresence:
    """Track user state with a grace period after disconnect."""

    GRACE_PERIOD: float = 60.0  # 1 minute to reconnect

    def __init__(self):
        # user_id â†’ state
        self._states: dict[int, dict] = {}
        # user_id â†’ cleanup task
        self._cleanup_tasks: dict[int, asyncio.Task] = {}

    async def user_connected(self, user_id: int, rooms: set[str]) -> set[str]:
        """
        Handle a user connecting (or reconnecting).
        Returns rooms to rejoin if this is a reconnection.
        """
        if user_id in self._states:
            # â”€â”€ RECONNECTION: cancel pending cleanup, restore state â”€â”€
            if user_id in self._cleanup_tasks:
                self._cleanup_tasks[user_id].cancel()
                del self._cleanup_tasks[user_id]
                logger.info(f"User {user_id} reconnected within grace period")

            state = self._states[user_id]
            state["status"] = "connected"
            state["disconnected_at"] = None
            return state["rooms"]  # Return rooms they were in

        # â”€â”€ NEW CONNECTION: create fresh state â”€â”€
        self._states[user_id] = {
            "status": "connected",
            "rooms": rooms,
            "disconnected_at": None,
        }
        return set()  # No rooms to rejoin

    async def user_disconnected(self, user_id: int) -> None:
        """Mark user as disconnected. Start the grace period countdown."""
        if user_id not in self._states:
            return

        self._states[user_id]["status"] = "disconnected"
        self._states[user_id]["disconnected_at"] = time.time()

        # â”€â”€ Start a cleanup timer instead of removing immediately â”€â”€
        self._cleanup_tasks[user_id] = asyncio.create_task(
            self._delayed_cleanup(user_id)
        )

    async def _delayed_cleanup(self, user_id: int) -> None:
        """Wait for grace period, then remove state if still disconnected."""
        await asyncio.sleep(self.GRACE_PERIOD)

        if (
            user_id in self._states
            and self._states[user_id]["status"] == "disconnected"
        ):
            del self._states[user_id]
            del self._cleanup_tasks[user_id]
            logger.info(f"User {user_id} grace period expired. State removed.")
```

**Visualize the timeline:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 GRACE PERIOD TIMELINE                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  CASE 1: User reconnects within grace period                    â”‚
â”‚                                                                 â”‚
â”‚  0s          15s                    45s            60s           â”‚
â”‚  â”‚           â”‚                      â”‚              â”‚            â”‚
â”‚  disconnect  â”‚   reconnect!         â”‚              â”‚            â”‚
â”‚  â”‚           â”‚   â”‚                  â”‚              â”‚            â”‚
â”‚  [â”€â”€â”€â”€ grace period (cleanup scheduled) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€]          â”‚
â”‚              â–²   â–²                                              â”‚
â”‚              â”‚   â””â”€â”€ Cleanup CANCELLED. State restored.         â”‚
â”‚              â”‚       User rejoins rooms seamlessly.             â”‚
â”‚              â”‚                                                  â”‚
â”‚                                                                 â”‚
â”‚  CASE 2: User doesn't come back                                â”‚
â”‚                                                                 â”‚
â”‚  0s                                                60s          â”‚
â”‚  â”‚                                                  â”‚           â”‚
â”‚  disconnect                                     cleanup runs    â”‚
â”‚  â”‚                                                  â”‚           â”‚
â”‚  [â”€â”€â”€â”€ grace period â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€]           â”‚
â”‚                                                     â–²           â”‚
â”‚                                     State removed. Memory freed.â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# PART 3: THE SCALING WALL

## 3.1 One Server Works, Two Servers Break

**Everything you've built so far has a hidden assumption: one server.**

> "Your chat app is growing. One server handles 1000 connections. You need to support 10,000. Natural instinct: run more servers behind a load balancer. You spin up 3 instances. What breaks?"

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              THE SINGLE-SERVER ILLUSION                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  ONE SERVER (everything works):                                 â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚           SERVER (1 instance)          â”‚                     â”‚
â”‚  â”‚                                        â”‚                     â”‚
â”‚  â”‚  ConnectionManager                     â”‚                     â”‚
â”‚  â”‚  â”œâ”€ room "general": [Alice, Bob, Eve]  â”‚                     â”‚
â”‚  â”‚  â””â”€ room "random":  [Bob, Charlie]     â”‚                     â”‚
â”‚  â”‚                                        â”‚                     â”‚
â”‚  â”‚  Alice sends "hello" â†’ broadcast to    â”‚                     â”‚
â”‚  â”‚  all 3 in "general" â†’ âœ… everyone      â”‚                     â”‚
â”‚  â”‚  receives it                           â”‚                     â”‚
â”‚  â”‚                                        â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                                 â”‚
â”‚  Works perfectly. The ConnectionManager has ALL connections.    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Now scale to 3 servers:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              THREE SERVERS (broadcasting breaks):               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                    â”‚ Load Balancerâ”‚                              â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚               â–¼           â–¼           â–¼                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚   Server 1     â”‚ â”‚   Server 2     â”‚ â”‚   Server 3     â”‚       â”‚
â”‚  â”‚                â”‚ â”‚                â”‚ â”‚                â”‚       â”‚
â”‚  â”‚ ConnectionMgr  â”‚ â”‚ ConnectionMgr  â”‚ â”‚ ConnectionMgr  â”‚       â”‚
â”‚  â”‚ room "general":â”‚ â”‚ room "general":â”‚ â”‚ room "general":â”‚       â”‚
â”‚  â”‚   [Alice]      â”‚ â”‚   [Bob]        â”‚ â”‚   [Eve]        â”‚       â”‚
â”‚  â”‚                â”‚ â”‚                â”‚ â”‚                â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                 â”‚
â”‚  Alice sends "hello" on Server 1.                               â”‚
â”‚  Server 1's ConnectionManager broadcasts to its room "general". â”‚
â”‚  Server 1's room "general" has: [Alice].                        â”‚
â”‚                                                                 â”‚
â”‚  âŒ Bob (Server 2) never sees it.                               â”‚
â”‚  âŒ Eve (Server 3) never sees it.                               â”‚
â”‚  âŒ Only Alice sees her own message.                            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ask the class:**

> "The ConnectionManager is an in-memory Python object. It only knows about connections on ITS process. Server 1 has no idea Server 2 exists. How do you make Server 1's message reach Bob on Server 2?"

---

## 3.2 The Architecture Shift

**The problem is that our ConnectionManager is LOCAL. We need a SHARED communication layer between servers.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                THE CORE INSIGHT                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  LOCAL ConnectionManager:                                       â”‚
â”‚                                                                 â”‚
â”‚    Server 1:  "Send to room general"                            â”‚
â”‚               â†’ sends to Server 1's connections only            â”‚
â”‚               â†’ other servers don't know                        â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  What we NEED:                                                  â”‚
â”‚                                                                 â”‚
â”‚    Server 1:  "Send to room general"                            â”‚
â”‚               â†’ publishes to a SHARED channel                   â”‚
â”‚               â†’ ALL servers receive it                          â”‚
â”‚               â†’ each server sends to ITS local connections      â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  The shared channel is a MESSAGE BUS.                           â”‚
â”‚  You already know the perfect tool: Redis Pub/Sub (Week 11).   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The architecture:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           REDIS PUB/SUB AS MESSAGE BUS                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚               â”‚ Load Balancerâ”‚                                  â”‚
â”‚               â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚          â–¼           â–¼           â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚  â”‚ Server 1 â”‚ â”‚ Server 2 â”‚ â”‚ Server 3 â”‚                         â”‚
â”‚  â”‚ [Alice]  â”‚ â”‚ [Bob]    â”‚ â”‚ [Eve]    â”‚                         â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚       â”‚            â”‚            â”‚                               â”‚
â”‚       â”‚    subscribe("room:general")                            â”‚
â”‚       â”‚            â”‚            â”‚                               â”‚
â”‚       â–¼            â–¼            â–¼                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚              REDIS                       â”‚                    â”‚
â”‚  â”‚                                         â”‚                    â”‚
â”‚  â”‚  Channel: "room:general"                â”‚                    â”‚
â”‚  â”‚  Subscribers: Server 1, Server 2, 3     â”‚                    â”‚
â”‚  â”‚                                         â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  FLOW when Alice sends a message:                               â”‚
â”‚                                                                 â”‚
â”‚  1. Alice's WS message arrives at Server 1                      â”‚
â”‚  2. Server 1 PUBLISHES to Redis channel "room:general"          â”‚
â”‚  3. Redis delivers to ALL subscribers (Server 1, 2, 3)          â”‚
â”‚  4. Each server broadcasts to ITS LOCAL connections             â”‚
â”‚     â”œâ”€ Server 1 â†’ sends to Alice  âœ…                            â”‚
â”‚     â”œâ”€ Server 2 â†’ sends to Bob    âœ…                            â”‚
â”‚     â””â”€ Server 3 â†’ sends to Eve    âœ…                            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3.3 Redis Pub/Sub as the Backbone (Connection to Week 11)

> "In Week 11, you learned Redis Pub/Sub for event-driven architecture â€” decoupling producers from consumers. This is the exact same pattern. The producer is 'the server that received a WebSocket message.' The consumers are 'all servers that have connections in that room.'"

**Quick recall â€” Redis Pub/Sub operations:**

```python
import redis.asyncio as redis

r = redis.from_url("redis://localhost:6379")

# Publisher (any server)
await r.publish("room:general", '{"user":"Alice","text":"hello"}')

# Subscriber (all servers)
pubsub = r.pubsub()
await pubsub.subscribe("room:general")

async for message in pubsub.listen():
    if message["type"] == "message":
        channel = message["channel"]   # b"room:general"
        data = message["data"]         # b'{"user":"Alice","text":"hello"}'
```

**That's it. You already know the primitive. Now we wire it into the ConnectionManager.**

---

## 3.4 Implementing Cross-Server Broadcasting

**Replace the local-only ConnectionManager with a Redis-backed version:**

```python
# scalable_manager.py
import asyncio
import json
import logging
from typing import Any

import redis.asyncio as redis
from fastapi import WebSocket

logger = logging.getLogger(__name__)


class ScalableConnectionManager:
    """
    Connection manager that works across multiple server instances.

    Architecture:
      - Each server keeps a LOCAL set of WebSocket connections (in-memory).
      - Broadcasting goes THROUGH Redis Pub/Sub, not directly to sockets.
      - A background listener task receives Redis messages and
        forwards them to local connections.

    This means:
      Server 1 publishes â†’ Redis â†’ Server 1, 2, 3 receive â†’ local broadcast
    """

    def __init__(self, redis_url: str = "redis://localhost:6379"):
        self._redis = redis.from_url(redis_url)
        self._pubsub = self._redis.pubsub()
        self._local_rooms: dict[str, set[WebSocket]] = {}
        self._listener_task: asyncio.Task | None = None

    # â”€â”€ Lifecycle: call on app startup/shutdown â”€â”€

    async def start(self) -> None:
        """Start the Redis listener. Call during FastAPI lifespan."""
        self._listener_task = asyncio.create_task(self._redis_listener())
        logger.info("ScalableConnectionManager started")

    async def stop(self) -> None:
        """Stop listening and close Redis. Call during FastAPI lifespan."""
        if self._listener_task:
            self._listener_task.cancel()
            try:
                await self._listener_task
            except asyncio.CancelledError:
                pass
        await self._pubsub.aclose()
        await self._redis.aclose()
        logger.info("ScalableConnectionManager stopped")

    # â”€â”€ Connection management (local) â”€â”€

    async def connect(self, room: str, websocket: WebSocket) -> None:
        await websocket.accept()

        if room not in self._local_rooms:
            self._local_rooms[room] = set()
            # Subscribe to Redis channel for this room
            await self._pubsub.subscribe(f"room:{room}")
            logger.info(f"Subscribed to Redis channel room:{room}")

        self._local_rooms[room].add(websocket)

    async def disconnect(self, room: str, websocket: WebSocket) -> None:
        if room in self._local_rooms:
            self._local_rooms[room].discard(websocket)

            # Unsubscribe if no local connections left in this room
            if not self._local_rooms[room]:
                del self._local_rooms[room]
                await self._pubsub.unsubscribe(f"room:{room}")
                logger.info(f"Unsubscribed from Redis channel room:{room}")

    # â”€â”€ Publishing (goes through Redis, not direct to sockets) â”€â”€

    async def publish(self, room: str, message: dict[str, Any]) -> None:
        """
        Publish a message to a room.
        This does NOT send directly to WebSockets.
        It publishes to Redis. The listener picks it up.
        """
        await self._redis.publish(f"room:{room}", json.dumps(message))

    # â”€â”€ Local broadcast (called by listener, not by application code) â”€â”€

    async def _broadcast_local(self, room: str, raw_message: str) -> None:
        """Send a message to all LOCAL connections in a room."""
        if room not in self._local_rooms:
            return

        dead: list[WebSocket] = []
        for ws in self._local_rooms[room]:
            try:
                await ws.send_text(raw_message)
            except Exception:
                dead.append(ws)

        for ws in dead:
            self._local_rooms[room].discard(ws)

    # â”€â”€ Redis listener (the bridge between servers) â”€â”€

    async def _redis_listener(self) -> None:
        """
        Background task: listen for messages on subscribed Redis
        channels and forward to local WebSocket connections.

        This is the CORE of cross-server broadcasting.
        """
        try:
            async for message in self._pubsub.listen():
                if message["type"] != "message":
                    continue  # Skip subscribe/unsubscribe confirmations

                channel: str = message["channel"].decode()
                room = channel.removeprefix("room:")
                data: str = message["data"].decode()

                await self._broadcast_local(room, data)

        except asyncio.CancelledError:
            pass  # Clean shutdown
        except Exception as e:
            logger.error(f"Redis listener error: {e}")
            # In production: restart the listener or alert
```

**Wire it into FastAPI using lifespan (you know this from Week 8):**

```python
# main.py
from contextlib import asynccontextmanager
from fastapi import FastAPI, WebSocket, WebSocketDisconnect

from scalable_manager import ScalableConnectionManager

manager = ScalableConnectionManager(redis_url="redis://localhost:6379")


@asynccontextmanager
async def lifespan(app: FastAPI):
    # â”€â”€ Startup â”€â”€
    await manager.start()
    yield
    # â”€â”€ Shutdown â”€â”€
    await manager.stop()


app = FastAPI(lifespan=lifespan)


@app.websocket("/ws/{room}")
async def websocket_endpoint(websocket: WebSocket, room: str):
    await manager.connect(room, websocket)
    try:
        while True:
            data = await websocket.receive_json()

            if data.get("type") == "pong":
                continue

            # â”€â”€ Publish through Redis, NOT direct broadcast â”€â”€
            await manager.publish(room, data)
            # The _redis_listener will pick this up and
            # _broadcast_local to all connections on every server.

    except WebSocketDisconnect:
        pass
    finally:
        await manager.disconnect(room, websocket)
```

**Walk through the flow one more time, in code:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              MESSAGE FLOW THROUGH THE SYSTEM                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Alice (Server 1) sends {"text": "hello"}                       â”‚
â”‚                                                                 â”‚
â”‚  â‘  websocket_endpoint receives it                               â”‚
â”‚     data = await websocket.receive_json()                       â”‚
â”‚                                                                 â”‚
â”‚  â‘¡ endpoint calls manager.publish("general", data)              â”‚
â”‚     This does: redis.publish("room:general", json.dumps(data))  â”‚
â”‚     NOTE: It does NOT send to WebSockets directly.              â”‚
â”‚                                                                 â”‚
â”‚  â‘¢ Redis delivers to ALL subscribers of "room:general"          â”‚
â”‚     â”œâ”€ Server 1's _redis_listener receives it                   â”‚
â”‚     â”œâ”€ Server 2's _redis_listener receives it                   â”‚
â”‚     â””â”€ Server 3's _redis_listener receives it                   â”‚
â”‚                                                                 â”‚
â”‚  â‘£ Each server's _redis_listener calls _broadcast_local()       â”‚
â”‚     â”œâ”€ Server 1 â†’ sends to Alice   âœ…                           â”‚
â”‚     â”œâ”€ Server 2 â†’ sends to Bob     âœ…                           â”‚
â”‚     â””â”€ Server 3 â†’ sends to Eve     âœ…                           â”‚
â”‚                                                                 â”‚
â”‚  RESULT: Every user in "general" gets the message,              â”‚
â”‚  regardless of which server they're connected to.               â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Important: the server that PUBLISHED also RECEIVES its own message through Redis.** This is intentional. It simplifies the code â€” there's one broadcast path, not two. The trade-off is a tiny bit of extra latency for the sender's own echo, but the architectural simplicity is worth it.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                SCALING CONSIDERATIONS                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Redis Pub/Sub limitations you should know:                     â”‚
â”‚                                                                 â”‚
â”‚  â”œâ”€ NO PERSISTENCE: If a server is down when a message is       â”‚
â”‚  â”‚   published, it misses it forever. Pub/Sub is fire-and-      â”‚
â”‚  â”‚   forget. (That's why we have the message buffer in Part 2.) â”‚
â”‚  â”‚                                                              â”‚
â”‚  â”œâ”€ SINGLE REDIS: If Redis itself goes down, broadcasting       â”‚
â”‚  â”‚   stops across all servers. Redis is a single point of       â”‚
â”‚  â”‚   failure here. (Redis Sentinel/Cluster for production.)     â”‚
â”‚  â”‚                                                              â”‚
â”‚  â””â”€ SCALING LIMIT: With thousands of rooms and millions of      â”‚
â”‚      messages, a single Redis instance may bottleneck. At that  â”‚
â”‚      scale, look at Redis Cluster or dedicated tools like Kafka â”‚
â”‚      (Week 11 awareness).                                       â”‚
â”‚                                                                 â”‚
â”‚  For most applications (< 100K concurrent connections),         â”‚
â”‚  a single Redis instance handles this trivially.                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# PART 4: SERVER-SENT EVENTS â€” THE SIMPLER TOOL

## 4.1 Not Everything Needs WebSocket

**Pause. Step back. Consider this scenario from your capstone project (Week 13-14):**

> "A user triggers a CSV export as a background Celery job (Week 11). The UI shows a progress bar. The server pushes progress updates: 10%, 25%, 50%, 100%, done. The user never sends anything back."

> "You reach for WebSocket. But think: the client never sends a message after connecting. It only LISTENS. You've opened a two-way communication channel to send data in ONE direction. That's like renting a walkie-talkie set for two people when one of them only ever listens."

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PUSH-ONLY USE CASES                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  These scenarios only need SERVER â†’ CLIENT:                     â”‚
â”‚                                                                 â”‚
â”‚  â”œâ”€ Progress updates (background job: 10%, 25%, 50%, done)      â”‚
â”‚  â”œâ”€ Live notifications (new comment, new follower)              â”‚
â”‚  â”œâ”€ Dashboard metrics (live request count, CPU usage)           â”‚
â”‚  â”œâ”€ Stock ticker / price feed                                   â”‚
â”‚  â”œâ”€ News feed updates                                           â”‚
â”‚  â””â”€ Log streaming (tail -f in the browser)                      â”‚
â”‚                                                                 â”‚
â”‚  For ALL of these, Server-Sent Events (SSE) is simpler,        â”‚
â”‚  lighter, and arguably better than WebSocket.                   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4.2 How SSE Works (Protocol and Format)

**SSE uses plain HTTP. No upgrade, no new protocol. Just a long-lived GET request with a special content type.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SSE vs WEBSOCKET PROTOCOL                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  WEBSOCKET:                                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                     â”‚
â”‚  Client: GET /ws (with Upgrade: websocket header)               â”‚
â”‚  Server: 101 Switching Protocols                                â”‚
â”‚  â†’ New protocol. Bidirectional frames.                          â”‚
â”‚  â†’ Requires special server support.                             â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  SSE (Server-Sent Events):                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚  Client: GET /events (Accept: text/event-stream)                â”‚
â”‚  Server: 200 OK (Content-Type: text/event-stream)               â”‚
â”‚  â†’ Standard HTTP. Server keeps sending data.                    â”‚
â”‚  â†’ Works with any HTTP server. No upgrade.                      â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  SSE is just an HTTP response that NEVER ENDS.                  â”‚
â”‚  The server keeps writing to the response body.                 â”‚
â”‚  Each "write" is an event the client receives.                  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The SSE data format is simple text:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  SSE EVENT FORMAT                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Each event is plain text, separated by a blank line (\n\n):    â”‚
â”‚                                                                 â”‚
â”‚  MINIMAL EVENT (data only):                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚                                                                 â”‚
â”‚    data: {"progress": 25, "status": "processing"}\n             â”‚
â”‚    \n                                                           â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  FULL EVENT (all optional fields):                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                              â”‚
â”‚                                                                 â”‚
â”‚    id: 42\n                    â† Event ID (for reconnection!)   â”‚
â”‚    event: progress_update\n    â† Event type (client can filter) â”‚
â”‚    data: {"progress": 25}\n    â† Payload (the actual data)      â”‚
â”‚    retry: 5000\n               â† Reconnect delay in ms          â”‚
â”‚    \n                          â† Blank line = end of event      â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  MULTI-LINE DATA:                                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                               â”‚
â”‚                                                                 â”‚
â”‚    data: first line\n                                           â”‚
â”‚    data: second line\n                                          â”‚
â”‚    \n                                                           â”‚
â”‚                                                                 â”‚
â”‚    (Client receives: "first line\nsecond line")                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**SSE has built-in reconnection â€” no client-side code needed:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SSE AUTO-RECONNECTION                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  The browser's EventSource API handles reconnection             â”‚
â”‚  AUTOMATICALLY. You don't write reconnection logic.             â”‚
â”‚                                                                 â”‚
â”‚  How it works:                                                  â”‚
â”‚                                                                 â”‚
â”‚  1. Server sends events with "id:" fields                       â”‚
â”‚  2. Connection drops                                            â”‚
â”‚  3. Browser waits (default 3s, or "retry:" value)               â”‚
â”‚  4. Browser reconnects, sends header:                           â”‚
â”‚     Last-Event-ID: 42                                           â”‚
â”‚  5. Server reads that header, replays events since ID 42        â”‚
â”‚                                                                 â”‚
â”‚  Compare to WebSocket:                                          â”‚
â”‚  â”œâ”€ WebSocket: YOU write all reconnection logic                 â”‚
â”‚  â””â”€ SSE: The BROWSER does it for you                            â”‚
â”‚                                                                 â”‚
â”‚  This is why SSE is so attractive for push-only scenarios.      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4.3 SSE in FastAPI

**FastAPI serves SSE through `StreamingResponse` with an async generator.**

> "Remember async generators? An `async def` with `yield` instead of `return`. FastAPI streams each yielded chunk to the client without closing the connection. Week 1's async knowledge makes this straightforward."

**Example 1: Job progress stream (connects to Week 11 â€” Celery)**

```python
# sse.py
import asyncio
import json

from fastapi import FastAPI, Request
from fastapi.responses import StreamingResponse

from celery_app import get_task_status   # Your Celery setup from Week 11

app = FastAPI()


async def job_progress_stream(
    job_id: str,
    request: Request,
) -> AsyncGenerator[str, None]:
    """
    Yields SSE events tracking a background job's progress.
    Ends when the job completes or fails (or client disconnects).
    """
    event_id = 0

    while True:
        # â”€â”€ Check if the client disconnected â”€â”€
        if await request.is_disconnected():
            break

        # â”€â”€ Poll the job status (Celery task, Week 11) â”€â”€
        status = await get_task_status(job_id)

        event_id += 1
        event = {
            "job_id": job_id,
            "progress": status["progress"],
            "status": status["state"],
        }

        # â”€â”€ Format as SSE â”€â”€
        yield (
            f"id: {event_id}\n"
            f"event: progress\n"
            f"data: {json.dumps(event)}\n"
            f"\n"
        )

        # â”€â”€ Stop streaming when job is terminal â”€â”€
        if status["state"] in ("completed", "failed"):
            break

        await asyncio.sleep(1)


@app.get("/jobs/{job_id}/progress")
async def stream_job_progress(job_id: str, request: Request):
    return StreamingResponse(
        job_progress_stream(job_id, request),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",      # Don't cache the stream
            "X-Accel-Buffering": "no",         # Disable nginx buffering
        },
    )
```

**Example 2: Notification stream with reconnection support**

```python
# notifications_sse.py
from collections.abc import AsyncGenerator

from fastapi import FastAPI, Request, Depends
from fastapi.responses import StreamingResponse

from auth import get_current_user, User   # Week 9
from db import get_notifications_since     # Week 6

app = FastAPI()


async def notification_stream(
    user_id: int,
    request: Request,
    last_event_id: int | None = None,
) -> AsyncGenerator[str, None]:
    """SSE stream of user notifications with reconnection support."""

    # â”€â”€ Replay missed notifications on reconnection â”€â”€
    if last_event_id is not None:
        missed = await get_notifications_since(user_id, last_event_id)
        for notif in missed:
            yield (
                f"id: {notif.id}\n"
                f"event: notification\n"
                f"data: {json.dumps(notif.to_dict())}\n"
                f"\n"
            )

    # â”€â”€ Stream new notifications as they arrive â”€â”€
    while True:
        if await request.is_disconnected():
            break

        # In production: use Redis pub/sub or a queue
        # instead of polling the database
        new = await poll_new_notifications(user_id)

        for notif in new:
            yield (
                f"id: {notif.id}\n"
                f"event: notification\n"
                f"data: {json.dumps(notif.to_dict())}\n"
                f"\n"
            )

        await asyncio.sleep(2)


@app.get("/notifications/stream")
async def notification_sse(
    request: Request,
    current_user: User = Depends(get_current_user),    # Week 9 auth
):
    # â”€â”€ Browser sends Last-Event-ID header on reconnect â”€â”€
    raw_id = request.headers.get("Last-Event-ID")
    last_id = int(raw_id) if raw_id else None

    return StreamingResponse(
        notification_stream(current_user.id, request, last_id),
        media_type="text/event-stream",
        headers={"Cache-Control": "no-cache", "X-Accel-Buffering": "no"},
    )
```

**How the browser consumes this (for your awareness):**

```javascript
// Client side â€” just 5 lines. The browser handles everything.
const source = new EventSource("/notifications/stream", {
    // Auth: SSE uses cookies (not Bearer tokens easily)
    // Or use a polyfill library that supports headers
});

source.addEventListener("notification", (event) => {
    const data = JSON.parse(event.data);
    console.log("New notification:", data);
    // event.lastEventId is tracked automatically
});

source.onerror = () => {
    // Browser auto-reconnects. Sends Last-Event-ID header.
    // You don't need to do anything.
    console.log("Connection lost, browser will reconnect...");
};
```

---

## 4.4 WebSocket vs SSE vs Polling (Decision Framework)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           CHOOSING THE RIGHT REAL-TIME TOOL                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚              START HERE: "Does the client need                  â”‚
â”‚               to send data AFTER connecting?"                   â”‚
â”‚                          â”‚                                      â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                                â”‚
â”‚                   YES          NO                               â”‚
â”‚                    â”‚           â”‚                                â”‚
â”‚                    â–¼           â–¼                                â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  "How often do                        â”‚
â”‚            â”‚ WEBSOCKET  â”‚   updates happen?"                    â”‚
â”‚            â”‚            â”‚       â”‚                               â”‚
â”‚            â”‚ Chat       â”‚  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”                          â”‚
â”‚            â”‚ Gaming     â”‚ Frequent  Rare                        â”‚
â”‚            â”‚ Collab     â”‚ (< 30s)   (minutes+)                  â”‚
â”‚            â”‚ editing    â”‚  â”‚          â”‚                          â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â–¼          â–¼                          â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚                     â”‚   SSE    â”‚ â”‚ POLLING   â”‚                   â”‚
â”‚                     â”‚          â”‚ â”‚           â”‚                   â”‚
â”‚                     â”‚ Progress â”‚ â”‚ Email     â”‚                   â”‚
â”‚                     â”‚ Notifs   â”‚ â”‚ check     â”‚                   â”‚
â”‚                     â”‚ Feeds    â”‚ â”‚ Sync      â”‚                   â”‚
â”‚                     â”‚ Metrics  â”‚ â”‚ (every    â”‚                   â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  5 min)   â”‚                   â”‚
â”‚                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Detailed comparison:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  FEATURE            â”‚ WEBSOCKET  â”‚ SSE         â”‚ POLLING        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚  Direction          â”‚ Bi-direct  â”‚ Serverâ†’Cli  â”‚ Clientâ†’Svr    â”‚
â”‚  Protocol           â”‚ WS (TCP)   â”‚ HTTP        â”‚ HTTP           â”‚
â”‚  Connection         â”‚ Persistent â”‚ Persistent  â”‚ Repeated       â”‚
â”‚  Auto-reconnect     â”‚ Manual     â”‚ Built-in    â”‚ N/A            â”‚
â”‚  Auth               â”‚ Custom*    â”‚ Cookies/URL â”‚ Headers        â”‚
â”‚  Proxy-friendly     â”‚ Sometimes  â”‚ Yes         â”‚ Yes            â”‚
â”‚  HTTP/2 multiplexed â”‚ No         â”‚ Yes         â”‚ Yes            â”‚
â”‚  Browser support    â”‚ All modern â”‚ All modern  â”‚ All            â”‚
â”‚  Complexity         â”‚ High       â”‚ Low         â”‚ Lowest         â”‚
â”‚  Scaling difficulty â”‚ High       â”‚ Medium      â”‚ Low            â”‚
â”‚                                                                 â”‚
â”‚  *WebSocket auth: token in query param or first message         â”‚
â”‚   (you learned this in Lecture 1)                               â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  SSE LIMITATIONS YOU SHOULD KNOW:                               â”‚
â”‚  â”œâ”€ Text only (no binary data without base64 encoding)          â”‚
â”‚  â”œâ”€ Unidirectional (client can't send through the SSE stream)   â”‚
â”‚  â”œâ”€ Max ~6 connections per domain in HTTP/1.1 browsers          â”‚
â”‚  â”‚   (not an issue with HTTP/2)                                 â”‚
â”‚  â””â”€ No built-in Bearer token auth (cookies or query params)     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The rule of thumb:**

> "Start with SSE. Upgrade to WebSocket only when the client needs to send data through the persistent connection. If updates are rare, just poll. Choose the simplest tool that satisfies the requirement."

---

# PART 5: TESTING REAL-TIME ENDPOINTS

## 5.1 Why Real-Time Testing is Hard

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           REAL-TIME TESTING CHALLENGES                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Compared to REST endpoints (Week 4), real-time tests are       â”‚
â”‚  harder because:                                                â”‚
â”‚                                                                 â”‚
â”‚  1. STATEFUL: A WebSocket test is a multi-step conversation,    â”‚
â”‚     not a single requestâ†’response. Order matters.               â”‚
â”‚                                                                 â”‚
â”‚  2. CONCURRENT: Broadcasting tests need multiple clients        â”‚
â”‚     connected simultaneously.                                   â”‚
â”‚                                                                 â”‚
â”‚  3. TIME-DEPENDENT: Heartbeat tests involve waiting for         â”‚
â”‚     intervals and timeouts.                                     â”‚
â”‚                                                                 â”‚
â”‚  4. BIDIRECTIONAL: You send AND receive, interleaved.           â”‚
â”‚     A REST test asserts one response. A WS test asserts a       â”‚
â”‚     sequence of messages.                                       â”‚
â”‚                                                                 â”‚
â”‚  5. EXTERNAL DEPENDENCIES: Scaling tests need Redis.            â”‚
â”‚     You need to mock or use fakeredis.                          â”‚
â”‚                                                                 â”‚
â”‚  FastAPI's TestClient handles most of this with                 â”‚
â”‚  its websocket_connect() context manager.                       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5.2 Testing WebSocket Endpoints with TestClient

**FastAPI's TestClient provides `websocket_connect()` â€” your primary tool.**

> "Remember from Week 4: TestClient wraps your app and simulates HTTP. It also simulates WebSocket connections. Same import, new method."

```python
# test_websocket.py
from fastapi.testclient import TestClient

from app.main import app

client = TestClient(app)


# â”€â”€ TEST: Basic connection and echo â”€â”€

def test_websocket_connect_and_send():
    """Client connects, sends a message, receives the broadcast."""
    with client.websocket_connect("/ws/general") as ws:
        ws.send_json({"type": "message", "text": "hello"})
        response = ws.receive_json()

        assert response["text"] == "hello"


# â”€â”€ TEST: Messages include an ID (for reconnection) â”€â”€

def test_messages_have_sequential_ids():
    """Every broadcast message should have an 'id' field."""
    with client.websocket_connect("/ws/general") as ws:
        ws.send_json({"type": "message", "text": "first"})
        msg1 = ws.receive_json()

        ws.send_json({"type": "message", "text": "second"})
        msg2 = ws.receive_json()

        assert "id" in msg1
        assert "id" in msg2
        assert msg2["id"] > msg1["id"]  # Sequential ordering


# â”€â”€ TEST: Broadcasting reaches multiple clients â”€â”€

def test_broadcast_to_room():
    """All clients in the same room receive the broadcast."""
    with (
        client.websocket_connect("/ws/general") as ws1,
        client.websocket_connect("/ws/general") as ws2,
    ):
        ws1.send_json({"type": "message", "text": "hello everyone"})

        # Both clients should receive the broadcast
        msg1 = ws1.receive_json()
        msg2 = ws2.receive_json()

        assert msg1["text"] == "hello everyone"
        assert msg2["text"] == "hello everyone"


# â”€â”€ TEST: Room isolation â”€â”€

def test_rooms_are_isolated():
    """Messages in one room don't leak to another."""
    with (
        client.websocket_connect("/ws/room_a") as ws_a,
        client.websocket_connect("/ws/room_b") as ws_b,
    ):
        # Send in room_a
        ws_a.send_json({"type": "message", "text": "room_a only"})
        msg_a = ws_a.receive_json()
        assert msg_a["text"] == "room_a only"

        # Verify room_b didn't receive it by sending its own message
        ws_b.send_json({"type": "message", "text": "room_b check"})
        msg_b = ws_b.receive_json()

        # room_b's first received message should be its own, not room_a's
        assert msg_b["text"] == "room_b check"
```

---

## 5.3 Testing Heartbeat, Disconnect, and Authentication

```python
# test_heartbeat_and_auth.py
import pytest
from fastapi.testclient import TestClient
from starlette.websockets import WebSocketDisconnect

from app.main import app
from app.auth import create_access_token   # Your JWT helper from Week 9

client = TestClient(app)


# â”€â”€ TEST: Server sends ping messages â”€â”€

def test_server_sends_heartbeat_ping():
    """
    After connecting, the server should send a ping
    within the ping_interval.

    NOTE: This test takes ~ping_interval seconds to run.
    Keep ping_interval short in test config.
    """
    with client.websocket_connect("/ws/general") as ws:
        # Wait for the server's ping (test config: interval=2s)
        msg = ws.receive_json()
        assert msg["type"] == "ping"

        # Respond with pong
        ws.send_json({"type": "pong"})

        # Connection should remain alive â€” send a real message
        ws.send_json({"type": "message", "text": "still alive"})
        response = ws.receive_json()
        assert response["text"] == "still alive"


# â”€â”€ TEST: Connection closes on heartbeat timeout â”€â”€

def test_heartbeat_timeout_closes_connection():
    """
    If the client never responds to pings, the server
    should close the connection after the timeout period.

    Test config: ping_interval=1s, timeout=3s
    """
    with pytest.raises(Exception):  # Connection will close
        with client.websocket_connect("/ws/general") as ws:
            # Receive ping but DON'T respond with pong
            msg = ws.receive_json()
            assert msg["type"] == "ping"

            # Don't send pong. Wait for timeout.
            # Server should close the connection.
            # The next receive will raise an exception.
            while True:
                ws.receive_json()   # Will raise when server closes


# â”€â”€ TEST: Unauthenticated clients are rejected â”€â”€

def test_websocket_rejects_unauthenticated():
    """Protected WebSocket endpoint rejects connections without a token."""
    with pytest.raises(Exception):
        with client.websocket_connect("/ws/protected/general"):
            pass   # Should never reach this line


# â”€â”€ TEST: Authenticated clients can connect â”€â”€

def test_websocket_accepts_valid_token():
    """Protected endpoint accepts connections with a valid JWT."""
    token = create_access_token(data={"sub": "user@example.com"})

    with client.websocket_connect(
        f"/ws/protected/general?token={token}"
    ) as ws:
        ws.send_json({"type": "message", "text": "authenticated hello"})
        response = ws.receive_json()
        assert response["text"] == "authenticated hello"


# â”€â”€ TEST: Expired tokens are rejected â”€â”€

def test_websocket_rejects_expired_token():
    """Expired JWT should result in connection rejection."""
    token = create_access_token(
        data={"sub": "user@example.com"},
        expires_minutes=-1,   # Already expired
    )

    with pytest.raises(Exception):
        with client.websocket_connect(
            f"/ws/protected/general?token={token}"
        ):
            pass
```

---

## 5.4 Mocking Redis for Cross-Server Tests

> "Your ScalableConnectionManager depends on Redis. In unit tests, you don't want a running Redis instance â€” that's an integration test concern. Use `fakeredis` or dependency overrides (Week 4) to isolate the behavior."

```python
# test_scalable_manager.py
import pytest
import fakeredis.aioredis       # pip install fakeredis[aioredis]

from app.main import app
from app.dependencies import get_redis
from fastapi.testclient import TestClient


@pytest.fixture
def fake_redis():
    """Create an in-memory fake Redis for testing."""
    return fakeredis.aioredis.FakeRedis()


@pytest.fixture
def test_client(fake_redis):
    """
    TestClient with Redis replaced by fakeredis.
    Uses dependency_overrides â€” same pattern as Week 4.
    """
    async def override_redis():
        return fake_redis

    app.dependency_overrides[get_redis] = override_redis

    with TestClient(app) as client:
        yield client

    app.dependency_overrides.clear()


def test_cross_room_isolation_with_redis(test_client):
    """Even through Redis pub/sub, rooms should be isolated."""
    with (
        test_client.websocket_connect("/ws/room_x") as ws_x,
        test_client.websocket_connect("/ws/room_y") as ws_y,
    ):
        ws_x.send_json({"type": "message", "text": "room_x msg"})
        msg_x = ws_x.receive_json()
        assert msg_x["text"] == "room_x msg"

        ws_y.send_json({"type": "message", "text": "room_y msg"})
        msg_y = ws_y.receive_json()
        assert msg_y["text"] == "room_y msg"
```

**When to use real Redis (integration tests):**

```python
# test_integration_redis.py
import pytest

REDIS_AVAILABLE = check_redis_connection()  # Helper that pings Redis


@pytest.mark.skipif(not REDIS_AVAILABLE, reason="Redis not running")
@pytest.mark.integration
def test_broadcast_through_real_redis():
    """
    Integration test: verify messages actually flow through Redis.
    Only runs when Redis is available (CI pipeline with Docker).
    """
    # ... test with real Redis connection ...
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              TESTING STRATEGY SUMMARY                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  UNIT TESTS (fast, no external dependencies):                   â”‚
â”‚  â”œâ”€ TestClient + websocket_connect()                            â”‚
â”‚  â”œâ”€ fakeredis for Redis-dependent code                          â”‚
â”‚  â”œâ”€ dependency_overrides for injected services (Week 4)         â”‚
â”‚  â””â”€ Run on every commit                                         â”‚
â”‚                                                                 â”‚
â”‚  INTEGRATION TESTS (slower, need Docker):                       â”‚
â”‚  â”œâ”€ Real Redis (docker-compose up)                              â”‚
â”‚  â”œâ”€ Test actual pub/sub message flow                            â”‚
â”‚  â”œâ”€ @pytest.mark.integration                                    â”‚
â”‚  â””â”€ Run in CI pipeline (Week 15)                                â”‚
â”‚                                                                 â”‚
â”‚  Same testing pyramid from Week 2:                              â”‚
â”‚  Many unit tests, fewer integration tests.                      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Quick Reference Card

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               REAL-TIME PATTERNS QUICK REFERENCE                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  HEARTBEAT:                                                     â”‚
â”‚      conn = HeartbeatConnection(ws, ping_interval=15, timeout=45â”‚)
â”‚      await conn.start()       # Background ping loop            â”‚
â”‚      conn.mark_alive()        # Call on ANY received message    â”‚
â”‚      await conn.stop()        # Cancel on disconnect            â”‚
â”‚                                                                 â”‚
â”‚  RECONNECTION (server-side):                                    â”‚
â”‚      buffer = MessageBuffer(redis, max_messages=500, ttl=300)   â”‚
â”‚      msg_id = await buffer.store(room, message)                 â”‚
â”‚      missed = await buffer.get_since(room, last_id)             â”‚
â”‚      # Replay missed messages on WebSocket connect              â”‚
â”‚                                                                 â”‚
â”‚  SCALING (Redis Pub/Sub bridge):                                â”‚
â”‚      await manager.publish(room, message)  # â†’ Redis            â”‚
â”‚      # _redis_listener() â†’ _broadcast_local()  (automatic)     â”‚
â”‚      # Each server subscribes to rooms it has connections for   â”‚
â”‚                                                                 â”‚
â”‚  SSE ENDPOINT:                                                  â”‚
â”‚      @app.get("/events")                                        â”‚
â”‚      async def sse(request: Request):                           â”‚
â”‚          return StreamingResponse(                               â”‚
â”‚              generator(request),                                â”‚
â”‚              media_type="text/event-stream",                    â”‚
â”‚          )                                                      â”‚
â”‚                                                                 â”‚
â”‚  SSE EVENT FORMAT:                                              â”‚
â”‚      f"id: {id}\nevent: {type}\ndata: {json}\n\n"              â”‚
â”‚                                                                 â”‚
â”‚  SSE RECONNECTION:                                              â”‚
â”‚      last_id = request.headers.get("Last-Event-ID")             â”‚
â”‚      # Browser sends this automatically on reconnect            â”‚
â”‚                                                                 â”‚
â”‚  TESTING:                                                       â”‚
â”‚      with client.websocket_connect("/ws/room") as ws:           â”‚
â”‚          ws.send_json(data)                                     â”‚
â”‚          response = ws.receive_json()                           â”‚
â”‚          assert response["key"] == "value"                      â”‚
â”‚                                                                 â”‚
â”‚  DECISION:                                                      â”‚
â”‚      Client sends data?  â†’ WebSocket                            â”‚
â”‚      Server push only?   â†’ SSE                                  â”‚
â”‚      Updates rare?       â†’ Polling                              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Summary: The Key Mental Model

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  REAL-TIME IN PRODUCTION = HANDLING UNRELIABILITY               â”‚
â”‚                                                                 â”‚
â”‚  Lecture 1 gave you the happy path:                             â”‚
â”‚    connect â†’ send â†’ receive â†’ disconnect cleanly                â”‚
â”‚                                                                 â”‚
â”‚  This lecture gave you the real world:                           â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
â”‚  â”‚  PROBLEM           â”‚â”€â”€â–¶  SOLUTION                            â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”€â”€â”€â”€â”€â”€â”€â”€â”€                           â”‚
â”‚  â”‚  Ghost connections â”‚â”€â”€â–¶  Heartbeat ping/pong                 â”‚
â”‚  â”‚  Missed messages   â”‚â”€â”€â–¶  Message buffer + replay             â”‚
â”‚  â”‚  Abrupt disconnect â”‚â”€â”€â–¶  Grace period + reconnect support    â”‚
â”‚  â”‚  Multi-server      â”‚â”€â”€â–¶  Redis pub/sub bridge                â”‚
â”‚  â”‚  Overkill          â”‚â”€â”€â–¶  SSE for push-only scenarios         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚
â”‚                                                                 â”‚
â”‚  Every pattern you learned today is a RESPONSE TO A FAILURE.    â”‚
â”‚  If someone asks "why do we need heartbeat?" the answer is      â”‚
â”‚  not "because it's a best practice." The answer is:             â”‚
â”‚  "because ghost connections will eat your server's memory       â”‚
â”‚   and make broadcasts hang."                                    â”‚
â”‚                                                                 â”‚
â”‚  Know the failure. Then the pattern makes sense.                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Connection to Upcoming Lectures

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WHERE THIS LEADS                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  WEEK 12, LECTURE 3: Performance Measurement & Optimization     â”‚
â”‚  â””â”€ You'll profile your WebSocket server under load.            â”‚
â”‚     How many connections can one instance handle?               â”‚
â”‚     Where does it bottleneck â€” CPU, memory, or Redis?           â”‚
â”‚                                                                 â”‚
â”‚  WEEK 12, LECTURE 4: Rate Limiting Your API                     â”‚
â”‚  â””â”€ Rate limiting applies to WebSocket connections too.         â”‚
â”‚     How do you prevent one client from flooding a room?         â”‚
â”‚     Connection limits per user, message rate limits.            â”‚
â”‚                                                                 â”‚
â”‚  WEEK 12 PROJECT: Add Real-Time & Optimize                      â”‚
â”‚  â””â”€ You'll add WebSocket notifications to your application,    â”‚
â”‚     with heartbeat, Redis-backed broadcasting, and              â”‚
â”‚     load test the whole thing.                                  â”‚
â”‚     Target: 500 req/min, <200ms p95 latency.                   â”‚
â”‚                                                                 â”‚
â”‚  WEEKS 13-14: Capstone Project                                  â”‚
â”‚  â””â”€ Real-time notifications via WebSocket (task updates,        â”‚
â”‚     mentions). SSE for background job progress.                 â”‚
â”‚     Everything from this lecture, production-grade.             â”‚
â”‚                                                                 â”‚
â”‚  WEEK 15: Docker & Deployment                                   â”‚
â”‚  â””â”€ Containerize the WebSocket server alongside Redis.          â”‚
â”‚     Docker Compose: API + worker + Redis + Postgres.            â”‚
â”‚     Scaling means running multiple containers â€”                 â”‚
â”‚     that's exactly the multi-server problem we solved today.    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```