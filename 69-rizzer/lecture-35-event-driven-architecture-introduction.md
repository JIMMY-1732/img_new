# LECTURE DESIGN PHILOSOPHY

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PEDAGOGICAL APPROACH                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  PAIN FIRST, PATTERN SECOND                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚  Students will see their OWN code pattern from the past         â”‚
â”‚  10 weeks collapse under new requirements. The coupling         â”‚
â”‚  explosion must be FELT before we introduce the cure.           â”‚
â”‚                                                                 â”‚
â”‚  ANALOGY-DRIVEN                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                 â”‚
â”‚  Radio Station (broadcast, nobody cares who listens)            â”‚
â”‚  vs Postal Service (directed, someone must receive).            â”‚
â”‚  Every concept maps to one of these two models.                 â”‚
â”‚                                                                 â”‚
â”‚  CONCEPT BEFORE IMPLEMENTATION                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â”‚
â”‚  The pub/sub diagram comes before redis.publish().              â”‚
â”‚  Architecture patterns come before tool selection.              â”‚
â”‚  Understand the WHY before choosing the WHAT.                   â”‚
â”‚                                                                 â”‚
â”‚  CONNECT TO PRIOR LECTURES                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚
â”‚  Redis (Week 10) â†’ now messaging, not just caching              â”‚
â”‚  Celery (Lecture 2-3) â†’ repositioned among alternatives         â”‚
â”‚  Async (Week 1) â†’ async-native tools leverage your knowledge   â”‚
â”‚  BackgroundTasks (Lecture 1) â†’ simplest tool revisited          â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# LECTURE OUTLINE

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          EVENT-DRIVEN ARCHITECTURE & TASK QUEUE SELECTION        â”‚
â”‚                       (3-4 Hour Lecture)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  PART 1: THE COUPLING PROBLEM (40 min)                          â”‚
â”‚  â”œâ”€ 1.1 The Feature Request That Breaks Everything              â”‚
â”‚  â”œâ”€ 1.2 Commands vs Events (Two Ways to Communicate)            â”‚
â”‚  â”œâ”€ 1.3 The Radio Station Analogy                               â”‚
â”‚  â””â”€ 1.4 The Pub/Sub Pattern                                     â”‚
â”‚                                                                 â”‚
â”‚  PART 2: REDIS PUB/SUB IN PRACTICE (50 min)                    â”‚
â”‚  â”œâ”€ 2.1 How Redis Pub/Sub Works (The Mechanism)                 â”‚
â”‚  â”œâ”€ 2.2 Publishing Events                                       â”‚
â”‚  â”œâ”€ 2.3 Subscribing to Channels                                 â”‚
â”‚  â”œâ”€ 2.4 Pattern Subscriptions (Wildcards)                       â”‚
â”‚  â”œâ”€ 2.5 Pub/Sub in a FastAPI Application                        â”‚
â”‚  â””â”€ 2.6 The Critical Limitation: Messages Are Ephemeral         â”‚
â”‚                                                                 â”‚
â”‚  PART 3: ARCHITECTURE PATTERNS â€” AWARENESS (35 min)             â”‚
â”‚  â”œâ”€ 3.1 Event Sourcing â€” Recording History, Not Just State      â”‚
â”‚  â”œâ”€ 3.2 CQRS â€” Separate Reads from Writes                      â”‚
â”‚  â””â”€ 3.3 When You'd Need Kafka or RabbitMQ (And When You Don't) â”‚
â”‚                                                                 â”‚
â”‚  PART 4: CHOOSING THE RIGHT TOOL (50 min)                       â”‚
â”‚  â”œâ”€ 4.1 The Landscape (What Exists and Why)                     â”‚
â”‚  â”œâ”€ 4.2 FastAPI BackgroundTasks (Recap & Positioning)           â”‚
â”‚  â”œâ”€ 4.3 Celery (Recap & Positioning)                            â”‚
â”‚  â”œâ”€ 4.4 Taskiq â€” The Async-Native Alternative                   â”‚
â”‚  â”œâ”€ 4.5 ARQ â€” The Lightweight Option                            â”‚
â”‚  â””â”€ 4.6 The Decision Framework                                  â”‚
â”‚                                                                 â”‚
â”‚  PART 5: COMMON MISTAKES AND MISCONCEPTIONS (15 min)            â”‚
â”‚  â”œâ”€ 5.1 Using Pub/Sub When You Need Guaranteed Delivery         â”‚
â”‚  â”œâ”€ 5.2 Blocking the Event Loop Inside a Subscriber             â”‚
â”‚  â”œâ”€ 5.3 Unstructured Events (No Schema)                         â”‚
â”‚  â”œâ”€ 5.4 Over-Engineering (Kafka for 100 Events/Day)             â”‚
â”‚  â””â”€ 5.5 Confusing Task Queues with Event Streams                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# PART 1: THE COUPLING PROBLEM

## 1.1 The Feature Request That Breaks Everything

**Start with code they recognize. This is THEIR code pattern.**

Over the past 10 weeks you've been building something like this. A service function that does the core thing and then handles side effects one by one:

```python
# services/task_service.py â€” What your code probably looks like right now
from datetime import datetime

async def complete_task(
    task_id: int,
    db: AsyncSession,
    redis: Redis,
) -> Task:
    """Mark a task as completed."""
    task = await task_repo.get(db, task_id)
    task.status = "completed"
    task.completed_at = datetime.utcnow()
    await db.commit()
    await db.refresh(task)

    # Invalidate cache (you added this in Week 10)
    await redis.delete(f"task:{task_id}")

    return task
```

**Clean. Readable. Works. Now the requirements start rolling in.**

> "Boss says: send an email when a task is completed."

```python
async def complete_task(
    task_id: int,
    db: AsyncSession,
    redis: Redis,
) -> Task:
    task = await task_repo.get(db, task_id)
    task.status = "completed"
    task.completed_at = datetime.utcnow()
    await db.commit()
    await db.refresh(task)

    await redis.delete(f"task:{task_id}")

    # NEW: Send email notification
    send_notification_email.delay(task.assignee_id, task.title)

    return task
```

> "Boss says: update the project progress percentage when tasks complete."

```python
async def complete_task(
    task_id: int,
    db: AsyncSession,
    redis: Redis,
) -> Task:
    task = await task_repo.get(db, task_id)
    task.status = "completed"
    task.completed_at = datetime.utcnow()
    await db.commit()
    await db.refresh(task)

    await redis.delete(f"task:{task_id}")
    send_notification_email.delay(task.assignee_id, task.title)

    # NEW: Update project progress
    await update_project_progress(db, task.project_id)

    return task
```

> "Boss says: write an audit log for compliance. Also notify admins via WebSocket. Also invalidate the user's task list cache. Also trigger a Celery job to regenerate the weekly report..."

```python
async def complete_task(
    task_id: int,
    db: AsyncSession,
    redis: Redis,
    ws_manager: ConnectionManager,
) -> Task:
    task = await task_repo.get(db, task_id)
    task.status = "completed"
    task.completed_at = datetime.utcnow()
    await db.commit()
    await db.refresh(task)

    # Side effect 1: Cache invalidation
    await redis.delete(f"task:{task_id}")
    await redis.delete(f"user:{task.assignee_id}:tasks")
    await redis.delete(f"project:{task.project_id}:stats")

    # Side effect 2: Email notification
    send_notification_email.delay(task.assignee_id, task.title)

    # Side effect 3: Project progress
    await update_project_progress(db, task.project_id)

    # Side effect 4: Audit log
    await audit_log.record(
        action="task_completed",
        entity_id=task_id,
        user_id=task.assignee_id,
    )

    # Side effect 5: WebSocket broadcast
    await ws_manager.broadcast_to_project(
        task.project_id,
        {"event": "task_completed", "task_id": task_id},
    )

    # Side effect 6: Report regeneration
    regenerate_weekly_report.delay(task.project_id)

    return task
```

**Now ask the class:**

> "What was this function supposed to do?"

Answer: **Mark a task as completed.** One line of business logic. But now it's 6 side effects bolted on, and every new feature request forces you to open this function, add more parameters, add more imports, add more failure modes.

**Visualize the problem:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    THE COUPLING EXPLOSION                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚                  complete_task()                                 â”‚
â”‚                       â”‚                                         â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚         â”‚             â”‚              â”‚                          â”‚
â”‚         â–¼             â–¼              â–¼                          â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚    â”‚  Redis  â”‚  â”‚  Email   â”‚  â”‚ Project  â”‚                     â”‚
â”‚    â”‚  Cache  â”‚  â”‚  Service â”‚  â”‚ Progress â”‚                     â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚         â”‚             â”‚              â”‚                          â”‚
â”‚         â–¼             â–¼              â–¼                          â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚    â”‚  Audit  â”‚  â”‚ WebSocketâ”‚  â”‚  Report  â”‚                     â”‚
â”‚    â”‚  Log    â”‚  â”‚ Broadcastâ”‚  â”‚  Regen   â”‚                     â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                                 â”‚
â”‚  complete_task() now KNOWS about 6 systems.                     â”‚
â”‚  It DEPENDS on 6 systems.                                       â”‚
â”‚  If ANY of those 6 change, this function changes.               â”‚
â”‚  If ANY of those 6 fail, this function must handle it.          â”‚
â”‚                                                                 â”‚
â”‚  Next month there will be 9 side effects.                       â”‚
â”‚  The month after that: 12.                                      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Three specific problems with this approach:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  PROBLEM 1: SHOTGUN SURGERY                                     â”‚
â”‚  Every new side effect â†’ edit complete_task()                   â”‚
â”‚  Every new side effect â†’ add new parameter                      â”‚
â”‚  Every new side effect â†’ add new import                         â”‚
â”‚  The function grows forever.                                    â”‚
â”‚                                                                 â”‚
â”‚  PROBLEM 2: CASCADING FAILURE                                   â”‚
â”‚  If the email service is down, does complete_task() fail?       â”‚
â”‚  Should the user see a 500 error because email is broken?       â”‚
â”‚  The task WAS completed. The core job IS done.                  â”‚
â”‚  Side effects are dragging the core operation into their mess.  â”‚
â”‚                                                                 â”‚
â”‚  PROBLEM 3: TESTING NIGHTMARE                                   â”‚
â”‚  To test complete_task() you now need to mock:                  â”‚
â”‚  - AsyncSession       - Redis                                   â”‚
â”‚  - Email service       - Audit logger                           â”‚
â”‚  - WebSocket manager   - Report generator                       â”‚
â”‚  Six mocks for a function that should just flip a status bit.   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1.2 Commands vs Events (Two Ways to Communicate)

**There are two fundamentally different ways for code to communicate.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               COMMANDS VS EVENTS                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  COMMAND                             EVENT                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€                             â”€â”€â”€â”€â”€                      â”‚
â”‚  "Do this."                          "This happened."           â”‚
â”‚                                                                 â”‚
â”‚  Directed at a specific receiver.    Broadcast to anyone        â”‚
â”‚                                      who cares.                 â”‚
â”‚                                                                 â”‚
â”‚  The sender KNOWS who will           The sender DOES NOT KNOW   â”‚
â”‚  handle it.                          who will handle it.        â”‚
â”‚                                                                 â”‚
â”‚  The sender EXPECTS a result.        The sender does NOT WAIT   â”‚
â”‚                                      for results.               â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  Example:                            Example:                   â”‚
â”‚  "Hey EmailService,                  "A task was completed.     â”‚
â”‚   send this email!"                   Just so you all know."    â”‚
â”‚                                                                 â”‚
â”‚  send_email(to, subject, body)       publish("task.completed",  â”‚
â”‚  â–²                                            {task_id: 42})    â”‚
â”‚  â”‚                                   â–²                          â”‚
â”‚  â””â”€â”€ I know exactly who              â””â”€â”€ I have no idea who     â”‚
â”‚      I'm talking to.                     is listening.           â”‚
â”‚                                          And I don't care.      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**What you've been writing so far is COMMAND-driven:**

```python
# Commands â€” you tell specific systems what to do
send_notification_email.delay(user_id, title)     # "EmailService, send!"
await update_project_progress(db, project_id)      # "ProgressService, update!"
await audit_log.record(action, entity_id, user_id) # "AuditService, record!"
```

**The event-driven alternative:**

```python
# Events â€” you announce what happened, you don't tell anyone what to do
await publish("task.completed", {"task_id": 42, "project_id": 7})
# "A task was completed. I'm done. Whoever cares, deal with it."
```

**The function after this shift:**

```python
async def complete_task(
    task_id: int,
    db: AsyncSession,
    event_bus: EventBus,            # Only ONE extra dependency
) -> Task:
    task = await task_repo.get(db, task_id)
    task.status = "completed"
    task.completed_at = datetime.utcnow()
    await db.commit()
    await db.refresh(task)

    # Announce what happened. That's it.
    await event_bus.publish("task.completed", {
        "task_id": task.id,
        "project_id": task.project_id,
        "assignee_id": task.assignee_id,
        "title": task.title,
    })

    return task
```

**Visualize the difference:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  BEFORE (COMMAND-DRIVEN)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚               complete_task()                                   â”‚
â”‚              â•±   â”‚    â”‚    â•²                                     â”‚
â”‚            â•±     â”‚    â”‚      â•²                                   â”‚
â”‚          â•±       â”‚    â”‚        â•²                                 â”‚
â”‚        â–¼         â–¼    â–¼          â–¼                               â”‚
â”‚     Email    Cache  Audit    WebSocket                          â”‚
â”‚                                                                 â”‚
â”‚   Function must know about ALL consumers.                       â”‚
â”‚   Add a consumer â†’ modify the function.                         â”‚
â”‚                                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                  AFTER (EVENT-DRIVEN)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚               complete_task()                                   â”‚
â”‚                     â”‚                                           â”‚
â”‚                     â–¼                                           â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚              â”‚  Event Bus  â”‚                                    â”‚
â”‚              â”‚  (Pub/Sub)  â”‚                                    â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚              â•±   â”‚    â”‚    â•²                                     â”‚
â”‚            â•±     â”‚    â”‚      â•²                                   â”‚
â”‚          â–¼       â–¼    â–¼        â–¼                                 â”‚
â”‚       Email   Cache  Audit  WebSocket                          â”‚
â”‚                                                                 â”‚
â”‚   Function knows about NOTHING except the event bus.            â”‚
â”‚   Add a consumer â†’ subscribe to the event. Function untouched. â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> "The function went from knowing about 6 systems to knowing about 0 systems. It just says what happened. The event bus does the rest."

---

## 1.3 The Radio Station Analogy

**This analogy will carry us through the rest of the lecture.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  THE RADIO STATION ANALOGY                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  COMMAND = POSTAL SERVICE                                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                       â”‚
â”‚                                                                 â”‚
â”‚  You write a letter addressed to a specific person.             â”‚
â”‚  The postal service delivers it to THAT person.                 â”‚
â”‚  If they're not home, the letter waits in the mailbox.          â”‚
â”‚  You KNOW who you're sending to.                                â”‚
â”‚  You EXPECT the letter to arrive.                               â”‚
â”‚                                                                 â”‚
â”‚       [You] â”€â”€letterâ”€â”€â–¶ [Postal Service] â”€â”€â–¶ [Alice]           â”‚
â”‚                                                                 â”‚
â”‚  This is Celery. You send a task TO a specific worker.          â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  EVENT = RADIO STATION                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                           â”‚
â”‚                                                                 â”‚
â”‚  The station broadcasts on a frequency.                         â”‚
â”‚  ANYONE with a radio can tune in.                               â”‚
â”‚  The station doesn't know who's listening.                      â”‚
â”‚  The station doesn't CARE who's listening.                      â”‚
â”‚  If nobody tunes in, the broadcast still happens â€” into air.   â”‚
â”‚                                                                 â”‚
â”‚       [Station] â”€â”€broadcastâ”€â”€â–¶ ğŸ“» [Alice]                      â”‚
â”‚                            â”€â”€â–¶ ğŸ“» [Bob]                        â”‚
â”‚                            â”€â”€â–¶ ğŸ“» [Charlie]                    â”‚
â”‚                            â”€â”€â–¶ ğŸ“» [... anyone]                 â”‚
â”‚                                                                 â”‚
â”‚  This is Pub/Sub. You publish an event. Whoever subscribes,    â”‚
â”‚  receives it. You never know or care who that is.               â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Map the analogy to programming:**

```
Radio Station                  â”‚  Event-Driven System
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Radio station (broadcaster)    â”‚  Publisher (your service function)
Broadcast frequency / channel  â”‚  Event channel / topic name
Radio listener                 â”‚  Subscriber (event handler)
The broadcast itself           â”‚  The published event (data payload)
Tuning your radio to 101.5 FM â”‚  Subscribing to "task.completed"
Station doesn't know listeners â”‚  Publisher doesn't know subscribers
Broadcast lost if nobody       â”‚  Redis Pub/Sub: message lost if
  tunes in                     â”‚    no subscriber is connected
```

**And the postal analogy to Celery:**

```
Postal Service                 â”‚  Task Queue (Celery)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
You (sender)                   â”‚  Producer (your endpoint)
Addressed letter               â”‚  Task with arguments
Postal service                 â”‚  Broker (Redis as Celery broker)
Recipient's mailbox            â”‚  Worker queue
Letter waits until opened      â”‚  Task waits until worker picks up
You KNOW the recipient         â”‚  You KNOW the task function
Delivery confirmation          â”‚  Task result / acknowledgment
```

> "Through the rest of this lecture, whenever I say 'broadcast,' think radio station. Whenever I say 'dispatch,' think postal service. These are two completely different communication models, and choosing the wrong one is a real-world mistake."

---

## 1.4 The Pub/Sub Pattern

**Formalize the pattern.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    THE PUB/SUB PATTERN                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  PUBLISHER                                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                      â”‚
â”‚  The code that announces "something happened."                  â”‚
â”‚  It does NOT know who will receive the message.                 â”‚
â”‚  It does NOT wait for anyone to handle it.                      â”‚
â”‚                                                                 â”‚
â”‚  CHANNEL (also called Topic)                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€                                                        â”‚
â”‚  A named stream that publishers write to and subscribers        â”‚
â”‚  read from. Like a radio frequency.                             â”‚
â”‚  Examples: "task.completed", "user.registered", "order.paid"    â”‚
â”‚                                                                 â”‚
â”‚  SUBSCRIBER                                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                     â”‚
â”‚  The code that listens on a channel and reacts.                 â”‚
â”‚  It does NOT know who published the message.                    â”‚
â”‚  Multiple subscribers can listen to the same channel.           â”‚
â”‚                                                                 â”‚
â”‚  BROKER                                                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€                                                         â”‚
â”‚  The infrastructure that routes messages from publishers        â”‚
â”‚  to subscribers. Redis, RabbitMQ, Kafka â€” this is the           â”‚
â”‚  radio tower that carries the signal.                           â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    publish     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    deliver          â”‚
â”‚  â”‚ Publisher  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚  Channel  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Sub A â”‚
â”‚  â”‚           â”‚  "task.done"  â”‚ (Broker)  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Sub B â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Sub C â”‚
â”‚                                                                 â”‚
â”‚  Publisher: 1        Channel: 1        Subscribers: N           â”‚
â”‚  (or many)                             (zero or many)           â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The three guarantees of pub/sub:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  1. DECOUPLING                                                  â”‚
â”‚     Publisher and subscriber do not know about each other.      â”‚
â”‚     They only know about the channel.                           â”‚
â”‚                                                                 â”‚
â”‚  2. ONE-TO-MANY                                                 â”‚
â”‚     One event can trigger multiple independent reactions.       â”‚
â”‚     Adding a new reaction = adding a new subscriber.            â”‚
â”‚     No existing code changes.                                   â”‚
â”‚                                                                 â”‚
â”‚  3. FIRE-AND-FORGET (from the publisher's perspective)          â”‚
â”‚     The publisher sends and moves on.                           â”‚
â”‚     It does not wait. It does not check.                        â”‚
â”‚     It's the subscriber's job to handle the message.            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Now map this back to our task completion problem:**

```python
# PUBLISHERS â€” they announce what happened
# (inside complete_task)
await event_bus.publish("task.completed", {
    "task_id": 42,
    "project_id": 7,
    "assignee_id": 3,
    "title": "Fix login bug",
})

# SUBSCRIBERS â€” each handles ONE concern, independently
# They are defined ELSEWHERE. complete_task() doesn't know they exist.

# subscriber_email.py
async def on_task_completed_send_email(event: dict):
    user = await get_user(event["assignee_id"])
    await send_email(user.email, f"Task done: {event['title']}")

# subscriber_cache.py
async def on_task_completed_invalidate_cache(event: dict):
    await redis.delete(f"task:{event['task_id']}")
    await redis.delete(f"project:{event['project_id']}:stats")

# subscriber_audit.py
async def on_task_completed_audit_log(event: dict):
    await audit_log.record("task_completed", entity_id=event["task_id"])

# subscriber_ws.py
async def on_task_completed_notify_ws(event: dict):
    await ws_manager.broadcast_to_project(
        event["project_id"],
        {"event": "task_completed", "task_id": event["task_id"]},
    )

# subscriber_report.py
async def on_task_completed_regen_report(event: dict):
    regenerate_weekly_report.delay(event["project_id"])
```

> "Five subscribers. Five files. Five independent concerns. And `complete_task()` knows about NONE of them. Want to add a sixth reaction next month? Write a new subscriber, subscribe to the channel. Zero changes to `complete_task()`."

---

# PART 2: REDIS PUB/SUB IN PRACTICE

## 2.1 How Redis Pub/Sub Works (The Mechanism)

**You already know Redis as a cache (Week 10). Now meet Redis as a message broker.**

Redis Pub/Sub is a built-in messaging system that is completely separate from the key-value operations you've been using. No `SET`, no `GET`, no `TTL`. Different mechanism entirely.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  REDIS PUB/SUB â€” HOW IT WORKS                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  REDIS SERVER                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                                                         â”‚    â”‚
â”‚  â”‚  Key-Value Store (what you've used)                     â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
â”‚  â”‚  â”‚ "task:42"  â†’ {"status": "completed"}            â”‚    â”‚    â”‚
â”‚  â”‚  â”‚ "user:3"   â†’ {"name": "Alice"}                  â”‚    â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
â”‚  â”‚                                                         â”‚    â”‚
â”‚  â”‚  Pub/Sub Engine (what we're learning now)               â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
â”‚  â”‚  â”‚ Channel: "task.completed"                       â”‚    â”‚    â”‚
â”‚  â”‚  â”‚   â””â”€ Subscribers: [Client A, Client B]          â”‚    â”‚    â”‚
â”‚  â”‚  â”‚ Channel: "user.registered"                      â”‚    â”‚    â”‚
â”‚  â”‚  â”‚   â””â”€ Subscribers: [Client C]                    â”‚    â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
â”‚  â”‚                                                         â”‚    â”‚
â”‚  â”‚  These are TWO SEPARATE SYSTEMS inside the same Redis.  â”‚    â”‚
â”‚  â”‚  Pub/Sub does NOT store data. No keys. No TTL. No GET.  â”‚    â”‚
â”‚  â”‚                                                         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The lifecycle of a pub/sub message:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              MESSAGE LIFECYCLE                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. Subscriber connects and SUBSCRIBES to a channel             â”‚
â”‚     Client A â”€â”€â–¶ SUBSCRIBE "task.completed"                     â”‚
â”‚     Client B â”€â”€â–¶ SUBSCRIBE "task.completed"                     â”‚
â”‚                                                                 â”‚
â”‚  2. Publisher sends a message to that channel                   â”‚
â”‚     Client X â”€â”€â–¶ PUBLISH "task.completed" '{"task_id": 42}'    â”‚
â”‚                                                                 â”‚
â”‚  3. Redis IMMEDIATELY forwards to ALL connected subscribers     â”‚
â”‚     Redis â”€â”€â–¶ Client A: '{"task_id": 42}'                      â”‚
â”‚     Redis â”€â”€â–¶ Client B: '{"task_id": 42}'                      â”‚
â”‚                                                                 â”‚
â”‚  4. Message is GONE. Not stored. Not retrievable.               â”‚
â”‚     If Client C subscribes 1 second later, it missed it.       â”‚
â”‚                                                                 â”‚
â”‚  âš ï¸  This is FUNDAMENTALLY different from Celery.               â”‚
â”‚     Celery stores tasks in the broker until a worker picks up.  â”‚
â”‚     Redis Pub/Sub delivers live and forgets immediately.        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2.2 Publishing Events

**Publishing is the easy side. One function call.**

You're using `redis.asyncio` â€” the same client from Week 10.

```python
import redis.asyncio as aioredis
import json
from datetime import datetime, timezone


async def publish_event(
    redis: aioredis.Redis,
    channel: str,
    data: dict,
) -> int:
    """
    Publish an event to a Redis Pub/Sub channel.

    Returns the number of subscribers who received the message.
    """
    message = json.dumps({
        "event": channel,
        "data": data,
        "published_at": datetime.now(timezone.utc).isoformat(),
    })
    receiver_count = await redis.publish(channel, message)
    return receiver_count
```

**Using it in your service:**

```python
async def complete_task(
    task_id: int,
    db: AsyncSession,
    redis: aioredis.Redis,
) -> Task:
    task = await task_repo.get(db, task_id)
    task.status = "completed"
    task.completed_at = datetime.now(timezone.utc)
    await db.commit()
    await db.refresh(task)

    # Publish the event â€” that's it
    receiver_count = await publish_event(redis, "task.completed", {
        "task_id": task.id,
        "project_id": task.project_id,
        "assignee_id": task.assignee_id,
        "title": task.title,
    })
    # receiver_count tells you how many subscribers got it
    # If 0 â†’ nobody was listening. The message is gone.

    return task
```

**What `redis.publish()` returns:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  await redis.publish("task.completed", message)                 â”‚
â”‚                                                                 â”‚
â”‚  Returns: int â€” the number of clients that received it          â”‚
â”‚                                                                 â”‚
â”‚  Returns 0  â†’ No one was subscribed. Message lost forever.      â”‚
â”‚  Returns 1  â†’ One subscriber got it.                            â”‚
â”‚  Returns 3  â†’ Three subscribers got it.                         â”‚
â”‚                                                                 â”‚
â”‚  The publisher does NOT get confirmation that subscribers       â”‚
â”‚  successfully PROCESSED the message. Only that they RECEIVED.   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2.3 Subscribing to Channels

**The subscriber runs a persistent loop, listening for messages.**

```python
import redis.asyncio as aioredis
import json


async def subscribe_to_events(redis: aioredis.Redis) -> None:
    """
    Long-running subscriber that listens for task events.
    This function runs FOREVER (until cancelled).
    """
    pubsub = redis.pubsub()
    await pubsub.subscribe("task.completed", "task.created")

    async for message in pubsub.listen():
        # Redis sends several message types
        if message["type"] != "message":
            # "subscribe" confirmation, "unsubscribe", etc. â€” skip
            continue

        channel = message["channel"]  # bytes, e.g. b"task.completed"
        raw_data = message["data"]    # bytes, e.g. b'{"event": ...}'

        # Decode (Redis gives us bytes)
        if isinstance(channel, bytes):
            channel = channel.decode()
        if isinstance(raw_data, bytes):
            raw_data = raw_data.decode()

        event = json.loads(raw_data)
        print(f"Received on '{channel}': {event}")

        # Route to the right handler
        await handle_event(channel, event)


async def handle_event(channel: str, event: dict) -> None:
    """Route events to their handlers."""
    handlers: dict[str, list] = {
        "task.completed": [
            on_task_completed_invalidate_cache,
            on_task_completed_send_email,
            on_task_completed_log_audit,
        ],
        "task.created": [
            on_task_created_notify_project,
        ],
    }

    for handler in handlers.get(channel, []):
        try:
            await handler(event["data"])
        except Exception as e:
            # One handler failing should NOT kill the others
            print(f"Handler {handler.__name__} failed: {e}")
```

**Visualize the subscriber loop:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  SUBSCRIBER LOOP                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   subscribe_to_events()                                         â”‚
â”‚          â”‚                                                      â”‚
â”‚          â–¼                                                      â”‚
â”‚   â”Œâ”€â”€â”€ pubsub.subscribe("task.completed") â—€â”€â”€â”€â”€ register       â”‚
â”‚   â”‚                                                             â”‚
â”‚   â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚   â””â”€â”€â–¶ â”‚   Wait for next   â”‚ â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚        â”‚   message...      â”‚                    â”‚               â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚               â”‚
â”‚                 â”‚ message arrives                â”‚               â”‚
â”‚                 â–¼                                â”‚               â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚               â”‚
â”‚        â”‚ Is type "message"?â”‚                    â”‚               â”‚
â”‚        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                    â”‚               â”‚
â”‚           Yes         No                        â”‚               â”‚
â”‚            â”‚          â””â”€â”€ skip â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤               â”‚
â”‚            â–¼                                    â”‚               â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚               â”‚
â”‚        â”‚  Decode JSON      â”‚                    â”‚               â”‚
â”‚        â”‚  Route to handler â”‚                    â”‚               â”‚
â”‚        â”‚  Execute handler  â”‚                    â”‚               â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚               â”‚
â”‚                 â”‚                               â”‚               â”‚
â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                                 â”‚
â”‚   This loop runs FOREVER. It's a long-lived process.           â”‚
â”‚   Like a radio that's always on, always listening.              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Message types from Redis Pub/Sub:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MESSAGE TYPES                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  "subscribe"     â†’ Confirmation that you subscribed             â”‚
â”‚                    {"type": "subscribe",                        â”‚
â”‚                     "channel": "task.completed",                â”‚
â”‚                     "data": 1}  â† number of active subs        â”‚
â”‚                                                                 â”‚
â”‚  "message"       â†’ An actual published message                  â”‚
â”‚                    {"type": "message",                          â”‚
â”‚                     "channel": "task.completed",                â”‚
â”‚                     "data": '{"task_id": 42}'}                  â”‚
â”‚                                                                 â”‚
â”‚  "unsubscribe"   â†’ Confirmation that you unsubscribed           â”‚
â”‚                    {"type": "unsubscribe",                      â”‚
â”‚                     "channel": "task.completed",                â”‚
â”‚                     "data": 0}  â† remaining subs               â”‚
â”‚                                                                 â”‚
â”‚  You only care about "message". Filter the rest.               â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2.4 Pattern Subscriptions (Wildcards)

**Instead of subscribing to exact channel names, subscribe to patterns.**

```python
pubsub = redis.pubsub()

# Exact subscription â€” only "task.completed"
await pubsub.subscribe("task.completed")

# Pattern subscription â€” any channel starting with "task."
await pubsub.psubscribe("task.*")
# Matches: "task.completed", "task.created", "task.deleted"
# Does NOT match: "user.registered", "order.paid"
```

**This is like tuning your radio to a range of frequencies instead of one.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PATTERN SUBSCRIPTIONS                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Pattern              Matches                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€                                   â”‚
â”‚  "task.*"             task.completed, task.created               â”‚
â”‚  "*.completed"        task.completed, order.completed            â”‚
â”‚  "project.*.updated"  project.settings.updated,                 â”‚
â”‚                       project.members.updated                   â”‚
â”‚                                                                 â”‚
â”‚  Use case:                                                      â”‚
â”‚  An audit log subscriber that needs to record ALL events:       â”‚
â”‚                                                                 â”‚
â”‚  await pubsub.psubscribe("*")  â† listen to EVERYTHING          â”‚
â”‚                                                                 â”‚
â”‚  A project-level dashboard subscriber:                          â”‚
â”‚                                                                 â”‚
â”‚  await pubsub.psubscribe("project.42.*")  â† all events for     â”‚
â”‚                                              project 42         â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Pattern subscriptions produce `"pmessage"` type, not `"message"`:**

```python
async for message in pubsub.listen():
    if message["type"] == "pmessage":
        pattern = message["pattern"]   # b"task.*"
        channel = message["channel"]   # b"task.completed"
        data = message["data"]         # b'{"task_id": 42}'
```

---

## 2.5 Pub/Sub in a FastAPI Application

**How do you actually wire this into the app you've been building?**

The publisher side is straightforward â€” call `redis.publish()` from any endpoint or service function. The subscriber side is the challenge: you need a long-running loop that starts when your app starts and stops when your app stops.

**Use FastAPI's `lifespan` â€” a context manager that wraps your app's lifecycle.**

If you've set up your Redis connection pool, you've already seen this pattern. It builds on the context manager concept from Week 1, Lecture 2.

```python
# main.py
import asyncio
from contextlib import asynccontextmanager
from fastapi import FastAPI
import redis.asyncio as aioredis

from app.events.subscriber import subscribe_to_events


@asynccontextmanager
async def lifespan(app: FastAPI):
    # â”€â”€ STARTUP â”€â”€
    app.state.redis = aioredis.from_url("redis://localhost:6379")

    # Start the subscriber as a background task
    subscriber_task = asyncio.create_task(
        subscribe_to_events(app.state.redis)
    )

    yield  # â† App is running, handling requests

    # â”€â”€ SHUTDOWN â”€â”€
    subscriber_task.cancel()
    try:
        await subscriber_task
    except asyncio.CancelledError:
        pass  # Expected â€” we cancelled it
    await app.state.redis.aclose()


app = FastAPI(lifespan=lifespan)
```

**Visualize the architecture:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 FASTAPI + REDIS PUB/SUB                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  FastAPI Process                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                                                         â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚   Request Handlers   â”‚   â”‚   Event Subscriber     â”‚  â”‚    â”‚
â”‚  â”‚  â”‚   (your endpoints)   â”‚   â”‚   (background task)    â”‚  â”‚    â”‚
â”‚  â”‚  â”‚                      â”‚   â”‚                        â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  POST /tasks/42/     â”‚   â”‚   Listening on:        â”‚  â”‚    â”‚
â”‚  â”‚  â”‚    complete          â”‚   â”‚   - "task.completed"   â”‚  â”‚    â”‚
â”‚  â”‚  â”‚      â”‚               â”‚   â”‚   - "task.created"     â”‚  â”‚    â”‚
â”‚  â”‚  â”‚      â”‚ publish â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”‚â”€â”€â–¶ handle_event()      â”‚  â”‚    â”‚
â”‚  â”‚  â”‚      â”‚               â”‚   â”‚     â”œâ”€ send email      â”‚  â”‚    â”‚
â”‚  â”‚  â”‚      â–¼               â”‚   â”‚     â”œâ”€ clear cache     â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  return response     â”‚   â”‚     â””â”€ log audit       â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â”‚            â”‚                          â–²                  â”‚    â”‚
â”‚  â”‚            â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚    â”‚
â”‚  â”‚            â–¼         â”‚                                   â”‚    â”‚
â”‚  â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚    â”‚
â”‚  â”‚       â”‚   Redis Server   â”‚                               â”‚    â”‚
â”‚  â”‚       â”‚   (Pub/Sub +     â”‚                               â”‚    â”‚
â”‚  â”‚       â”‚    Cache)        â”‚                               â”‚    â”‚
â”‚  â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                 â”‚
â”‚  Both publisher and subscriber live in the SAME process.        â”‚
â”‚  The event goes: endpoint â†’ Redis â†’ back to same process.       â”‚
â”‚  This seems silly â€” but it DECOUPLES the code.                  â”‚
â”‚  And when you scale to multiple processes, it still works.      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**A more structured event system for production:**

```python
# app/events/schemas.py
from pydantic import BaseModel
from datetime import datetime, timezone


class TaskCompletedEvent(BaseModel):
    task_id: int
    project_id: int
    assignee_id: int
    title: str


class EventEnvelope(BaseModel):
    """Every event gets wrapped in a standard envelope."""
    event_type: str
    data: dict
    published_at: datetime

    @classmethod
    def create(cls, event_type: str, data: BaseModel) -> "EventEnvelope":
        return cls(
            event_type=event_type,
            data=data.model_dump(),
            published_at=datetime.now(timezone.utc),
        )
```

```python
# app/events/publisher.py
import json
import redis.asyncio as aioredis
from app.events.schemas import EventEnvelope


class EventPublisher:
    def __init__(self, redis: aioredis.Redis) -> None:
        self._redis = redis

    async def publish(self, channel: str, envelope: EventEnvelope) -> int:
        """Publish a structured event. Returns subscriber count."""
        message = envelope.model_dump_json()
        return await self._redis.publish(channel, message)
```

```python
# app/events/handlers.py
from app.events.schemas import EventEnvelope


async def handle_task_completed_email(envelope: EventEnvelope) -> None:
    data = envelope.data
    # ... send email using data["assignee_id"], data["title"]


async def handle_task_completed_cache(envelope: EventEnvelope) -> None:
    data = envelope.data
    # ... invalidate cache for data["task_id"], data["project_id"]
```

```python
# app/events/subscriber.py
import json
import redis.asyncio as aioredis
from app.events.schemas import EventEnvelope
from app.events.handlers import (
    handle_task_completed_email,
    handle_task_completed_cache,
)

# Registry: channel â†’ list of handler functions
HANDLERS: dict[str, list] = {
    "task.completed": [
        handle_task_completed_email,
        handle_task_completed_cache,
    ],
}


async def subscribe_to_events(redis: aioredis.Redis) -> None:
    pubsub = redis.pubsub()
    await pubsub.subscribe(*HANDLERS.keys())

    async for message in pubsub.listen():
        if message["type"] != "message":
            continue

        channel = message["channel"]
        if isinstance(channel, bytes):
            channel = channel.decode()

        raw = message["data"]
        if isinstance(raw, bytes):
            raw = raw.decode()

        envelope = EventEnvelope.model_validate_json(raw)

        for handler in HANDLERS.get(channel, []):
            try:
                await handler(envelope)
            except Exception as e:
                # Log error, but don't crash the subscriber loop
                print(f"Handler {handler.__name__} failed: {e}")
```

> "Notice: Pydantic validates the event structure. Type hints everywhere. The handler registry is a simple dict. Adding a new handler? Add one line to HANDLERS and write the function. Zero changes to the publisher."

---

## 2.6 The Critical Limitation: Messages Are Ephemeral

**This is the most important thing to understand about Redis Pub/Sub.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            âš ï¸  REDIS PUB/SUB = FIRE AND FORGET                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  There is NO message persistence. None.                         â”‚
â”‚                                                                 â”‚
â”‚  If a message is published and NO subscriber is connected:      â”‚
â”‚  â†’ The message is GONE. FOREVER. No retry. No queue. Nothing.   â”‚
â”‚                                                                 â”‚
â”‚  If a subscriber crashes mid-processing:                        â”‚
â”‚  â†’ The message is GONE. It was already delivered. No re-read.   â”‚
â”‚                                                                 â”‚
â”‚  If your app restarts (deployment, crash, scaling):             â”‚
â”‚  â†’ All messages published during the restart gap are GONE.      â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  RADIO STATION ANALOGY:                                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                         â”‚
â”‚  If you turn your radio off, you miss the broadcast.            â”‚
â”‚  The station doesn't record it for you.                         â”‚
â”‚  You can't rewind. You can't ask for a replay.                  â”‚
â”‚  It was broadcast. It's over.                                   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**When is this acceptable?**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  âœ… EPHEMERAL IS FINE FOR:                                      â”‚
â”‚  â”œâ”€ Cache invalidation (miss one? Cache just stays stale        â”‚
â”‚  â”‚   a bit longer â€” it has TTL anyway)                          â”‚
â”‚  â”œâ”€ Real-time UI updates (user refreshes page, gets new data)   â”‚
â”‚  â”œâ”€ Live dashboards (next data point comes in seconds)          â”‚
â”‚  â””â”€ Development/debugging event monitoring                      â”‚
â”‚                                                                 â”‚
â”‚  âŒ EPHEMERAL IS DANGEROUS FOR:                                 â”‚
â”‚  â”œâ”€ Email notifications (user NEVER gets the email)             â”‚
â”‚  â”œâ”€ Billing events (payment not recorded â†’ money lost)          â”‚
â”‚  â”œâ”€ Audit logs (compliance failure, legal liability)            â”‚
â”‚  â””â”€ Anything where losing a message has BUSINESS consequences   â”‚
â”‚                                                                 â”‚
â”‚  RULE: If losing ONE message keeps you up at night,             â”‚
â”‚  Redis Pub/Sub is the wrong tool. Use Celery, a persistent      â”‚
â”‚  message broker, or Redis Streams instead.                      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> "This is the single most common mistake people make with Redis Pub/Sub. They use it for critical business events because 'Redis is fast' and then discover months later that they've been silently losing messages during every deployment. Don't be that person."

---

# PART 3: ARCHITECTURE PATTERNS â€” AWARENESS

> "The following two patterns are concepts you'll encounter in architecture discussions, technical blogs, and system design interviews. We are NOT implementing them. You are learning to RECOGNIZE them, understand when they make sense, and know enough to participate in a conversation about them."

## 3.1 Event Sourcing â€” Recording History, Not Just State

**The normal approach (what you've been doing):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   STATE-BASED STORAGE                           â”‚
â”‚                   (What you do now)                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  You store the CURRENT state of an entity.                      â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚  â”‚  tasks table                â”‚                                â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                â”‚
â”‚  â”‚  id: 42                     â”‚                                â”‚
â”‚  â”‚  title: "Fix login bug"     â”‚                                â”‚
â”‚  â”‚  status: "completed"        â”‚ â† Only the current state      â”‚
â”‚  â”‚  assignee_id: 3             â”‚                                â”‚
â”‚  â”‚  updated_at: 2026-02-16     â”‚                                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚                                                                 â”‚
â”‚  Question: Who changed the status from "in_progress"            â”‚
â”‚  to "completed"? When? Was it ever changed back?                â”‚
â”‚  Was it "blocked" at some point?                                â”‚
â”‚                                                                 â”‚
â”‚  Answer: You don't know. You overwrote the history.             â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The event sourcing approach:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   EVENT SOURCING                                â”‚
â”‚                   (Alternative approach)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  You store EVERY EVENT that happened to the entity.             â”‚
â”‚  Current state = replay all events from the beginning.          â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  task_events table                                      â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚  1. TaskCreated    {title: "Fix login", assignee: 3}    â”‚    â”‚
â”‚  â”‚  2. TaskStarted    {started_by: 3}                      â”‚    â”‚
â”‚  â”‚  3. TaskBlocked    {reason: "waiting on design"}        â”‚    â”‚
â”‚  â”‚  4. TaskUnblocked  {unblocked_by: 5}                    â”‚    â”‚
â”‚  â”‚  5. TaskReassigned {from: 3, to: 7}                     â”‚    â”‚
â”‚  â”‚  6. TaskCompleted  {completed_by: 7}                    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                 â”‚
â”‚  Current state? Replay events 1â†’6:                              â”‚
â”‚    title="Fix login", status="completed", assignee=7            â”‚
â”‚                                                                 â”‚
â”‚  State at event 3? Replay events 1â†’3:                           â”‚
â”‚    title="Fix login", status="blocked", assignee=3              â”‚
â”‚                                                                 â”‚
â”‚  Full audit trail? Read the events. It's ALL there.             â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Think of it like a bank account:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  STATE-BASED BANK:                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚  Account #12345      â”‚                                       â”‚
â”‚  â”‚  Balance: $500       â”‚  â† That's all you know                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚                                                                 â”‚
â”‚  EVENT-SOURCED BANK:                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚  Jan 01: AccountOpened      +$0     = $0     â”‚               â”‚
â”‚  â”‚  Jan 05: DepositMade        +$1000  = $1000  â”‚               â”‚
â”‚  â”‚  Jan 12: WithdrawalMade     -$300   = $700   â”‚               â”‚
â”‚  â”‚  Jan 20: TransferReceived   +$200   = $900   â”‚               â”‚
â”‚  â”‚  Feb 01: WithdrawalMade     -$400   = $500   â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                                 â”‚
â”‚  Same balance. But the event-sourced version can answer:        â”‚
â”‚  â€¢ "What was my balance on Jan 15?" â†’ $700                      â”‚
â”‚  â€¢ "How much did I withdraw total?" â†’ $700                      â”‚
â”‚  â€¢ "Show me all deposits." â†’ Jan 05, Jan 20                     â”‚
â”‚                                                                 â”‚
â”‚  The state-based version can answer: "$500. That's it."         â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**When event sourcing makes sense:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  âœ… USE WHEN:                                                   â”‚
â”‚  â”œâ”€ Audit trails are legally required (finance, healthcare)     â”‚
â”‚  â”œâ”€ You need "time travel" (undo, replay, reconstruct state)    â”‚
â”‚  â”œâ”€ Multiple systems derive different views from the same data  â”‚
â”‚  â””â”€ Debugging production issues ("what happened to order #X?")  â”‚
â”‚                                                                 â”‚
â”‚  âŒ DON'T USE WHEN:                                             â”‚
â”‚  â”œâ”€ Simple CRUD is enough (most apps, including your project)   â”‚
â”‚  â”œâ”€ You don't need history (overwrite is fine)                  â”‚
â”‚  â””â”€ Your team is small and complexity would slow you down       â”‚
â”‚                                                                 â”‚
â”‚  EVENT SOURCING IS POWERFUL BUT COMPLEX.                        â”‚
â”‚  It changes how you think about data fundamentally.             â”‚
â”‚  For this course: know it exists, know when it shines,          â”‚
â”‚  don't implement it unless the domain demands it.               â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3.2 CQRS â€” Separate Reads from Writes

**CQRS stands for Command Query Responsibility Segregation.**

The core idea: the model you use to WRITE data doesn't have to be the same model you use to READ data.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     TRADITIONAL APPROACH                        â”‚
â”‚                     (What you do now)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚   Writes â”€â”€â–¶  â”‚              â”‚  â—€â”€â”€ Reads                       â”‚
â”‚               â”‚  SAME MODEL  â”‚                                  â”‚
â”‚   (CREATE,    â”‚  SAME TABLE  â”‚  (SELECT, JOIN,                  â”‚
â”‚    UPDATE,    â”‚  SAME SCHEMA â”‚   aggregate, filter)             â”‚
â”‚    DELETE)    â”‚              â”‚                                  â”‚
â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚                                                                 â”‚
â”‚  Your SQLAlchemy model is used for both writing and reading.    â”‚
â”‚  This is fine for most applications.                            â”‚
â”‚                                                                 â”‚
â”‚  But what if your write model (normalized, consistent)          â”‚
â”‚  is SLOW to read (complex JOINs, aggregations)?                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CQRS APPROACH                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚             COMMAND SIDE            QUERY SIDE                   â”‚
â”‚            (Write Model)           (Read Model)                 â”‚
â”‚                                                                 â”‚
â”‚   Writes â”€â”€â–¶ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”€â”€â–¶ Reads     â”‚
â”‚              â”‚ Normalized â”‚       â”‚Denormalizedâ”‚                â”‚
â”‚              â”‚ tables     â”‚â”€â”€syncâ”€â–¶â”‚ views /    â”‚                â”‚
â”‚              â”‚ (3NF)      â”‚       â”‚ projectionsâ”‚                â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                                                 â”‚
â”‚   Optimized for:                  Optimized for:                â”‚
â”‚   â€¢ Data integrity                â€¢ Fast queries                â”‚
â”‚   â€¢ Consistency                   â€¢ No JOINs needed             â”‚
â”‚   â€¢ Normalization                 â€¢ Pre-computed aggregates     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**A concrete example with your Task Manager:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               CQRS EXAMPLE: PROJECT DASHBOARD                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  WRITE SIDE (normalized â€” what you have now):                   â”‚
â”‚                                                                 â”‚
â”‚  tasks: id, title, status, assignee_id, project_id             â”‚
â”‚  users: id, name, email                                        â”‚
â”‚  projects: id, name, org_id                                    â”‚
â”‚                                                                 â”‚
â”‚  To build a dashboard you need to SELECT + JOIN + GROUP BY:     â”‚
â”‚  "For project 7, give me task count by status,                  â”‚
â”‚   assignee names, completion percentage, overdue count."        â”‚
â”‚  â†’ Complex query. Multiple JOINs. Slow if tables are large.    â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  QUERY SIDE (denormalized â€” CQRS optimization):                 â”‚
â”‚                                                                 â”‚
â”‚  project_dashboard: project_id, total_tasks, completed_tasks,   â”‚
â”‚                     in_progress_tasks, overdue_tasks,           â”‚
â”‚                     completion_pct, top_assignees_json,         â”‚
â”‚                     last_updated_at                             â”‚
â”‚                                                                 â”‚
â”‚  Dashboard query: SELECT * FROM project_dashboard WHERE id = 7  â”‚
â”‚  â†’ One table. No JOINs. Instant.                               â”‚
â”‚                                                                 â”‚
â”‚  The "sync" step: whenever a task changes, an event triggers   â”‚
â”‚  a handler that updates the project_dashboard row.              â”‚
â”‚  (See how pub/sub feeds into this?)                             â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**When CQRS makes sense:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  âœ… USE WHEN:                                                   â”‚
â”‚  â”œâ”€ Read and write patterns are drastically different           â”‚
â”‚  â”œâ”€ Read-heavy systems (100 reads per 1 write)                 â”‚
â”‚  â”œâ”€ Complex read queries that slow down under load             â”‚
â”‚  â””â”€ Different teams own the read and write paths               â”‚
â”‚                                                                 â”‚
â”‚  âŒ DON'T USE WHEN:                                             â”‚
â”‚  â”œâ”€ Reads and writes use similar models (most CRUD apps)       â”‚
â”‚  â”œâ”€ Data must be instantly consistent (no sync delay)          â”‚
â”‚  â””â”€ The added complexity isn't justified by performance needs  â”‚
â”‚                                                                 â”‚
â”‚  KEY TRADEOFF: Consistency vs Performance.                      â”‚
â”‚  Your read model is "eventually consistent" â€” there's a tiny   â”‚
â”‚  delay between writing data and seeing it in the read model.    â”‚
â”‚  For a real-time trading system? Probably unacceptable.         â”‚
â”‚  For a project dashboard? Nobody notices a 500ms delay.         â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> "Notice how event sourcing and CQRS connect to pub/sub. Event sourcing generates events. Pub/Sub distributes them. CQRS subscribers build optimized read models from those events. These patterns are building blocks that compose together. You don't need all of them. But when you do, they're a natural fit."

---

## 3.3 When You'd Need Kafka or RabbitMQ (And When You Don't)

**You've now seen two messaging tools: Redis Pub/Sub (this lecture) and Celery with Redis as broker (Lectures 2-3). When are these not enough?**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              MESSAGE BROKER LANDSCAPE                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  REDIS PUB/SUB                                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                  â”‚
â”‚  Delivery: At-most-once (fire and forget)                       â”‚
â”‚  Persistence: None                                              â”‚
â”‚  Replay: Impossible                                             â”‚
â”‚  Scale: Single Redis instance (millions of msg/sec possible)    â”‚
â”‚  Best for: Real-time notifications, cache invalidation          â”‚
â”‚                                                                 â”‚
â”‚  ğŸ”‘ Think: LIVE radio broadcast. Miss it, it's gone.           â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  RABBITMQ                                                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€                                                       â”‚
â”‚  Delivery: At-least-once, at-most-once, exactly-once possible   â”‚
â”‚  Persistence: Yes (messages survive broker restart)              â”‚
â”‚  Replay: No (message is deleted once acknowledged)              â”‚
â”‚  Scale: Clustering, but not infinite                            â”‚
â”‚  Best for: Reliable task routing, complex routing rules,        â”‚
â”‚            when messages MUST be processed                       â”‚
â”‚                                                                 â”‚
â”‚  ğŸ”‘ Think: Postal service with tracking.                        â”‚
â”‚     Guaranteed delivery. Signed receipt.                         â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  KAFKA                                                          â”‚
â”‚  â”€â”€â”€â”€â”€                                                          â”‚
â”‚  Delivery: At-least-once (exactly-once with transactions)       â”‚
â”‚  Persistence: Yes (messages stored for days/weeks/forever)      â”‚
â”‚  Replay: Yes! Any consumer can re-read from any point in time.  â”‚
â”‚  Scale: Massive horizontal scaling (partitions, consumer groups)â”‚
â”‚  Best for: Event streaming at scale, event sourcing,            â”‚
â”‚            log aggregation, data pipelines                       â”‚
â”‚                                                                 â”‚
â”‚  ğŸ”‘ Think: Newspaper archive. Read today's paper.               â”‚
â”‚     Read last week's paper. Read from any date you want.        â”‚
â”‚     The papers don't disappear when you read them.              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**When do you ACTUALLY need these?**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             DO I NEED KAFKA / RABBITMQ?                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  You probably DON'T if:                                         â”‚
â”‚  â”œâ”€ Your app has < 1000 users                                  â”‚
â”‚  â”œâ”€ Redis Pub/Sub + Celery cover your needs                    â”‚
â”‚  â”œâ”€ Message loss is tolerable (cache invalidation, live UI)    â”‚
â”‚  â”œâ”€ You're a small team (< 5 engineers)                        â”‚
â”‚  â””â”€ You're not doing event sourcing                            â”‚
â”‚                                                                 â”‚
â”‚  You might need RABBITMQ if:                                    â”‚
â”‚  â”œâ”€ Messages MUST be delivered (billing, notifications)         â”‚
â”‚  â”œâ”€ You need complex routing (message goes to different        â”‚
â”‚  â”‚   queues based on content, headers, patterns)               â”‚
â”‚  â”œâ”€ Multiple consumers need to SHARE load (work queues)        â”‚
â”‚  â””â”€ Celery's features aren't enough and you want more control  â”‚
â”‚                                                                 â”‚
â”‚  You might need KAFKA if:                                       â”‚
â”‚  â”œâ”€ You process millions of events per day                     â”‚
â”‚  â”œâ”€ Multiple independent services need the SAME events         â”‚
â”‚  â”œâ”€ You need to REPLAY events (rebuild state, fix bugs)        â”‚
â”‚  â”œâ”€ You're building data pipelines (analytics, ML features)    â”‚
â”‚  â””â”€ You're doing event sourcing at scale                       â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  REALITY CHECK:                                          â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  Most startups and small-to-medium applications will     â”‚   â”‚
â”‚  â”‚  NEVER need Kafka. Redis + Celery handles an enormous    â”‚   â”‚
â”‚  â”‚  range of use cases. Don't add infrastructure complexity â”‚   â”‚
â”‚  â”‚  you don't need yet.                                     â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  If you're handling 100 events per day and you reach     â”‚   â”‚
â”‚  â”‚  for Kafka, you're building a rocket to cross the        â”‚   â”‚
â”‚  â”‚  street.                                                 â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# PART 4: CHOOSING THE RIGHT TOOL

## 4.1 The Landscape (What Exists and Why)

> "You now know Celery and FastAPI BackgroundTasks from this week. You just learned Redis Pub/Sub. Now I'm going to show you two more tools â€” Taskiq and ARQ â€” because the Python async ecosystem has matured, and you should know what's available. Then we'll build a decision framework so you never have to guess."

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              THE PYTHON BACKGROUND TASK LANDSCAPE               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚            Simple â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Complex          â”‚
â”‚                                                                 â”‚
â”‚  BackgroundTasks    ARQ        Taskiq        Celery             â”‚
â”‚       â”‚              â”‚           â”‚             â”‚                â”‚
â”‚       â–¼              â–¼           â–¼             â–¼                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚In-processâ”‚  â”‚Redis-onlyâ”‚ â”‚Async-    â”‚ â”‚Industry  â”‚          â”‚
â”‚  â”‚No broker â”‚  â”‚Lightweightâ”‚ â”‚native   â”‚ â”‚standard  â”‚          â”‚
â”‚  â”‚No persistâ”‚  â”‚Async-    â”‚ â”‚Multiple  â”‚ â”‚Battle-   â”‚          â”‚
â”‚  â”‚Fire-and- â”‚  â”‚first     â”‚ â”‚brokers   â”‚ â”‚tested    â”‚          â”‚
â”‚  â”‚forget    â”‚  â”‚Simple APIâ”‚ â”‚Type-safe â”‚ â”‚Sync-firstâ”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                 â”‚
â”‚  "I need a          "I need         "I need        "I need     â”‚
â”‚   quick side         something       async-first    proven,     â”‚
â”‚   effect."           simple."        + typed."      reliable."  â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  Also in this space (not task queues):                          â”‚
â”‚  â”œâ”€ Redis Pub/Sub  â†’ Event broadcasting (no persistence)       â”‚
â”‚  â”œâ”€ RabbitMQ       â†’ Enterprise message broker                 â”‚
â”‚  â””â”€ Kafka          â†’ Distributed event streaming               â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4.2 FastAPI BackgroundTasks (Recap & Positioning)

**You learned this in Lecture 1. Here's where it fits.**

```python
from fastapi import BackgroundTasks

@app.post("/tasks/{task_id}/complete")
async def complete_task(
    task_id: int,
    background_tasks: BackgroundTasks,
):
    task = await do_complete(task_id)

    # Side effect runs AFTER response is sent
    background_tasks.add_task(send_notification, task.assignee_id)

    return task
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FASTAPI BACKGROUNDTASKS                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  âœ… Strengths:                                                  â”‚
â”‚  â”œâ”€ Zero setup. No broker. No worker process.                  â”‚
â”‚  â”œâ”€ Built into FastAPI. Import and use.                        â”‚
â”‚  â”œâ”€ Perfect for "send email after responding to user."         â”‚
â”‚  â””â”€ Async or sync functions both work.                         â”‚
â”‚                                                                 â”‚
â”‚  âŒ Weaknesses:                                                 â”‚
â”‚  â”œâ”€ NO persistence. If the process crashes, task is lost.      â”‚
â”‚  â”œâ”€ NO retry logic. Fails once â†’ gone forever.                 â”‚
â”‚  â”œâ”€ NO scheduling. Cannot run "every Monday at 9am."           â”‚
â”‚  â”œâ”€ NO monitoring. No way to see pending/failed tasks.         â”‚
â”‚  â”œâ”€ Runs in the SAME process as your API.                      â”‚
â”‚  â”‚   Heavy background work slows down your request handling.   â”‚
â”‚  â””â”€ NO distributed execution. One server only.                 â”‚
â”‚                                                                 â”‚
â”‚  ğŸ“ Position: The "good enough for simple things" option.       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4.3 Celery (Recap & Positioning)

**You've spent two lectures on Celery. Here's the honest assessment.**

```python
# What you've been writing:
@celery_app.task(bind=True, max_retries=3, default_retry_delay=60)
def send_notification_email(self, user_id: int, title: str) -> None:
    try:
        user = get_user_sync(user_id)  # â† sync call
        send_email_sync(user.email, f"Task completed: {title}")
    except Exception as exc:
        self.retry(exc=exc)
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CELERY                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  âœ… Strengths:                                                  â”‚
â”‚  â”œâ”€ Industry standard. Used at Instagram, Mozilla, Robinhood.  â”‚
â”‚  â”œâ”€ Battle-tested for 15+ years. Known failure modes.          â”‚
â”‚  â”œâ”€ Rich ecosystem: retry, scheduling (Beat), monitoring       â”‚
â”‚  â”‚   (Flower), result backends, rate limiting.                 â”‚
â”‚  â”œâ”€ Multiple broker support (Redis, RabbitMQ, SQS).            â”‚
â”‚  â”œâ”€ Excellent documentation and community support.             â”‚
â”‚  â””â”€ Tasks persist in broker until a worker picks them up.      â”‚
â”‚                                                                 â”‚
â”‚  âŒ Weaknesses:                                                 â”‚
â”‚  â”œâ”€ SYNC-FIRST ARCHITECTURE.                                   â”‚
â”‚  â”‚   Workers run synchronous code by default.                  â”‚
â”‚  â”‚   Running async code in Celery requires workarounds.        â”‚
â”‚  â”‚   This is awkward when your ENTIRE APP is async.            â”‚
â”‚  â”œâ”€ Heavy setup: separate worker process, broker, Beat.        â”‚
â”‚  â”œâ”€ No type hints on task signatures (task.delay(x, y)         â”‚
â”‚  â”‚   gives no autocomplete, no type checking).                 â”‚
â”‚  â”œâ”€ Task arguments must be serializable (JSON/pickle).         â”‚
â”‚  â”‚   No Pydantic models, no SQLAlchemy objects.                â”‚
â”‚  â””â”€ Configuration is complex (many settings to tune).          â”‚
â”‚                                                                 â”‚
â”‚  ğŸ“ Position: The safe choice. Never wrong. Sometimes clunky.   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The async problem with Celery â€” why alternatives emerged:**

```python
# Your FastAPI app is async. Everything is async.
# Async endpoint â†’ async SQLAlchemy â†’ async Redis â†’ async httpx

# But Celery tasks are sync:
@celery_app.task
def process_data(data_id: int):
    # To use async code here, you need workarounds:
    import asyncio
    result = asyncio.run(async_process(data_id))
    # This creates a NEW event loop per task.
    # It works, but it's inelegant and loses the benefits
    # of connection sharing, async context, etc.
```

> "Celery was designed before Python had async/await. It's sync at its core. Your entire application is async. This mismatch is real, and it's the reason tools like Taskiq and ARQ exist."

---

## 4.4 Taskiq â€” The Async-Native Alternative

**Taskiq is what you'd get if you redesigned Celery with async and type safety as first-class priorities.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        TASKIQ                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  CORE IDEA: Celery, but async-native and type-hinted.           â”‚
â”‚                                                                 â”‚
â”‚  â€¢ Tasks are async functions (no workarounds needed)            â”‚
â”‚  â€¢ Task parameters have type hints (IDE autocomplete works)     â”‚
â”‚  â€¢ Return types are preserved (type-checked results)            â”‚
â”‚  â€¢ FastAPI integration via taskiq-fastapi                       â”‚
â”‚  â€¢ Multiple broker support (Redis, RabbitMQ, Kafka, etc.)       â”‚
â”‚  â€¢ Middleware system (logging, metrics, error handling)          â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Setup and task definition:**

```python
# broker.py
from taskiq_redis import ListQueueBroker, RedisAsyncResultBackend

# Same Redis you're already running
result_backend = RedisAsyncResultBackend(
    redis_url="redis://localhost:6379/1",
)

broker = ListQueueBroker(
    url="redis://localhost:6379/0",
).with_result_backend(result_backend)
```

```python
# tasks.py
from broker import broker


@broker.task(retry_on_error=True, max_retries=3)
async def send_notification_email(user_id: int, title: str) -> bool:
    """
    Notice:
    1. This is an async function. Your async DB, Redis, httpx â€” all work.
    2. Parameters are type-hinted. IDE knows user_id is int.
    3. Return type is declared. Result is typed.
    """
    user = await async_get_user(user_id)    # Async DB call â€” natural
    await async_send_email(                  # Async HTTP call â€” natural
        to=user.email,
        subject=f"Task completed: {title}",
    )
    return True


@broker.task
async def generate_report(project_id: int) -> dict:
    async with get_async_session() as db:    # Async SQLAlchemy â€” natural
        stats = await compute_project_stats(db, project_id)
    return stats
```

**Calling tasks â€” compare with Celery:**

```python
# Celery â€” you've been doing this:
send_notification_email.delay(user_id=3, title="Fix bug")
#                       ^^^^^ No type hints. No autocomplete.
#                             IDE doesn't know the args.

# Taskiq â€” kiq (kick) instead of delay:
await send_notification_email.kiq(user_id=3, title="Fix bug")
#                              ^^^ Async call.
#                                  Type-checked by IDE.
#                                  Autocomplete works.
```

**Getting results:**

```python
# Celery:
result = send_notification_email.delay(3, "Fix bug")
value = result.get(timeout=10)  # Blocks the calling thread!

# Taskiq:
task_handle = await send_notification_email.kiq(user_id=3, title="Fix bug")
result = await task_handle.wait_result(timeout=10)  # Async wait!

if result.is_err:
    print(f"Task failed: {result.error}")
else:
    print(f"Task result: {result.return_value}")  # Typed as bool
```

**FastAPI integration:**

```python
# With taskiq-fastapi, tasks can access FastAPI dependencies
from taskiq_fastapi import InjectDependency
from app.dependencies import get_db, get_redis


@broker.task
async def process_with_deps(
    task_id: int,
    db: AsyncSession = InjectDependency(get_db),      # â† FastAPI dep!
    redis: Redis = InjectDependency(get_redis),        # â† FastAPI dep!
) -> None:
    """Task has access to the same dependencies as your endpoints."""
    task = await task_repo.get(db, task_id)
    await redis.delete(f"task:{task_id}")
```

**Running a Taskiq worker:**

```bash
# Very similar to Celery:
# Celery:  celery -A app.celery_app worker --loglevel=info
# Taskiq:  taskiq worker app.broker:broker
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  âœ… Strengths:                                                  â”‚
â”‚  â”œâ”€ Async-native: tasks are async def, no workarounds.         â”‚
â”‚  â”œâ”€ Type-hinted: IDE autocomplete, type checking.              â”‚
â”‚  â”œâ”€ FastAPI integration: shared dependencies.                  â”‚
â”‚  â”œâ”€ Multiple brokers: Redis, RabbitMQ, Kafka, NATS.            â”‚
â”‚  â””â”€ Middleware system for cross-cutting concerns.              â”‚
â”‚                                                                 â”‚
â”‚  âŒ Weaknesses:                                                 â”‚
â”‚  â”œâ”€ Younger ecosystem. Less battle-tested than Celery.         â”‚
â”‚  â”œâ”€ Smaller community. Fewer Stack Overflow answers.           â”‚
â”‚  â”œâ”€ Scheduling (cron) is less mature than Celery Beat.         â”‚
â”‚  â””â”€ Less tooling (no Flower equivalent yet).                   â”‚
â”‚                                                                 â”‚
â”‚  ğŸ“ Position: The modern choice for async-first Python apps.    â”‚
â”‚     Growing fast. Production-ready. Not yet "default."          â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4.5 ARQ â€” The Lightweight Option

**ARQ is the minimalist's task queue. Redis-only, async-only, simple.**

Built by Samuel Colvin â€” the same person who created Pydantic.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          ARQ                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  CORE IDEA: What if a task queue was just...                    â”‚
â”‚             async functions + Redis? That's it.                 â”‚
â”‚                                                                 â”‚
â”‚  â€¢ No broker abstraction. Redis IS the broker.                  â”‚
â”‚  â€¢ Tasks are plain async functions with a ctx parameter.        â”‚
â”‚  â€¢ Pessimistic execution: assumes tasks can fail.               â”‚
â”‚  â€¢ At-least-once delivery: guarantees processing.               â”‚
â”‚  â€¢ Built on Redis streams (not Pub/Sub â€” persistent).           â”‚
â”‚  â€¢ Cron-style scheduling built in.                              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Task definition â€” just write async functions:**

```python
# tasks.py

async def send_notification_email(
    ctx: dict,                 # â† ARQ always passes a context dict
    user_id: int,
    title: str,
) -> bool:
    """
    This is a plain async function. Not decorated.
    The ctx dict contains: redis connection, job metadata.
    """
    redis = ctx["redis"]  # ARQ provides a Redis connection
    user_data = await redis.get(f"user:{user_id}")
    # ... send email ...
    return True


async def generate_report(ctx: dict, project_id: int) -> dict:
    """Another plain async function."""
    # ... async work ...
    return {"project_id": project_id, "status": "done"}
```

**Worker configuration â€” a single class:**

```python
# worker.py
from arq import cron
from arq.connections import RedisSettings

from tasks import send_notification_email, generate_report


class WorkerSettings:
    """All worker config in one place."""

    # Register available task functions
    functions = [send_notification_email, generate_report]

    # Cron jobs (like Celery Beat, but built-in)
    cron_jobs = [
        cron(generate_report, hour=9, minute=0, project_id=1),  # Daily at 9am
    ]

    # Redis connection
    redis_settings = RedisSettings(
        host="localhost",
        port=6379,
        database=0,
    )

    # Timeouts
    max_jobs = 10           # Max concurrent jobs
    job_timeout = 300       # 5 minutes per job
    retry_jobs = True       # Retry failed jobs
    max_tries = 3           # Up to 3 attempts
```

**Enqueuing jobs:**

```python
from arq.connections import ArqRedis, create_pool, RedisSettings


async def enqueue_example() -> None:
    pool: ArqRedis = await create_pool(RedisSettings())

    # Enqueue a job â€” type-safe pool call
    job = await pool.enqueue_job(
        "send_notification_email",  # Function name as string
        user_id=3,
        title="Fix login bug",
    )

    print(f"Job ID: {job.job_id}")

    # Optionally wait for result
    result = await job.result(timeout=30)
    print(f"Result: {result}")
```

**Running the worker:**

```bash
arq worker.WorkerSettings
```

**The "pessimistic execution" model:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PESSIMISTIC EXECUTION                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  ARQ assumes the worst:                                         â”‚
â”‚                                                                 â”‚
â”‚  "This task will probably fail. Let me prepare for that."       â”‚
â”‚                                                                 â”‚
â”‚  1. Job is enqueued â†’ stored in Redis stream (persistent)       â”‚
â”‚  2. Worker picks up job â†’ marks it as "in progress"             â”‚
â”‚  3. If worker crashes â†’ job is NOT acknowledged                 â”‚
â”‚     â†’ Redis knows it wasn't completed                          â”‚
â”‚     â†’ Another worker can pick it up (at-least-once delivery)   â”‚
â”‚  4. If job succeeds â†’ result stored, job marked complete        â”‚
â”‚  5. If job fails â†’ retry according to max_tries                 â”‚
â”‚                                                                 â”‚
â”‚  Compare to Redis Pub/Sub:                                      â”‚
â”‚  Pub/Sub assumes the best: "Someone will hear this."           â”‚
â”‚  ARQ assumes the worst: "This might fail. Let me be safe."     â”‚
â”‚                                                                 â”‚
â”‚  "At-least-once" means: a job might run MORE than once          â”‚
â”‚  (if the worker crashes after completing but before             â”‚
â”‚  acknowledging). Your tasks should be IDEMPOTENT                â”‚
â”‚  (Lecture 2 callback â€” idempotent task design).                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  âœ… Strengths:                                                  â”‚
â”‚  â”œâ”€ Dead simple. Minimal API, easy to understand.              â”‚
â”‚  â”œâ”€ Async-first. Tasks are plain async functions.              â”‚
â”‚  â”œâ”€ Built-in cron scheduling (no separate Beat process).       â”‚
â”‚  â”œâ”€ Persistent: uses Redis streams, not Pub/Sub.               â”‚
â”‚  â”œâ”€ At-least-once delivery. Jobs don't silently vanish.        â”‚
â”‚  â””â”€ Built by the Pydantic creator (quality, thoughtful API).   â”‚
â”‚                                                                 â”‚
â”‚  âŒ Weaknesses:                                                 â”‚
â”‚  â”œâ”€ Redis-only. Cannot use RabbitMQ, SQS, or Kafka.           â”‚
â”‚  â”œâ”€ Smaller ecosystem than Celery (fewer plugins, middleware). â”‚
â”‚  â”œâ”€ Task name is a string at enqueue time (no autocomplete).   â”‚
â”‚  â”œâ”€ Less flexible routing (no priority queues, exchanges).     â”‚
â”‚  â””â”€ Smaller community. Less documentation.                     â”‚
â”‚                                                                 â”‚
â”‚  ğŸ“ Position: The "simple and correct" option.                   â”‚
â”‚     When Celery is overkill and BackgroundTasks isn't enough.   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4.6 The Decision Framework

**Now the question that matters: WHICH ONE DO I USE?**

Evaluate along three axes:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               THREE-AXIS DECISION FRAMEWORK                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  AXIS 1: COMPLEXITY OF YOUR NEEDS                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                              â”‚
â”‚  Low:  "Run this after the response."                           â”‚
â”‚  Med:  "Retry on failure, schedule weekly."                     â”‚
â”‚  High: "Priority queues, rate limiting, complex routing,        â”‚
â”‚         multiple worker types, result chaining."                â”‚
â”‚                                                                 â”‚
â”‚  AXIS 2: ASYNC-NATIVENESS                                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                       â”‚
â”‚  Low:  "Doesn't matter, sync tasks are fine."                   â”‚
â”‚  Med:  "Nice to have, but I can work around it."                â”‚
â”‚  High: "My entire stack is async. I don't want sync anywhere." â”‚
â”‚                                                                 â”‚
â”‚  AXIS 3: ECOSYSTEM MATURITY                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚  Low:  "I'm comfortable being an early adopter."                â”‚
â”‚  Med:  "I want stable with decent docs."                        â”‚
â”‚  High: "I need stack overflow answers, corporate backing,       â”‚
â”‚         and a tool that's been in production for 10+ years."    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The decision matrix:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚                    Complexity    Async-    Ecosystem             â”‚
â”‚  Tool              of Needs     Native    Maturity              â”‚
â”‚  â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€     â”€â”€â”€â”€â”€â”€    â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”‚
â”‚  BackgroundTasks   Low          âœ… Yes    âœ… FastAPI built-in    â”‚
â”‚  ARQ               Low-Med      âœ… Yes    âš ï¸  Small community    â”‚
â”‚  Taskiq            Med-High     âœ… Yes    âš ï¸  Growing fast       â”‚
â”‚  Celery            Med-High     âŒ No     âœ… Industry standard   â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  QUICK PICKS:                                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                   â”‚
â”‚                                                                 â”‚
â”‚  "I just need a simple side effect after a response."           â”‚
â”‚  â†’ FastAPI BackgroundTasks. Done.                               â”‚
â”‚                                                                 â”‚
â”‚  "I need retries, scheduling, and my app is fully async."       â”‚
â”‚  â†’ Taskiq if you want typed + async.                            â”‚
â”‚  â†’ ARQ if you want simple + async and only use Redis.           â”‚
â”‚                                                                 â”‚
â”‚  "I'm at a company. We need proven. We need Flower.             â”‚
â”‚   We need 50 Stack Overflow answers per problem."               â”‚
â”‚  â†’ Celery. It's not sexy, but it's reliable.                    â”‚
â”‚                                                                 â”‚
â”‚  "I just need to broadcast events, not assign tasks."           â”‚
â”‚  â†’ Redis Pub/Sub. Different tool, different purpose.            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**And the visual decision tree:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PICK YOUR TOOL                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚                      START HERE                                 â”‚
â”‚                          â”‚                                      â”‚
â”‚                          â–¼                                      â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚              â”‚ Do I need persistence â”‚                           â”‚
â”‚              â”‚ (survive crashes)?    â”‚                           â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                   â”‚            â”‚                                â”‚
â”‚                  NO           YES                               â”‚
â”‚                   â”‚            â”‚                                â”‚
â”‚                   â–¼            â–¼                                â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚         â”‚ Is it a task  â”‚  â”‚ Is your entire    â”‚                 â”‚
â”‚         â”‚ or an event?  â”‚  â”‚ stack async?      â”‚                 â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚             â”‚       â”‚            â”‚         â”‚                    â”‚
â”‚           Task    Event        YES        NO                   â”‚
â”‚             â”‚       â”‚            â”‚         â”‚                    â”‚
â”‚             â–¼       â–¼            â–¼         â–¼                    â”‚
â”‚      Background  Redis       â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”                â”‚
â”‚        Tasks     Pub/Sub     â”‚ Need â”‚  â”‚      â”‚                â”‚
â”‚                              â”‚complexâ”‚  â”‚Celeryâ”‚                â”‚
â”‚                              â”‚featuresâ”‚  â”‚      â”‚                â”‚
â”‚                              â””â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                              â”‚     â”‚                           â”‚
â”‚                            YES     NO                          â”‚
â”‚                              â”‚     â”‚                           â”‚
â”‚                              â–¼     â–¼                           â”‚
â”‚                           Taskiq  ARQ                          â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Side-by-side comparison â€” same task, four tools:**

```python
# â”€â”€ THE TASK: Send a notification email with retry â”€â”€

# 1. FastAPI BackgroundTasks (no retry possible)
@app.post("/tasks/{task_id}/complete")
async def complete(task_id: int, bg: BackgroundTasks):
    task = await do_complete(task_id)
    bg.add_task(send_email, task.assignee_id, task.title)
    return task

# 2. Celery (sync task, sync email)
@celery_app.task(bind=True, max_retries=3, default_retry_delay=60)
def send_email_task(self, user_id: int, title: str):
    try:
        send_email_sync(user_id, title)
    except Exception as exc:
        self.retry(exc=exc)

# 3. Taskiq (async task, async email)
@broker.task(retry_on_error=True, max_retries=3)
async def send_email_task(user_id: int, title: str) -> bool:
    await send_email_async(user_id, title)
    return True

# 4. ARQ (async function, retry via config)
async def send_email_task(ctx: dict, user_id: int, title: str):
    await send_email_async(user_id, title)
# retry configured in WorkerSettings: max_tries=3
```

---

# PART 5: COMMON MISTAKES AND MISCONCEPTIONS

### Mistake 1: Using Redis Pub/Sub when you need guaranteed delivery

```python
# âŒ DANGEROUS: Billing event via Pub/Sub
async def process_payment(order_id: int, redis: Redis):
    await charge_credit_card(order_id)

    # If NO subscriber is connected right now, this event is LOST.
    # The customer was charged, but the order is never marked as paid.
    await redis.publish("order.paid", json.dumps({"order_id": order_id}))

# âœ… CORRECT: Use a persistent task queue for critical events
await process_order_payment.kiq(order_id=order_id)  # Taskiq
# or
process_order_payment.delay(order_id)                # Celery
```

> "If losing the message means losing money, losing compliance, or losing data â€” it needs a persistent queue, not Pub/Sub."

---

### Mistake 2: Blocking the event loop inside a subscriber

```python
# âŒ WRONG: Blocking call inside async subscriber handler
async def on_task_completed_send_email(event: dict):
    user = requests.get(f"/api/users/{event['assignee_id']}")  # BLOCKS!
    # All other event handlers are frozen while this completes.
    # If you have 10 events queued, they ALL wait for this HTTP call.

# âœ… CORRECT: Use async libraries inside async handlers
async def on_task_completed_send_email(event: dict):
    async with httpx.AsyncClient() as client:                  # Non-blocking
        response = await client.get(f"/api/users/{event['assignee_id']}")
```

This is the same lesson from Week 1, Lecture 3 â€” blocking calls in async code freeze the event loop. Inside a pub/sub subscriber, this is especially damaging because it stalls ALL event processing, not just one request.

---

### Mistake 3: Unstructured events (no schema)

```python
# âŒ BAD: Different publishers send different shapes
# Publisher A:
await redis.publish("task.completed", json.dumps({"id": 42}))
# Publisher B:
await redis.publish("task.completed", json.dumps({"task_id": 42, "name": "Fix bug"}))
# Subscriber has no idea what fields to expect.

# âœ… GOOD: Enforce schema with Pydantic (you already know this)
class TaskCompletedEvent(BaseModel):
    task_id: int
    project_id: int
    assignee_id: int
    title: str

# Publisher:
event = TaskCompletedEvent(task_id=42, project_id=7, assignee_id=3, title="Fix bug")
await redis.publish("task.completed", event.model_dump_json())

# Subscriber:
event = TaskCompletedEvent.model_validate_json(raw_data)
# Now you KNOW what fields exist. Pydantic validates it.
```

---

### Mistake 4: Over-engineering (Kafka for 100 events/day)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  Your traffic:     100 events / day                             â”‚
â”‚  Kafka designed:   millions of events / second                  â”‚
â”‚                                                                 â”‚
â”‚  Kafka requires:                                                â”‚
â”‚  â”œâ”€ ZooKeeper (or KRaft) cluster                               â”‚
â”‚  â”œâ”€ Broker cluster (minimum 3 nodes for replication)           â”‚
â”‚  â”œâ”€ Schema registry                                            â”‚
â”‚  â”œâ”€ Ops knowledge to manage partitions, replication, ISR       â”‚
â”‚  â””â”€ At least one person whose job is "Kafka admin"             â”‚
â”‚                                                                 â”‚
â”‚  Redis Pub/Sub + Celery requires:                               â”‚
â”‚  â”œâ”€ Redis (you already have it)                                â”‚
â”‚  â””â”€ That's it.                                                 â”‚
â”‚                                                                 â”‚
â”‚  Don't build infrastructure for problems you don't have.        â”‚
â”‚  Scale is a GOOD problem. Solve it when it arrives.             â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Mistake 5: Confusing task queues with event streams

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          TASK QUEUE â‰  EVENT STREAM                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  TASK QUEUE (Celery, Taskiq, ARQ):                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                      â”‚
â”‚  "Hey worker, DO this specific thing."                          â”‚
â”‚  One task â†’ one worker processes it â†’ done.                     â”‚
â”‚  The task is CONSUMED. No one else sees it.                     â”‚
â”‚                                                                 â”‚
â”‚  Analogy: Postal letter â†’ one recipient.                        â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  EVENT STREAM (Pub/Sub, Kafka):                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                   â”‚
â”‚  "Hey everyone, this thing HAPPENED."                           â”‚
â”‚  One event â†’ ALL subscribers see it â†’ each reacts differently.  â”‚
â”‚  The event is BROADCAST, not consumed by one.                   â”‚
â”‚                                                                 â”‚
â”‚  Analogy: Radio broadcast â†’ all listeners.                      â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  COMMON MISTAKE:                                                â”‚
â”‚  Using Pub/Sub to distribute tasks â†’ multiple subscribers       â”‚
â”‚  all process the same task â†’ duplicate work.                    â”‚
â”‚                                                                 â”‚
â”‚  Using a task queue to broadcast events â†’ only one worker       â”‚
â”‚  processes the event â†’ other systems never learn about it.      â”‚
â”‚                                                                 â”‚
â”‚  Use the right tool for the communication pattern.              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Quick Reference Card

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               EVENT-DRIVEN QUICK REFERENCE                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  PUBLISH EVENT (Redis Pub/Sub):                                 â”‚
â”‚      await redis.publish("channel.name", json_string)           â”‚
â”‚                                                                 â”‚
â”‚  SUBSCRIBE TO EVENTS:                                           â”‚
â”‚      pubsub = redis.pubsub()                                    â”‚
â”‚      await pubsub.subscribe("channel.name")                     â”‚
â”‚      async for msg in pubsub.listen():                          â”‚
â”‚          if msg["type"] == "message": ...                       â”‚
â”‚                                                                 â”‚
â”‚  PATTERN SUBSCRIBE:                                             â”‚
â”‚      await pubsub.psubscribe("task.*")                          â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  TOOL CHEAT SHEET:                                              â”‚
â”‚                                                                 â”‚
â”‚  "Simple side effect, no retry"                                 â”‚
â”‚      â†’ FastAPI BackgroundTasks                                  â”‚
â”‚                                                                 â”‚
â”‚  "Persistent tasks, proven ecosystem, sync OK"                  â”‚
â”‚      â†’ Celery                                                   â”‚
â”‚                                                                 â”‚
â”‚  "Persistent tasks, async-native, typed"                        â”‚
â”‚      â†’ Taskiq                                                   â”‚
â”‚                                                                 â”‚
â”‚  "Persistent tasks, async, Redis-only, simple"                  â”‚
â”‚      â†’ ARQ                                                      â”‚
â”‚                                                                 â”‚
â”‚  "Broadcast events, no persistence needed"                      â”‚
â”‚      â†’ Redis Pub/Sub                                            â”‚
â”‚                                                                 â”‚
â”‚  "Broadcast events, persistence + replay needed"                â”‚
â”‚      â†’ Kafka (but do you really need it?)                       â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  KEY PATTERNS:                                                  â”‚
â”‚  â”œâ”€ Pub/Sub: decouple producers from consumers                 â”‚
â”‚  â”œâ”€ Event Sourcing: store events, derive state                 â”‚
â”‚  â”œâ”€ CQRS: separate read model from write model                 â”‚
â”‚  â””â”€ Commands vs Events: "do this" vs "this happened"           â”‚
â”‚                                                                 â”‚
â”‚  CRITICAL RULE:                                                 â”‚
â”‚  If losing a message has business consequences,                 â”‚
â”‚  do NOT use Redis Pub/Sub. Use a persistent queue.              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Summary: The Key Mental Model

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  EVENT-DRIVEN = DON'T CALL. ANNOUNCE.                           â”‚
â”‚                                                                 â”‚
â”‚  Instead of your code calling every system that cares,          â”‚
â”‚  your code announces what happened. Systems that care           â”‚
â”‚  subscribe and handle it themselves.                            â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  "task done"  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚ Your Code â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚ Event Bus â”‚                      â”‚
â”‚  â”‚           â”‚               â”‚ (broker)  â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                                    â”‚                            â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚                    â”‚               â”‚               â”‚            â”‚
â”‚                    â–¼               â–¼               â–¼            â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚              â”‚  Email   â”‚   â”‚  Cache   â”‚   â”‚  Audit   â”‚         â”‚
â”‚              â”‚  Handler â”‚   â”‚  Handler â”‚   â”‚  Handler â”‚         â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                 â”‚
â”‚  THE RADIO STATION ANALOGY:                                     â”‚
â”‚  â”œâ”€ Commands = Postal service ("you, specifically, do this")    â”‚
â”‚  â”œâ”€ Events = Radio broadcast ("this happened, FYI")             â”‚
â”‚  â”œâ”€ Pub/Sub = Live radio (miss it, it's gone)                   â”‚
â”‚  â”œâ”€ Kafka = Newspaper archive (read any past issue)             â”‚
â”‚  â”œâ”€ Celery = Postal service (guaranteed delivery, directed)     â”‚
â”‚  â””â”€ Taskiq/ARQ = Modern postal (same delivery, async staff)     â”‚
â”‚                                                                 â”‚
â”‚  THERE IS NO "BEST" TOOL. THERE IS ONLY "RIGHT FOR THE JOB."  â”‚
â”‚  Match the tool to the problem, not the other way around.       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Connection to Upcoming Lectures

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WHERE THIS LEADS                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  WEEK 11 PROJECT (This week):                                   â”‚
â”‚  â””â”€ Background Processing Pipeline                              â”‚
â”‚     You'll implement event-triggered notifications,             â”‚
â”‚     scheduled jobs, and choose between task queue tools.        â”‚
â”‚     The decision framework from 4.6 is your guide.             â”‚
â”‚                                                                 â”‚
â”‚  WEEK 12: WebSockets & Real-Time                                â”‚
â”‚  â””â”€ Redis Pub/Sub becomes your backbone for scaling WebSockets. â”‚
â”‚     When a task is completed on Server A, the event goes        â”‚
â”‚     through Pub/Sub to Server B which has the WebSocket         â”‚
â”‚     connection to the user. This pattern is EVERYWHERE.         â”‚
â”‚                                                                 â”‚
â”‚  WEEK 12: Performance & Load Testing                            â”‚
â”‚  â””â”€ You'll measure the impact of moving side effects out        â”‚
â”‚     of the request path. Response times drop dramatically       â”‚
â”‚     when your endpoint publishes an event instead of doing      â”‚
â”‚     6 side effects synchronously.                               â”‚
â”‚                                                                 â”‚
â”‚  WEEK 13-14: Capstone SaaS Platform                             â”‚
â”‚  â””â”€ Your capstone requires real-time notifications              â”‚
â”‚     (WebSocket + Pub/Sub), background jobs (Celery or           â”‚
â”‚     Taskiq), and audit logging. Everything from today           â”‚
â”‚     is load-bearing architecture in your final project.         â”‚
â”‚                                                                 â”‚
â”‚  WEEK 16: System Design                                         â”‚
â”‚  â””â”€ Event-driven architecture, CQRS, and event sourcing        â”‚
â”‚     are staple topics in system design interviews.              â”‚
â”‚     Today gave you the vocabulary and mental models.            â”‚
â”‚     Week 16 teaches you how to draw them on a whiteboard.       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```