# LECTURE DESIGN PHILOSOPHY

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PEDAGOGICAL APPROACH                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  ZOOM OUT, NOT UP                                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                               â”‚
â”‚  For 15 weeks, students have lived INSIDE a single server.      â”‚
â”‚  Today we step outside and look at the building from above.     â”‚
â”‚  Every concept maps back to code they've already written.       â”‚
â”‚                                                                 â”‚
â”‚  NUMBERS BEFORE THEORY                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚
â”‚  Students must CALCULATE why one server fails before we         â”‚
â”‚  teach them how to add more. No hand-waving.                    â”‚
â”‚                                                                 â”‚
â”‚  ANALOGY-DRIVEN                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                 â”‚
â”‚  We extend Week 1's restaurant to a RESTAURANT CHAIN.           â”‚
â”‚  Every system design concept maps to growing a business.        â”‚
â”‚                                                                 â”‚
â”‚  TRADEOFFS, NOT ANSWERS                                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                         â”‚
â”‚  System design has no "correct" solution. Only tradeoffs.       â”‚
â”‚  We teach students to CHOOSE and JUSTIFY, not memorize.         â”‚
â”‚                                                                 â”‚
â”‚  CONNECT EVERYTHING                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                               â”‚
â”‚  JWT, Redis, Celery, Docker, async â€” students have built all    â”‚
â”‚  the pieces. Today they see how those pieces form a machine.    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# LECTURE OUTLINE

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 SYSTEM DESIGN FUNDAMENTALS                      â”‚
â”‚                     (3.5-4 Hour Lecture)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  PART 1: THE BREAKING POINT (45 min)                            â”‚
â”‚  â”œâ”€ 1.1 Your Capstone Under Siege                               â”‚
â”‚  â”œâ”€ 1.2 What is System Design?                                  â”‚
â”‚  â”œâ”€ 1.3 The Restaurant Chain Analogy                            â”‚
â”‚  â”œâ”€ 1.4 The Framework (Requirements â†’ Estimation â†’ Design       â”‚
â”‚  â”‚       â†’ Tradeoffs)                                           â”‚
â”‚  â””â”€ 1.5 Back-of-Envelope Estimation                             â”‚
â”‚                                                                 â”‚
â”‚  PART 2: SCALING YOUR SERVERS (50 min)                          â”‚
â”‚  â”œâ”€ 2.1 Vertical Scaling (A Bigger Restaurant)                  â”‚
â”‚  â”œâ”€ 2.2 Horizontal Scaling (More Locations)                     â”‚
â”‚  â”œâ”€ 2.3 The State Problem (Why Horizontal Is Hard)              â”‚
â”‚  â”œâ”€ 2.4 Load Balancers (The Central Reservation System)         â”‚
â”‚  â”œâ”€ 2.5 Load Balancing Algorithms                               â”‚
â”‚  â””â”€ 2.6 Health Checks (Is This Location Open?)                  â”‚
â”‚                                                                 â”‚
â”‚  PART 3: SCALING YOUR DATABASE (50 min)                         â”‚
â”‚  â”œâ”€ 3.1 The Database Bottleneck                                 â”‚
â”‚  â”œâ”€ 3.2 Read Replicas (Copies of the Recipe Book)               â”‚
â”‚  â”œâ”€ 3.3 Replication Lag (The Update Delay)                      â”‚
â”‚  â”œâ”€ 3.4 Sharding (Splitting the Kitchen)                        â”‚
â”‚  â”œâ”€ 3.5 Sharding Strategies                                     â”‚
â”‚  â””â”€ 3.6 The Decision Framework                                  â”‚
â”‚                                                                 â”‚
â”‚  PART 4: CACHING AT EVERY LAYER (40 min)                        â”‚
â”‚  â”œâ”€ 4.1 The Caching Hierarchy                                   â”‚
â”‚  â”œâ”€ 4.2 CDN (The Menu Board Outside the Building)               â”‚
â”‚  â”œâ”€ 4.3 Application Cache (Your Redis Knowledge)                â”‚
â”‚  â”œâ”€ 4.4 Database-Level Caching                                  â”‚
â”‚  â””â”€ 4.5 Cache Invalidation (The Hardest Problem)                â”‚
â”‚                                                                 â”‚
â”‚  PART 5: CAP THEOREM & DESIGN THINKING (40 min)                 â”‚
â”‚  â”œâ”€ 5.1 The CAP Theorem                                         â”‚
â”‚  â”œâ”€ 5.2 CP vs AP in Practice                                    â”‚
â”‚  â”œâ”€ 5.3 Everything is a Tradeoff                                â”‚
â”‚  â””â”€ 5.4 Full Architecture â€” Putting It All Together             â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# PART 1: THE BREAKING POINT

## 1.1 Your Capstone Under Siege

**Start by putting their own project on trial. Make it personal.**

Draw the architecture of their capstone on the whiteboard:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            YOUR CAPSTONE RIGHT NOW (Week 13-14)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                        â”‚ Client  â”‚                              â”‚
â”‚                        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                              â”‚
â”‚                             â”‚                                   â”‚
â”‚                             â–¼                                   â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚                   â”‚   ONE SERVER     â”‚                           â”‚
â”‚                   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                           â”‚
â”‚                   â”‚  â”‚  FastAPI   â”‚  â”‚                           â”‚
â”‚                   â”‚  â”‚  Celery    â”‚  â”‚                           â”‚
â”‚                   â”‚  â”‚  Redis     â”‚  â”‚                           â”‚
â”‚                   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                           â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                            â”‚                                    â”‚
â”‚                            â–¼                                    â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚                   â”‚   PostgreSQL     â”‚                           â”‚
â”‚                   â”‚  (ONE instance)  â”‚                           â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                                                                 â”‚
â”‚   This is EVERYTHING on ONE machine.                            â”‚
â”‚   Your API, your workers, your cache, your database.            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Now ask the class:**

> "Your capstone is deployed. It works. Your load test from Week 12 showed it handles 500 requests/min with <200ms p95. You're proud of it. Now imagine you post it on Hacker News and it goes viral. What happens?"

Pause. Let them think.

> "Let's not guess. Let's do math."

**Walk through the numbers â€” scale progression:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              YOUR CAPSTONE AT DIFFERENT SCALES                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  USERS      DAU       REQ/DAY       PEAK REQ/SEC    STATUS     â”‚
â”‚  â”€â”€â”€â”€â”€â”€     â”€â”€â”€       â”€â”€â”€â”€â”€â”€â”€       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”€â”€â”€â”€â”€â”€     â”‚
â”‚  1,000      100       5,000         ~1              ğŸ˜Š Fine     â”‚
â”‚  10,000     1,000     50,000        ~6              ğŸ˜Š Fine     â”‚
â”‚  100,000    10,000    500,000       ~58             ğŸ˜ Warm     â”‚
â”‚  1,000,000  100,000   5,000,000     ~580            ğŸ˜° Trouble  â”‚
â”‚  10,000,000 1,000,000 50,000,000    ~5,800          ğŸ’€ Dead     â”‚
â”‚                                                                 â”‚
â”‚  ASSUMPTIONS:                                                   â”‚
â”‚  â”œâ”€ 10% of total users active daily (DAU)                       â”‚
â”‚  â”œâ”€ Each active user makes ~50 requests/day                     â”‚
â”‚  â”œâ”€ Peak traffic = ~4 hours where 40% of daily traffic lands    â”‚
â”‚  â””â”€ Peak RPS = (daily_requests Ã— 0.4) / (4 Ã— 3600)             â”‚
â”‚                                                                 â”‚
â”‚  YOUR LOAD TEST: 500 req/min = ~8 req/sec sustained             â”‚
â”‚                                                                 â”‚
â”‚  CONCLUSION: Your single server dies somewhere between           â”‚
â”‚              100K and 1M total users.                            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**But it's not just requests. What else breaks?**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              WHAT BREAKS AND WHY                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. CPU SATURATION                                              â”‚
â”‚     Your FastAPI process maxes out CPU.                         â”‚
â”‚     Requests queue up. Latency spikes. Timeouts.                â”‚
â”‚     Even async can't help â€” the event loop is overloaded.       â”‚
â”‚                                                                 â”‚
â”‚  2. DATABASE CONNECTIONS EXHAUSTED                              â”‚
â”‚     PostgreSQL default: max_connections = 100.                  â”‚
â”‚     Your connection pool from Week 6 fills up.                  â”‚
â”‚     New requests get "connection refused."                      â”‚
â”‚                                                                 â”‚
â”‚  3. MEMORY EXHAUSTION                                           â”‚
â”‚     Each WebSocket connection (Week 12) holds state.            â”‚
â”‚     10,000 concurrent WebSockets â‰ˆ hundreds of MB.              â”‚
â”‚     Redis, Celery workers, FastAPI â€” all compete for RAM.       â”‚
â”‚                                                                 â”‚
â”‚  4. DISK I/O BOTTLENECK                                         â”‚
â”‚     PostgreSQL writes WAL logs, indexes, temp files.            â”‚
â”‚     Heavy queries cause disk thrashing.                         â”‚
â”‚     Your EXPLAIN ANALYZE from Week 7 showed fast queries â€”      â”‚
â”‚     but that was with 1,000 rows, not 500 million.              â”‚
â”‚                                                                 â”‚
â”‚  5. SINGLE POINT OF FAILURE                                     â”‚
â”‚     Server crashes â†’ EVERYTHING goes down.                      â”‚
â”‚     Database corrupts â†’ ALL data at risk.                       â”‚
â”‚     No redundancy. No fallback. No recovery.                    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The insight:**

> "Your capstone isn't broken. It's *unscaled*. Every single decision you made â€” FastAPI, async, Redis, Celery, Docker â€” was a correct decision. But you designed it for one machine. System design is the discipline of making it work on *many* machines."

---

## 1.2 What is System Design?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WHAT IS SYSTEM DESIGN?                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  System design is the process of defining the ARCHITECTURE,     â”‚
â”‚  COMPONENTS, and DATA FLOW of a system to satisfy               â”‚
â”‚  requirements at SCALE.                                         â”‚
â”‚                                                                 â”‚
â”‚  It answers:                                                    â”‚
â”‚  â”œâ”€ How do we handle millions of users?                         â”‚
â”‚  â”œâ”€ How do we survive server failures?                          â”‚
â”‚  â”œâ”€ How do we keep responses fast as data grows?                â”‚
â”‚  â”œâ”€ How do we evolve the system without downtime?               â”‚
â”‚  â””â”€ What do we SACRIFICE to achieve the above?                  â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  WHAT IT IS NOT:                                                â”‚
â”‚  â”œâ”€ âœ— Writing code (you've done that for 15 weeks)              â”‚
â”‚  â”œâ”€ âœ— Choosing frameworks (FastAPI, SQLAlchemy â€” done)          â”‚
â”‚  â”œâ”€ âœ— A single "correct answer" (always tradeoffs)              â”‚
â”‚  â””â”€ âœ— Only relevant at Google-scale (a 10-person startup needs  â”‚
â”‚       it too â€” just different decisions)                         â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  WHAT IT IS:                                                    â”‚
â”‚  â”œâ”€ âœ“ Deciding HOW components connect                           â”‚
â”‚  â”œâ”€ âœ“ Deciding WHERE data lives                                 â”‚
â”‚  â”œâ”€ âœ“ Deciding WHAT happens when things fail                    â”‚
â”‚  â””â”€ âœ“ JUSTIFYING your choices with numbers and tradeoffs        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> "For the past 15 weeks, you've been an architect designing the interior of a building â€” the rooms, the plumbing, the wiring. System design is about designing the *city* â€” where do buildings go, how do roads connect them, what happens when a bridge collapses?"

---

## 1.3 The Restaurant Chain Analogy

**In Week 1, we used a single restaurant to explain async. Now we're growing a chain.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                THE RESTAURANT CHAIN ANALOGY                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Your capstone is a RESTAURANT.                                 â”‚
â”‚                                                                 â”‚
â”‚  Right now:                                                     â”‚
â”‚  â”œâ”€ One location                                                â”‚
â”‚  â”œâ”€ One kitchen (database)                                      â”‚
â”‚  â”œâ”€ A few waiters (async workers)                               â”‚
â”‚  â”œâ”€ One fridge for prep (Redis cache)                           â”‚
â”‚  â”œâ”€ One prep cook doing tasks overnight (Celery)                â”‚
â”‚  â””â”€ Serves 200 customers/day comfortably                        â”‚
â”‚                                                                 â”‚
â”‚  Now imagine 50,000 customers want to eat there daily.          â”‚
â”‚  What do you do?                                                â”‚
â”‚                                                                 â”‚
â”‚  OPTION A: Make the restaurant BIGGER                           â”‚
â”‚            (Vertical Scaling)                                   â”‚
â”‚                                                                 â”‚
â”‚  OPTION B: Open MORE restaurants                                â”‚
â”‚            (Horizontal Scaling)                                 â”‚
â”‚                                                                 â”‚
â”‚  This analogy will carry us through the entire lecture.          â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The mapping:**

```
Restaurant Chain             â”‚  Distributed System
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
One restaurant               â”‚  Single server
Bigger restaurant            â”‚  Vertical scaling
Multiple locations           â”‚  Horizontal scaling
Central reservation hotline  â”‚  Load balancer
Master recipe book (HQ)      â”‚  Primary database
Copies at each location      â”‚  Read replicas
Splitting by cuisine type    â”‚  Database sharding
Menu board outside building  â”‚  CDN
Daily specials board (front) â”‚  Application cache (Redis)
Pre-prepped sauce bases      â”‚  Database query cache
"Is this location open?"     â”‚  Health checks
Every location, same menu    â”‚  Consistency
Every location, always open  â”‚  Availability
Phone lines between go down  â”‚  Network partition
```

---

## 1.4 The Framework: Requirements â†’ Estimation â†’ Design â†’ Tradeoffs

**Before you design anything, you need a PROCESS. This is the system design thinking framework â€” it's also how system design interviews work:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             THE SYSTEM DESIGN FRAMEWORK                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  STEP 1: CLARIFY REQUIREMENTS (5 min in interview)              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â”‚
â”‚  â”‚                                                              â”‚
â”‚  â”œâ”€ Functional: What does it DO?                                â”‚
â”‚  â”‚  "Users create tasks, assign them, get notifications"        â”‚
â”‚  â”‚                                                              â”‚
â”‚  â””â”€ Non-Functional: What QUALITIES must it have?                â”‚
â”‚     "< 200ms latency, 99.9% uptime, 10M users"                 â”‚
â”‚                                                                 â”‚
â”‚          â”‚                                                      â”‚
â”‚          â–¼                                                      â”‚
â”‚                                                                 â”‚
â”‚  STEP 2: BACK-OF-ENVELOPE ESTIMATION (5 min)                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                           â”‚
â”‚  â”‚                                                              â”‚
â”‚  â”œâ”€ How many users? How many requests/second?                   â”‚
â”‚  â”œâ”€ How much data? How much storage?                            â”‚
â”‚  â””â”€ What bandwidth? What are the bottlenecks?                   â”‚
â”‚                                                                 â”‚
â”‚          â”‚                                                      â”‚
â”‚          â–¼                                                      â”‚
â”‚                                                                 â”‚
â”‚  STEP 3: HIGH-LEVEL DESIGN (10 min)                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚
â”‚  â”‚                                                              â”‚
â”‚  â”œâ”€ Draw the main components (boxes and arrows)                 â”‚
â”‚  â”œâ”€ Identify the data flow                                      â”‚
â”‚  â””â”€ Pick the core technologies                                  â”‚
â”‚                                                                 â”‚
â”‚          â”‚                                                      â”‚
â”‚          â–¼                                                      â”‚
â”‚                                                                 â”‚
â”‚  STEP 4: DETAILED DESIGN (15 min)                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                       â”‚
â”‚  â”‚                                                              â”‚
â”‚  â”œâ”€ Zoom into critical components                               â”‚
â”‚  â”œâ”€ Database schema, API design, caching strategy               â”‚
â”‚  â””â”€ Handle edge cases and failure modes                         â”‚
â”‚                                                                 â”‚
â”‚          â”‚                                                      â”‚
â”‚          â–¼                                                      â”‚
â”‚                                                                 â”‚
â”‚  STEP 5: IDENTIFY TRADEOFFS & BOTTLENECKS (5 min)               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                       â”‚
â”‚  â”‚                                                              â”‚
â”‚  â”œâ”€ What breaks first under 10x load?                           â”‚
â”‚  â”œâ”€ What did you sacrifice? Why is that acceptable?             â”‚
â”‚  â””â”€ What would you change with more time/budget?                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why this order?**

> "Notice: you don't draw a SINGLE box until Step 3. Most beginners jump straight to drawing diagrams. But without understanding the requirements and the scale, your diagram is fiction. You wouldn't design a restaurant without knowing if it serves 50 or 50,000 people per day."

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  FUNCTIONAL REQUIREMENTS         NON-FUNCTIONAL REQUIREMENTS    â”‚
â”‚  (What the system does)          (How well it does it)          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”‚
â”‚                                                                 â”‚
â”‚  â€¢ Users can create tasks        â€¢ 99.9% uptime                 â”‚
â”‚  â€¢ Users can assign tasks        â€¢ < 200ms p95 latency          â”‚
â”‚  â€¢ Real-time notifications       â€¢ Support 1M daily users       â”‚
â”‚  â€¢ Search and filter tasks       â€¢ Data must survive failures   â”‚
â”‚  â€¢ Export reports as CSV         â€¢ Audit trail for 7 years      â”‚
â”‚                                                                 â”‚
â”‚  These are WHAT you build.       These decide HOW you build.    â”‚
â”‚                                                                 â”‚
â”‚  You already know how to         Today is about THESE.          â”‚
â”‚  build all of these.                                            â”‚
â”‚  (You did it in your capstone.)                                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1.5 Back-of-Envelope Estimation

**This is the most underrated skill in system design. Let's work a real example using your capstone: the Project Management SaaS.**

**First, memorize these reference numbers:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               NUMBERS EVERY ENGINEER SHOULD KNOW               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  TIME                                                           â”‚
â”‚  â”€â”€â”€â”€                                                           â”‚
â”‚  1 day â‰ˆ 86,400 sec â‰ˆ 100,000 sec (for quick math)             â”‚
â”‚  1 day peak (assume 8 busy hours) = 28,800 sec â‰ˆ 30,000 sec    â”‚
â”‚                                                                 â”‚
â”‚  THROUGHPUT (rough single-machine numbers)                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                     â”‚
â”‚  FastAPI (async):           ~1,000 â€“ 10,000 req/sec             â”‚
â”‚  PostgreSQL simple reads:   ~10,000 queries/sec                 â”‚
â”‚  PostgreSQL writes:         ~1,000 â€“ 5,000 queries/sec          â”‚
â”‚  Redis operations:          ~100,000 ops/sec                    â”‚
â”‚                                                                 â”‚
â”‚  STORAGE                                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€                                                        â”‚
â”‚  1 JSON API response:       ~1-5 KB                             â”‚
â”‚  1 database row:            ~0.5-2 KB                           â”‚
â”‚  1 million rows Ã— 1KB:     ~1 GB                                â”‚
â”‚  1 billion rows Ã— 1KB:     ~1 TB                                â”‚
â”‚                                                                 â”‚
â”‚  NETWORK                                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€                                                        â”‚
â”‚  Typical server NIC:        1 Gbps â‰ˆ 125 MB/sec                â”‚
â”‚  Average API response:      ~2 KB                               â”‚
â”‚  1 Gbps / 2KB =            ~62,000 responses/sec (not the      â”‚
â”‚                              bottleneck for most apps)          â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Worked example: Your capstone at 1M total users.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        ESTIMATION: PROJECT MANAGEMENT SAAS (1M USERS)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  STEP 1: TRAFFIC                                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                â”‚
â”‚  Total users:              1,000,000                            â”‚
â”‚  Daily active (10%):       100,000                              â”‚
â”‚  Actions per user per day: ~50 (page loads, creates, edits)     â”‚
â”‚  Total requests/day:       5,000,000                            â”‚
â”‚                                                                 â”‚
â”‚  Average RPS:  5,000,000 / 86,400 â‰ˆ 58 req/sec                 â”‚
â”‚  Peak RPS (3x): â‰ˆ 175 req/sec                                  â”‚
â”‚                                                                 â”‚
â”‚  âœ… One FastAPI server can handle this (you tested ~8 RPS       â”‚
â”‚     in Week 12 load test, but that was unoptimized with DB      â”‚
â”‚     queries. Tuned, a single server can push 500-2000 RPS).     â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  STEP 2: STORAGE                                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                               â”‚
â”‚  Users table:              1M Ã— 1KB = 1 GB                      â”‚
â”‚  Organizations:            100K Ã— 0.5KB = 50 MB                 â”‚
â”‚  Tasks (avg 30/user):      30M Ã— 2KB = 60 GB                   â”‚
â”‚  Audit log (10 events/     10M events/day Ã— 0.5KB = 5 GB/day   â”‚
â”‚     user/day):             Ã— 365 days = 1.8 TB/year             â”‚
â”‚                                                                 â”‚
â”‚  âš ï¸  Audit log grows FAST. This will be a problem.              â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  STEP 3: DATABASE LOAD                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚
â”‚  Read/write ratio:         ~90% reads / 10% writes              â”‚
â”‚  Read queries:             ~160 reads/sec at peak                â”‚
â”‚  Write queries:            ~18 writes/sec at peak               â”‚
â”‚                                                                 â”‚
â”‚  âœ… PostgreSQL handles this easily.                              â”‚
â”‚     But at 10M users? 1,750 reads/sec peak.                     â”‚
â”‚     With complex JOINs? That's where it breaks.                 â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  STEP 4: WEBSOCKET CONNECTIONS                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                 â”‚
â”‚  Concurrent users (peak):  ~30,000 (30% of DAU online at once)  â”‚
â”‚  Each WS connection:       ~10 KB memory                        â”‚
â”‚  Total WS memory:          ~300 MB                              â”‚
â”‚                                                                 â”‚
â”‚  âš ï¸  30K concurrent connections is a lot for one process.        â”‚
â”‚     Linux default file descriptor limit: 1024.                  â”‚
â”‚     Need to tune OS settings AND think about scaling.           â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Now ask the class:**

> "At 1M users, we're *probably* fine on one beefy server. Tight, but fine. What about 10M users? Everything we just calculated multiplies by 10. 1,750 peak reads/sec, 300K WebSocket connections, 18 TB/year audit logs. One machine cannot do that. *That's* when system design kicks in."

> "The point isn't the exact numbers. It's the HABIT: estimate before you design. This turns 'I think we need more servers' into 'We need at least 3 app servers and 2 database replicas to handle projected peak load.' That's engineering."

---

# PART 2: SCALING YOUR SERVERS

## 2.1 Vertical Scaling (A Bigger Restaurant)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VERTICAL SCALING                             â”‚
â”‚               "Make the machine BIGGER"                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  BEFORE                          AFTER                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€                          â”€â”€â”€â”€â”€                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚   4 CPU     â”‚                 â”‚   32 CPU             â”‚       â”‚
â”‚  â”‚   8 GB RAM  â”‚    â”€â”€â”€â”€â–¶        â”‚   128 GB RAM         â”‚       â”‚
â”‚  â”‚   100 GB SSDâ”‚                 â”‚   2 TB NVMe SSD      â”‚       â”‚
â”‚  â”‚   $50/month â”‚                 â”‚   $800/month         â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                 â”‚
â”‚  THE RESTAURANT ANALOGY:                                        â”‚
â”‚  "Knock down walls, expand the dining room, buy a bigger        â”‚
â”‚   oven, hire more waiters â€” but it's still ONE restaurant."     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Advantages and limits:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  âœ… ADVANTAGES:                    âŒ LIMITS:                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                   â”‚
â”‚  Simple â€” no code changes          Hardware has a ceiling       â”‚
â”‚  No distributed complexity         (you can't buy a 10,000-    â”‚
â”‚  No network hops between           core machine)               â”‚
â”‚    components                                                   â”‚
â”‚  Same deployment process           Cost grows non-linearly     â”‚
â”‚  Your capstone works AS-IS         (2x CPU â‰  2x cost, often   â”‚
â”‚                                     more like 3-4x)            â”‚
â”‚                                                                 â”‚
â”‚                                    Still ONE failure point     â”‚
â”‚                                    (server dies = app dies)    â”‚
â”‚                                                                 â”‚
â”‚                                    Downtime during upgrade     â”‚
â”‚                                    (must stop, resize, start)  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**When to use vertical scaling:**

> "Vertical scaling is your FIRST move. Always. It's the cheapest, simplest fix. Don't build a distributed system when a $200/month server solves your problem. Many successful startups run on a single beefy machine for years."

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  THE VERTICAL SCALING RULE OF THUMB:                            â”‚
â”‚                                                                 â”‚
â”‚  If your problem can be solved by throwing money at a bigger    â”‚
â”‚  server, DO THAT FIRST. Distributed systems are an order of     â”‚
â”‚  magnitude more complex. You earn that complexity with growth.  â”‚
â”‚                                                                 â”‚
â”‚  Go horizontal when:                                            â”‚
â”‚  â”œâ”€ The biggest available machine isn't enough                  â”‚
â”‚  â”œâ”€ You need redundancy (can't afford single-server downtime)   â”‚
â”‚  â””â”€ Cost of scaling up exceeds cost of scaling out              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2.2 Horizontal Scaling (More Locations)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   HORIZONTAL SCALING                            â”‚
â”‚               "Add MORE machines"                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  BEFORE                          AFTER                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€                          â”€â”€â”€â”€â”€                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚  Server 1   â”‚                 â”‚  Server 1  â”‚                 â”‚
â”‚  â”‚  (handles   â”‚    â”€â”€â”€â”€â–¶        â”‚  Server 2  â”‚                 â”‚
â”‚  â”‚   everythingâ”‚                 â”‚  Server 3  â”‚                 â”‚
â”‚  â”‚   alone)    â”‚                 â”‚  Server 4  â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                                 â”‚
â”‚  THE RESTAURANT ANALOGY:                                        â”‚
â”‚  "Open a second location. Then a third. Then a fourth.          â”‚
â”‚   Same menu, same quality, multiple places serving customers."  â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  âœ… ADVANTAGES:                    âŒ COMPLEXITY:                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€               â”‚
â”‚  Near-infinite scaling             Must coordinate between      â”‚
â”‚  (add more machines)               servers                      â”‚
â”‚                                                                 â”‚
â”‚  Redundancy built in               Where does data live?        â”‚
â”‚  (one dies, others continue)       Which server handles which   â”‚
â”‚                                    request?                     â”‚
â”‚  Cheaper at scale                                               â”‚
â”‚  (many small > one huge)           How do they share state?     â”‚
â”‚                                    How do you deploy changes?   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**What your architecture looks like horizontally scaled:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          HORIZONTAL ARCHITECTURE (simplified)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                       â”‚ Clients  â”‚                              â”‚
â”‚                       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                            â”‚                                    â”‚
â”‚                            â–¼                                    â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚                   â”‚ LOAD BALANCER  â”‚  â† NEW (we'll cover soon)  â”‚
â”‚                   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”˜                             â”‚
â”‚                       â”‚    â”‚    â”‚                                â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚              â–¼             â–¼             â–¼                       â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚        â”‚ FastAPI  â”‚ â”‚ FastAPI  â”‚ â”‚ FastAPI  â”‚                   â”‚
â”‚        â”‚ Server 1 â”‚ â”‚ Server 2 â”‚ â”‚ Server 3 â”‚                   â”‚
â”‚        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚             â”‚            â”‚            â”‚                          â”‚
â”‚             â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                    â–¼           â–¼                                 â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚            â”‚ PostgreSQL â”‚ â”‚   Redis    â”‚  â† Shared resources    â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                                                                 â”‚
â”‚   THREE copies of your FastAPI app,                             â”‚
â”‚   sharing ONE database and ONE Redis.                           â”‚
â”‚   Each can handle requests independently.                       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Connection to Week 15:**

> "Remember Docker Compose from Week 15? You could spin this up today. Three containers running the same FastAPI image, one Postgres container, one Redis container. The infrastructure knowledge you have already supports this."

---

## 2.3 The State Problem (Why Horizontal Is Hard)

**This is the CENTRAL difficulty of horizontal scaling. Pay attention.**

> "Opening a second restaurant sounds simple. But think: if a customer walks into Location A, places an order, then drives to Location B to pick it up â€” does Location B know about that order?"

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   THE STATE PROBLEM                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  "State" = data that a server remembers between requests.       â”‚
â”‚                                                                 â”‚
â”‚  STATEFUL SERVER (your Week 3 in-memory Task Manager):          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”‚
â”‚  tasks = {}  â† Data lives IN the server's memory               â”‚
â”‚                                                                 â”‚
â”‚  Request 1 â†’ Server A â†’ tasks["1"] = "Buy milk" âœ…             â”‚
â”‚  Request 2 â†’ Server B â†’ tasks["1"] = ???          âŒ NOT HERE!  â”‚
â”‚                                                                 â”‚
â”‚  Server B has its OWN empty dict. It doesn't know about         â”‚
â”‚  the task created on Server A.                                  â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  STATELESS SERVER (your Week 6+ database-backed app):           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”‚
â”‚  Each request is self-contained. Server stores NOTHING locally. â”‚
â”‚  All persistent data lives in the database.                     â”‚
â”‚                                                                 â”‚
â”‚  Request 1 â†’ Server A â†’ writes to PostgreSQL     âœ…             â”‚
â”‚  Request 2 â†’ Server B â†’ reads from PostgreSQL    âœ… FOUND IT!  â”‚
â”‚                                                                 â”‚
â”‚  Both servers talk to the SAME database.                        â”‚
â”‚  The server is just a "compute pipe" â€” data flows through it.   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Now ask the class:**

> "Why did we switch from an in-memory dict in Week 3 to PostgreSQL in Week 6? Back then we said it was for persistence and data integrity. But here's the second reason you didn't know about yet: *stateless servers can be horizontally scaled.* That migration wasn't just about databases â€” it was about scalability."

**Connection to Week 9:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           WHY YOU CHOSE JWT (AND DIDN'T KNOW IT)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  SESSION-BASED AUTH (if you had chosen it):                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                     â”‚
â”‚                                                                 â”‚
â”‚  Login â†’ Server A creates session, stores in memory             â”‚
â”‚  Next request â†’ Load balancer sends to Server B                 â”‚
â”‚  Server B: "Who are you? I have no session for you." âŒ         â”‚
â”‚                                                                 â”‚
â”‚  SOLUTIONS:                                                     â”‚
â”‚  â”œâ”€ Sticky sessions (always route to same server â€” fragile)     â”‚
â”‚  â””â”€ Session store in Redis (extra infrastructure â€” viable)      â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  JWT AUTH (what you built in Week 9):                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                           â”‚
â”‚                                                                 â”‚
â”‚  Login â†’ Server A creates JWT, sends to client                  â”‚
â”‚  Next request â†’ Client sends JWT â†’ load balancer â†’ Server B     â”‚
â”‚  Server B: Validates JWT signature. No server state needed. âœ…  â”‚
â”‚                                                                 â”‚
â”‚  The token carries the identity. ANY server can verify it.      â”‚
â”‚  This is why JWT is the standard for horizontally scaled APIs.  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The statelessness checklist for your capstone:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          IS YOUR CAPSTONE HORIZONTALLY SCALABLE?                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  âœ… Auth via JWT (stateless â€” Week 9)                            â”‚
â”‚  âœ… Data in PostgreSQL (shared external state â€” Week 6)          â”‚
â”‚  âœ… Cache in Redis (shared external state â€” Week 10)             â”‚
â”‚  âœ… Background jobs via Celery+Redis (shared queue â€” Week 11)    â”‚
â”‚  âœ… Config in environment variables (12-factor â€” Week 15)        â”‚
â”‚                                                                 â”‚
â”‚  âš ï¸  WebSocket connections: connection manager holds state       â”‚
â”‚     in memory (your ConnectionManager from Week 12).            â”‚
â”‚     This BREAKS with multiple servers. Solution: Redis pub/sub  â”‚
â”‚     (you learned this in Week 12 Lecture 2).                    â”‚
â”‚                                                                 â”‚
â”‚  âš ï¸  File uploads: if you save to local disk, only that server  â”‚
â”‚     has the file. Solution: S3-compatible storage               â”‚
â”‚     (you learned about presigned URLs in Week 13).              â”‚
â”‚                                                                 â”‚
â”‚  VERDICT: Your capstone is MOSTLY ready for horizontal          â”‚
â”‚           scaling. The decisions you made over 15 weeks were     â”‚
â”‚           the right decisions. You just didn't know WHY yet.    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2.4 Load Balancers (The Central Reservation System)

**If you have 3 servers, who decides which server gets which request?**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     LOAD BALANCER                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  A load balancer sits BETWEEN clients and your servers.         â”‚
â”‚  It distributes incoming requests across multiple servers.      â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  WITHOUT LOAD BALANCER:             WITH LOAD BALANCER:         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        â”‚
â”‚                                                                 â”‚
â”‚   Client â”€â”€â–¶ Server 1 ğŸ˜° (all        Client                    â”‚
â”‚   Client â”€â”€â–¶ Server 1    traffic      Client â”€â”€â–¶ â”Œâ”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   Client â”€â”€â–¶ Server 1    to one       Client â”€â”€â–¶ â”‚  LB  â”‚      â”‚
â”‚                server)    Client â”€â”€â–¶ â””â”€â”€â”¬â”€â”€â”€â”˜      â”‚
â”‚              Server 2 ğŸ˜´ (idle)             â”‚   â”‚   â”‚           â”‚
â”‚              Server 3 ğŸ˜´ (idle)             â–¼   â–¼   â–¼           â”‚
â”‚                                           S1   S2   S3         â”‚
â”‚                                           ğŸ˜Š   ğŸ˜Š   ğŸ˜Š          â”‚
â”‚                                                                 â”‚
â”‚  THE RESTAURANT ANALOGY:                                        â”‚
â”‚  A central reservation hotline. You call one number.            â”‚
â”‚  The operator checks which location has available tables        â”‚
â”‚  and routes you there. You never pick the server yourself.      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**What a load balancer does:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               LOAD BALANCER RESPONSIBILITIES                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚      Client â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  LOAD BALANCER   â”‚                       â”‚
â”‚      Request         â”‚                  â”‚                       â”‚
â”‚                      â”‚  1. Receive      â”‚                       â”‚
â”‚                      â”‚  2. Choose serverâ”‚                       â”‚
â”‚                      â”‚  3. Forward      â”‚                       â”‚
â”‚                      â”‚  4. Return       â”‚                       â”‚
â”‚                      â”‚     response     â”‚                       â”‚
â”‚                      â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”˜                       â”‚
â”‚                          â”‚      â”‚   â”‚                           â”‚
â”‚                          â–¼      â–¼   â–¼                           â”‚
â”‚                        S1      S2   S3                          â”‚
â”‚                                                                 â”‚
â”‚  CORE FUNCTIONS:                                                â”‚
â”‚  â”œâ”€ DISTRIBUTE traffic across healthy servers                   â”‚
â”‚  â”œâ”€ DETECT failed servers (health checks)                       â”‚
â”‚  â”œâ”€ REMOVE failed servers from the pool                         â”‚
â”‚  â”œâ”€ RE-ADD recovered servers automatically                      â”‚
â”‚  â””â”€ TERMINATE SSL (handle HTTPS, pass HTTP to servers)          â”‚
â”‚                                                                 â”‚
â”‚  The client talks to ONE address. It never knows there are      â”‚
â”‚  multiple servers behind it. The load balancer is invisible.    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Layer 4 vs Layer 7 â€” two types of load balancing:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              TWO TYPES OF LOAD BALANCING                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  LAYER 4 (Transport Layer)                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚
â”‚  Routes based on: IP address and port                           â”‚
â”‚  Knows about: TCP/UDP connections                               â”‚
â”‚  Cannot see: HTTP headers, URLs, cookies                        â”‚
â”‚  Speed: Very fast (just forwarding packets)                     â”‚
â”‚  Analogy: A receptionist who sends you to "the next available   â”‚
â”‚           restaurant" without knowing what food you want.       â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  LAYER 7 (Application Layer)                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚  Routes based on: URL path, headers, cookies, request body      â”‚
â”‚  Knows about: HTTP content (can read your request)              â”‚
â”‚  Can do: Route /api/* to API servers, /static/* to CDN          â”‚
â”‚  Speed: Slightly slower (must parse HTTP)                       â”‚
â”‚  Analogy: A host who reads your reservation and sends you       â”‚
â”‚           to the Italian section or the sushi bar accordingly.  â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  FOR YOUR FASTAPI APP: Layer 7 is most common.                  â”‚
â”‚  It lets you route by URL, inspect headers, handle              â”‚
â”‚  WebSocket upgrades separately from HTTP requests.              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2.5 Load Balancing Algorithms

**How does the load balancer CHOOSE which server gets the request?**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               LOAD BALANCING ALGORITHMS                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  1. ROUND ROBIN                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                 â”‚
â”‚  Take turns. Request 1 â†’ S1, Request 2 â†’ S2,                   â”‚
â”‚  Request 3 â†’ S3, Request 4 â†’ S1, ...                            â”‚
â”‚                                                                 â”‚
â”‚  Request:  1    2    3    4    5    6                            â”‚
â”‚  Server:  S1   S2   S3   S1   S2   S3                           â”‚
â”‚                                                                 â”‚
â”‚  âœ… Simple, fair         âŒ Ignores server load                  â”‚
â”‚                             (S1 might be handling a heavy       â”‚
â”‚                              query while S2 is idle)            â”‚
â”‚                                                                 â”‚
â”‚  Analogy: Customers line up, alternating between                â”‚
â”‚           Location A, B, C regardless of how busy each is.      â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  2. LEAST CONNECTIONS                                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                           â”‚
â”‚  Send to the server with the fewest active connections.         â”‚
â”‚                                                                 â”‚
â”‚  S1: 12 connections                                             â”‚
â”‚  S2: 3 connections     â† Next request goes HERE                 â”‚
â”‚  S3: 8 connections                                              â”‚
â”‚                                                                 â”‚
â”‚  âœ… Adapts to actual load  âŒ Needs connection tracking          â”‚
â”‚  âœ… Good for varied         (slightly more complex)             â”‚
â”‚     request durations                                           â”‚
â”‚                                                                 â”‚
â”‚  Analogy: The reservation system checks which restaurant        â”‚
â”‚           has the shortest wait and sends you there.            â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  3. IP HASH                                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                      â”‚
â”‚  Hash the client's IP to determine server.                      â”‚
â”‚  Same client â†’ same server (always).                            â”‚
â”‚                                                                 â”‚
â”‚  hash("192.168.1.1") % 3 = 1  â†’ Always Server 2                â”‚
â”‚  hash("10.0.0.5") % 3 = 0     â†’ Always Server 1                â”‚
â”‚                                                                 â”‚
â”‚  âœ… Session affinity       âŒ Uneven distribution if             â”‚
â”‚     (sticky sessions)        few clients send lots of traffic   â”‚
â”‚                                                                 â”‚
â”‚  Analogy: "You always go to the location closest to your        â”‚
â”‚           house." Predictable, but some locations get crowded.  â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  4. WEIGHTED ROUND ROBIN                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                        â”‚
â”‚  Like round robin, but some servers get MORE traffic.           â”‚
â”‚                                                                 â”‚
â”‚  S1 (weight 5): gets 5 out of every 8 requests                  â”‚
â”‚  S2 (weight 2): gets 2 out of every 8 requests                  â”‚
â”‚  S3 (weight 1): gets 1 out of every 8 requests                  â”‚
â”‚                                                                 â”‚
â”‚  âœ… When servers have different capacities                       â”‚
â”‚  âœ… Gradual rollout (send 10% to new version)                    â”‚
â”‚                                                                 â”‚
â”‚  Analogy: The flagship location has 100 tables.                 â”‚
â”‚           The new small location has 20. Route accordingly.     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Which algorithm should you pick?**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 ALGORITHM DECISION GUIDE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Stateless API (your capstone):      â†’ ROUND ROBIN or           â”‚
â”‚                                        LEAST CONNECTIONS        â”‚
â”‚                                                                 â”‚
â”‚  WebSocket connections (long-lived): â†’ LEAST CONNECTIONS        â”‚
â”‚    (some servers accumulate more                                â”‚
â”‚     open sockets over time)                                     â”‚
â”‚                                                                 â”‚
â”‚  Mixed server sizes:                 â†’ WEIGHTED ROUND ROBIN     â”‚
â”‚                                                                 â”‚
â”‚  Need same-client â†’ same-server:     â†’ IP HASH                  â”‚
â”‚    (only if absolutely necessary;                               â”‚
â”‚     prefer stateless design instead)                            â”‚
â”‚                                                                 â”‚
â”‚  DEFAULT CHOICE: LEAST CONNECTIONS.                             â”‚
â”‚  It adapts to real-world conditions. Start there.               â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2.6 Health Checks (Is This Location Open?)

**A load balancer needs to know which servers are alive.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      HEALTH CHECKS                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  The load balancer periodically asks each server:               â”‚
â”‚  "Are you alive and ready to handle requests?"                  â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  LB â”€â”€GET /healthâ”€â”€â–¶ Server 1 â”€â”€â–¶ 200 OK âœ…  (keep in pool)    â”‚
â”‚  LB â”€â”€GET /healthâ”€â”€â–¶ Server 2 â”€â”€â–¶ 200 OK âœ…  (keep in pool)    â”‚
â”‚  LB â”€â”€GET /healthâ”€â”€â–¶ Server 3 â”€â”€â–¶ TIMEOUT âŒ  (remove!)        â”‚
â”‚                                                                 â”‚
â”‚  After removal:                                                 â”‚
â”‚  LB routes traffic to Server 1 and 2 only.                      â”‚
â”‚  Periodically retries Server 3.                                 â”‚
â”‚  If Server 3 recovers â†’ add it back.                            â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  THE RESTAURANT ANALOGY:                                        â”‚
â”‚  The franchise manager calls each location every 30 seconds.    â”‚
â”‚  "Are you open? Is the kitchen working?"                        â”‚
â”‚  If a location doesn't answer 3 times â†’ stop sending customers. â”‚
â”‚  Keep calling. When they answer again â†’ resume sending.         â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Connection to Week 15:**

> "You already built health check endpoints. Remember `/health` and `/ready` from Week 15? Now you see exactly where those get used â€” the load balancer hits them continuously. The `/health` endpoint you wrote isn't decorative. It's critical infrastructure."

**Two types of health checks:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  LIVENESS CHECK: /health                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚
â”‚  "Is the process running?"                                      â”‚
â”‚  Returns 200 if the FastAPI process is alive.                   â”‚
â”‚  Doesn't check dependencies.                                   â”‚
â”‚  If this fails â†’ server is crashed, restart it.                 â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  READINESS CHECK: /ready                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                         â”‚
â”‚  "Can you handle requests right now?"                           â”‚
â”‚  Checks: database connection? Redis connection? Disk space?     â”‚
â”‚  If this fails â†’ server is alive but NOT ready.                 â”‚
â”‚  Don't restart, don't send traffic. Wait for recovery.          â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  WHY BOTH?                                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                     â”‚
â”‚  Server is live but not ready: database migration running.      â”‚
â”‚  Don't kill the server (it's working!). Don't send it traffic   â”‚
â”‚  (it can't serve users yet). These are different signals.       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# PART 3: SCALING YOUR DATABASE

## 3.1 The Database Bottleneck

**Scaling app servers is relatively easy â€” they're stateless. The database is the hard part.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 THE DATABASE BOTTLENECK                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  You can add 10 FastAPI servers easily:                         â”‚
â”‚                                                                 â”‚
â”‚   S1  S2  S3  S4  S5  S6  S7  S8  S9  S10                      â”‚
â”‚    \   \   \   |   |   |   /   /   /   /                        â”‚
â”‚     \   \   \  |   |   |  /   /   /   /                         â”‚
â”‚      â–¼   â–¼   â–¼ â–¼   â–¼   â–¼ â–¼   â–¼   â–¼   â–¼                         â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚     â”‚         ONE PostgreSQL               â”‚ â† ALL traffic     â”‚
â”‚     â”‚         (sweating)          ğŸ˜°       â”‚    funnels here    â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                                                 â”‚
â”‚  More app servers = MORE database connections.                  â”‚
â”‚  10 servers Ã— 20 connections each = 200 connections.            â”‚
â”‚  All reading and writing to the same PostgreSQL.                â”‚
â”‚                                                                 â”‚
â”‚  THE RESTAURANT ANALOGY:                                        â”‚
â”‚  You opened 10 restaurant locations. But they all share ONE     â”‚
â”‚  kitchen. The kitchen becomes the bottleneck. Waiters are       â”‚
â”‚  fast, but everyone's waiting for the same oven.                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> "You scaled the easy part (stateless servers). But the database is the *shared state* that every server depends on. You can't just 'add more databases' the way you add more app servers â€” because the data must be consistent. This is the fundamental challenge of distributed systems."

**A key observation:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  Most web applications have a READ-HEAVY workload:              â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–“â–“â–“â–“â–“â”‚                   â”‚
â”‚  â”‚          READS (~85-95%)           WRITESâ”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                                 â”‚
â”‚  Think about your capstone:                                     â”‚
â”‚  â”œâ”€ Loading the dashboard:       READ                           â”‚
â”‚  â”œâ”€ Viewing task details:        READ                           â”‚
â”‚  â”œâ”€ Listing team members:        READ                           â”‚
â”‚  â”œâ”€ Searching tasks:             READ                           â”‚
â”‚  â”œâ”€ Viewing audit log:           READ                           â”‚
â”‚  â”œâ”€ Creating a task:             WRITE                          â”‚
â”‚  â”œâ”€ Updating task status:        WRITE                          â”‚
â”‚  â””â”€ Assigning a member:          WRITE                          â”‚
â”‚                                                                 â”‚
â”‚  Most users spend most of their time LOOKING, not CREATING.     â”‚
â”‚  This asymmetry is the key to database scaling strategy.        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3.2 Read Replicas (Copies of the Recipe Book)

**If reads are the bottleneck, make more copies for reading.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     READ REPLICAS                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚   ALL WRITES â”€â”€â–¶  â”‚  PRIMARY DATABASE  â”‚                        â”‚
â”‚                   â”‚  (read + write)    â”‚                        â”‚
â”‚                   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                       â”‚replicatesâ”‚                              â”‚
â”‚                       â”‚  data    â”‚                              â”‚
â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚   READS â”€â”€â”€â–¶  â”‚ REPLICA 1â”‚  â”‚ REPLICA 2  â”‚  â—€â”€â”€â”€ READS        â”‚
â”‚               â”‚ (read    â”‚  â”‚ (read      â”‚                     â”‚
â”‚               â”‚  only)   â”‚  â”‚  only)     â”‚                     â”‚
â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                                 â”‚
â”‚  HOW IT WORKS:                                                  â”‚
â”‚  â”œâ”€ One PRIMARY database handles all WRITES                     â”‚
â”‚  â”œâ”€ REPLICAS are exact copies of the primary                    â”‚
â”‚  â”œâ”€ Data streams from primary â†’ replicas automatically          â”‚
â”‚  â”œâ”€ Reads are distributed across replicas                       â”‚
â”‚  â””â”€ If primary dies â†’ promote a replica to primary              â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  THE RESTAURANT ANALOGY:                                        â”‚
â”‚  Headquarters (primary) maintains the master recipe book.       â”‚
â”‚  Each location (replica) gets a copy.                           â”‚
â”‚  When customers ask "What's on the menu?" â†’ any location can    â”‚
â”‚  answer (read from their copy).                                 â”‚
â”‚  When a NEW recipe is invented â†’ it goes to HQ first (write     â”‚
â”‚  to primary), then gets distributed to all locations.           â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The impact on throughput:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  BEFORE (single database):                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚
â”‚  All 10,000 read queries/sec â†’ ONE database                     â”‚
â”‚  All 500 write queries/sec â†’ ONE database                       â”‚
â”‚  Total load: 10,500 queries/sec on ONE machine                  â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  AFTER (1 primary + 2 replicas):                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                               â”‚
â”‚  500 write queries/sec â†’ PRIMARY only                           â”‚
â”‚  10,000 read queries/sec â†’ split across 2 REPLICAS              â”‚
â”‚    Replica 1: ~5,000 reads/sec                                  â”‚
â”‚    Replica 2: ~5,000 reads/sec                                  â”‚
â”‚                                                                 â”‚
â”‚  Each machine handles ~5,000-5,500 queries/sec instead of       â”‚
â”‚  10,500. That's a ~50% reduction per machine.                   â”‚
â”‚                                                                 â”‚
â”‚  Add more replicas â†’ further reduce per-machine load.           â”‚
â”‚  Read capacity scales near-linearly with replicas.              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Connection to your SQLAlchemy code (Week 6):**

> "In practice, your repository layer from Week 6 would route queries: write operations go to the primary's connection string, read operations go to a replica's connection string. The SQLAlchemy `Session` can be configured with separate `bind` settings for reads vs. writes. Your code doesn't change much â€” the routing logic lives in the infrastructure layer."

```python
# Conceptual â€” how your Week 6 async sessions would adapt:

# Primary database (writes)
primary_engine = create_async_engine("postgresql+asyncpg://primary-host/mydb")

# Replica database (reads)
replica_engine = create_async_engine("postgresql+asyncpg://replica-host/mydb")

# In your FastAPI dependency (like your Week 6 session dependency):
async def get_read_session():
    """Use replica for read-heavy endpoints"""
    async with AsyncSession(replica_engine) as session:
        yield session

async def get_write_session():
    """Use primary for write operations"""
    async with AsyncSession(primary_engine) as session:
        yield session
```

---

## 3.3 Replication Lag (The Update Delay)

**Replicas are NOT instant. This creates real problems.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   REPLICATION LAG                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Time â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶           â”‚
â”‚                                                                 â”‚
â”‚  t=0ms     User creates a task (writes to PRIMARY)              â”‚
â”‚  t=1ms     PRIMARY confirms: "Task created!"                    â”‚
â”‚  t=2ms     User's page refreshes, reads from REPLICA            â”‚
â”‚  t=2ms     REPLICA hasn't received the new task yet...          â”‚
â”‚  t=2ms     User sees: "Where's my task?!"  ğŸ˜±                   â”‚
â”‚  t=50ms    REPLICA finally gets the data                        â”‚
â”‚  t=100ms   User refreshes again. "Oh, there it is."            â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  This 50ms gap is REPLICATION LAG.                              â”‚
â”‚  Usually milliseconds. Can spike to seconds under heavy load.   â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  THE RESTAURANT ANALOGY:                                        â”‚
â”‚  HQ invents a new recipe at 2:00 PM.                            â”‚
â”‚  They fax it to all locations. (Yes, fax. It's an analogy.)     â”‚
â”‚  Location B gets it at 2:03 PM.                                 â”‚
â”‚  A customer walks into Location B at 2:01 PM and orders the     â”‚
â”‚  new dish. "Sorry, we don't have that." But HQ says they do!   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Strategies for dealing with replication lag:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             HANDLING REPLICATION LAG                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. READ-YOUR-OWN-WRITES                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                        â”‚
â”‚  After a write, route THAT USER's next reads to the primary     â”‚
â”‚  for a short window (e.g., 5 seconds). Other users still        â”‚
â”‚  read from replicas.                                            â”‚
â”‚                                                                 â”‚
â”‚    User writes task â†’ next 5 sec reads go to PRIMARY            â”‚
â”‚    After 5 sec â†’ back to REPLICA (lag has caught up)            â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  2. SYNCHRONOUS REPLICATION (for critical data)                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚  Primary waits for at least one replica to confirm before       â”‚
â”‚  telling the client "write successful."                         â”‚
â”‚                                                                 â”‚
â”‚    âœ… No lag (replica is always up-to-date)                      â”‚
â”‚    âŒ Slower writes (must wait for replica confirmation)         â”‚
â”‚    Use for: Financial data, auth changes, critical state        â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  3. TOLERATE IT                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                  â”‚
â”‚  For many features, a few hundred milliseconds of lag is        â”‚
â”‚  invisible to users. Dashboard analytics, activity feeds,       â”‚
â”‚  search results â€” all fine with slight staleness.               â”‚
â”‚                                                                 â”‚
â”‚  Not everything needs perfect consistency.                      â”‚
â”‚  (We'll formalize this idea in the CAP theorem section.)        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3.4 Sharding (Splitting the Kitchen)

**Read replicas handle the *read* bottleneck. What about writes?**

> "You can't add write capacity with replicas. ALL writes still go to one primary. If you have 50,000 writes/sec and one PostgreSQL can handle 5,000 â€” replicas don't help. You need to split the data itself."

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       SHARDING                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Sharding = splitting your data across MULTIPLE databases,      â”‚
â”‚  each holding a SUBSET of the total data.                       â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  BEFORE (one database, all data):                               â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚          PostgreSQL              â”‚                           â”‚
â”‚  â”‚  Users A-Z, Tasks 1-50M         â”‚                           â”‚
â”‚  â”‚  Organizations 1-100K            â”‚ â† Everything, one DB     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  AFTER (sharded by organization):                               â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚   Shard 1   â”‚ â”‚   Shard 2   â”‚ â”‚   Shard 3   â”‚               â”‚
â”‚  â”‚  Orgs 1-33K â”‚ â”‚ Orgs 33-66K â”‚ â”‚ Orgs 66-100Kâ”‚               â”‚
â”‚  â”‚  + their    â”‚ â”‚  + their    â”‚ â”‚  + their    â”‚               â”‚
â”‚  â”‚  users,     â”‚ â”‚  users,     â”‚ â”‚  users,     â”‚               â”‚
â”‚  â”‚  tasks,     â”‚ â”‚  tasks,     â”‚ â”‚  tasks,     â”‚               â”‚
â”‚  â”‚  audit logs â”‚ â”‚  audit logs â”‚ â”‚  audit logs â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                                 â”‚
â”‚  Each shard handles 1/3 of the writes.                          â”‚
â”‚  Each shard has 1/3 of the data (smaller, faster indexes).      â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  THE RESTAURANT ANALOGY:                                        â”‚
â”‚  Instead of one massive kitchen cooking everything, you         â”‚
â”‚  create specialized kitchens:                                   â”‚
â”‚  Kitchen A handles customers A-H (their orders, their tabs)     â”‚
â”‚  Kitchen B handles customers I-P                                â”‚
â”‚  Kitchen C handles customers Q-Z                                â”‚
â”‚  Each kitchen is smaller, faster, independent.                  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3.5 Sharding Strategies

**How do you decide which data goes to which shard?**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  SHARDING STRATEGIES                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  1. KEY-BASED (HASH) SHARDING                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                   â”‚
â”‚  shard = hash(shard_key) % number_of_shards                     â”‚
â”‚                                                                 â”‚
â”‚  Example with org_id:                                           â”‚
â”‚  hash(org_42) % 3 = 0  â†’ Shard 1                               â”‚
â”‚  hash(org_99) % 3 = 2  â†’ Shard 3                               â”‚
â”‚  hash(org_71) % 3 = 1  â†’ Shard 2                               â”‚
â”‚                                                                 â”‚
â”‚  âœ… Even distribution (if hash is good)                          â”‚
â”‚  âŒ Adding a shard requires rehashing (data migration)           â”‚
â”‚     hash(org_42) % 4 â‰  hash(org_42) % 3                        â”‚
â”‚     â†’ Data must move between shards                             â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  2. RANGE-BASED SHARDING                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                       â”‚
â”‚  Shard 1: org_id 1 â€“ 33,000                                     â”‚
â”‚  Shard 2: org_id 33,001 â€“ 66,000                                â”‚
â”‚  Shard 3: org_id 66,001 â€“ 100,000                               â”‚
â”‚                                                                 â”‚
â”‚  âœ… Simple to understand, easy range queries                     â”‚
â”‚  âŒ Hot spots: if new users get sequential IDs, Shard 3          â”‚
â”‚     gets ALL new writes. Older shards idle.                     â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  3. DIRECTORY-BASED SHARDING                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                   â”‚
â”‚  A lookup table maps each key to its shard.                     â”‚
â”‚                                                                 â”‚
â”‚  org_42 â†’ Shard 1                                               â”‚
â”‚  org_99 â†’ Shard 2                                               â”‚
â”‚  org_71 â†’ Shard 1   (custom assignment)                         â”‚
â”‚                                                                 â”‚
â”‚  âœ… Maximum flexibility (can rebalance individual keys)          â”‚
â”‚  âŒ Lookup table becomes its own bottleneck/SPOF                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The danger of cross-shard queries:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CROSS-SHARD QUERIES (THE PAIN)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  WITHIN ONE SHARD â€” everything is easy:                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”‚
â”‚  "Get all tasks for org_42"                                     â”‚
â”‚  â†’ org_42 is on Shard 1 â†’ query Shard 1 â†’ done.                â”‚
â”‚                                                                 â”‚
â”‚  ACROSS SHARDS â€” everything is hard:                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                           â”‚
â”‚  "Get the top 10 most active organizations across ALL orgs"     â”‚
â”‚  â†’ Must query ALL shards                                        â”‚
â”‚  â†’ Combine results in the application layer                     â”‚
â”‚  â†’ No database-level JOIN across shards                         â”‚
â”‚  â†’ Pagination becomes a nightmare                               â”‚
â”‚                                                                 â”‚
â”‚  This is why SHARD KEY CHOICE is the most important decision.   â”‚
â”‚  You want queries to hit ONE shard whenever possible.           â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  FOR YOUR MULTI-TENANT CAPSTONE:                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                 â”‚
â”‚  Shard key = organization_id  â† NATURAL FIT                    â”‚
â”‚                                                                 â”‚
â”‚  Why? Your multi-tenant design (Week 13) already isolates       â”‚
â”‚  data by organization. Every query already filters by org.      â”‚
â”‚  Users, tasks, projects, audit logs â€” all scoped to an org.     â”‚
â”‚  Sharding by org_id means almost every query hits one shard.    â”‚
â”‚                                                                 â”‚
â”‚  This is not a coincidence. Multi-tenant design and sharding    â”‚
â”‚  strategy are deeply connected. Your architecture was already   â”‚
â”‚  shard-friendly and you didn't know it.                         â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3.6 The Decision Framework

**Don't shard prematurely. Follow this sequence:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            DATABASE SCALING DECISION SEQUENCE                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  START HERE                                                     â”‚
â”‚      â”‚                                                          â”‚
â”‚      â–¼                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚  â”‚  1. OPTIMIZE QUERIES FIRST     â”‚  â† You learned this        â”‚
â”‚  â”‚     Indexes, EXPLAIN ANALYZE,  â”‚    in Week 7.               â”‚
â”‚  â”‚     fix N+1, optimize JOINs    â”‚    Always start here.       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                  â”‚ Still not enough?                             â”‚
â”‚                  â–¼                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚  â”‚  2. VERTICAL SCALE THE DB      â”‚  â† Bigger machine.         â”‚
â”‚  â”‚     More RAM, faster disk,     â”‚    Cheapest fix.            â”‚
â”‚  â”‚     more connections           â”‚                             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                  â”‚ Still not enough?                             â”‚
â”‚                  â–¼                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚  â”‚  3. ADD CACHING LAYER          â”‚  â† You built this          â”‚
â”‚  â”‚     Redis for hot data,        â”‚    in Week 10.              â”‚
â”‚  â”‚     reduce DB read load        â”‚    Huge impact.             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                  â”‚ Still not enough?                             â”‚
â”‚                  â–¼                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚  â”‚  4. ADD READ REPLICAS          â”‚  â† Handles read            â”‚
â”‚  â”‚     Route reads to replicas,   â”‚    bottleneck.              â”‚
â”‚  â”‚     writes to primary          â”‚    Moderate complexity.     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                  â”‚ Still not enough?                             â”‚
â”‚                  â–¼                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚  â”‚  5. SHARD THE DATABASE         â”‚  â† Last resort.            â”‚
â”‚  â”‚     Split data across multiple â”‚    Highest complexity.      â”‚
â”‚  â”‚     databases by shard key     â”‚    Hard to undo.            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                                                                 â”‚
â”‚  MOST COMPANIES NEVER REACH STEP 5.                             â”‚
â”‚  Steps 1-4 handle millions of users for most applications.      â”‚
â”‚  Sharding is for companies with hundreds of millions of         â”‚
â”‚  rows and thousands of writes per second.                       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# PART 4: CACHING AT EVERY LAYER

## 4.1 The Caching Hierarchy

**Caching isn't one thing. It's a CHAIN of caches, each closer to the user.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  THE CACHING HIERARCHY                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚            USER (browser)                                       â”‚
â”‚                â”‚                                                â”‚
â”‚           â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                                          â”‚
â”‚     â‘      â”‚ BROWSER  â”‚  HTTP cache headers (Cache-Control)      â”‚
â”‚           â”‚ CACHE    â”‚  Static assets, some API responses       â”‚
â”‚           â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                          â”‚
â”‚                â”‚  cache miss                                    â”‚
â”‚           â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                                          â”‚
â”‚     â‘¡     â”‚   CDN    â”‚  Edge servers worldwide                  â”‚
â”‚           â”‚          â”‚  Static files, public API responses      â”‚
â”‚           â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                          â”‚
â”‚                â”‚  cache miss                                    â”‚
â”‚           â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                                          â”‚
â”‚     â‘¢     â”‚   LOAD   â”‚                                          â”‚
â”‚           â”‚ BALANCER â”‚  (routes to app server)                  â”‚
â”‚           â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                          â”‚
â”‚                â”‚                                                â”‚
â”‚           â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                                          â”‚
â”‚     â‘£     â”‚  APP     â”‚  Redis / in-memory cache                 â”‚
â”‚           â”‚  CACHE   â”‚  Hot data, computed results              â”‚
â”‚           â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                          â”‚
â”‚                â”‚  cache miss                                    â”‚
â”‚           â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                                          â”‚
â”‚     â‘¤     â”‚ DATABASE â”‚  Query cache, materialized views         â”‚
â”‚           â”‚  CACHE   â”‚  Internal PostgreSQL buffer pool         â”‚
â”‚           â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                          â”‚
â”‚                â”‚  cache miss                                    â”‚
â”‚           â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                                          â”‚
â”‚     â‘¥     â”‚ DATABASE â”‚  Actual disk read                        â”‚
â”‚           â”‚  DISK    â”‚  The source of truth                     â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                          â”‚
â”‚                                                                 â”‚
â”‚  Each layer catches requests BEFORE they reach the next.        â”‚
â”‚  The more requests caught early, the less load on the DB.       â”‚
â”‚                                                                 â”‚
â”‚  THE RESTAURANT ANALOGY:                                        â”‚
â”‚  â‘  Customer remembers the menu from last visit (browser)        â”‚
â”‚  â‘¡ Menu board outside the building (CDN)                        â”‚
â”‚  â‘¢ Host stand directs you (load balancer)                       â”‚
â”‚  â‘£ "Today's specials" board inside â€” waiter answers             â”‚
â”‚     without asking the kitchen (Redis app cache)                â”‚
â”‚  â‘¤ Pre-prepped sauce bases in the kitchen (DB cache)            â”‚
â”‚  â‘¥ Actually cooking from raw ingredients (DB disk read)         â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4.2 CDN â€” Content Delivery Network

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CDN                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  A CDN is a NETWORK OF SERVERS distributed worldwide.           â”‚
â”‚  They cache and serve content from a location CLOSE to the      â”‚
â”‚  user, instead of going all the way to your origin server.      â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  WITHOUT CDN:                                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                   â”‚
â”‚  User in Tokyo â”€â”€â”€ 12,000 km â”€â”€â”€â–¶ Server in Virginia           â”‚
â”‚  Latency: ~150ms round trip                                     â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  WITH CDN:                                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                     â”‚
â”‚  User in Tokyo â”€â”€â”€ 50 km â”€â”€â”€â–¶ CDN Edge in Tokyo                â”‚
â”‚  Latency: ~5ms round trip                                       â”‚
â”‚                                                                 â”‚
â”‚  The CDN edge has a CACHED COPY of the content.                 â”‚
â”‚  If it doesn't (cache miss), it fetches from your origin        â”‚
â”‚  server, caches it, and serves future requests locally.         â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚       User        User        User                              â”‚
â”‚      (Tokyo)    (London)    (SÃ£o Paulo)                         â”‚
â”‚        â”‚           â”‚           â”‚                                â”‚
â”‚        â–¼           â–¼           â–¼                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚   â”‚CDN Edge â”‚ â”‚CDN Edge â”‚ â”‚CDN Edge â”‚                          â”‚
â”‚   â”‚ Tokyo   â”‚ â”‚ London  â”‚ â”‚SÃ£o Pauloâ”‚                          â”‚
â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                          â”‚
â”‚        â”‚           â”‚           â”‚                                â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚                    â”‚  (cache miss only)                         â”‚
â”‚                    â–¼                                            â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â”‚
â”‚            â”‚ Your Server  â”‚                                     â”‚
â”‚            â”‚ (Virginia)   â”‚                                     â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  WHAT CDNs CACHE WELL:                                          â”‚
â”‚  â”œâ”€ Static assets (images, CSS, JS, fonts)                      â”‚
â”‚  â”œâ”€ Public API responses that rarely change                     â”‚
â”‚  â”œâ”€ Documentation pages, marketing pages                        â”‚
â”‚  â””â”€ Pre-rendered content                                        â”‚
â”‚                                                                 â”‚
â”‚  WHAT CDNs CANNOT CACHE:                                        â”‚
â”‚  â”œâ”€ User-specific data (my tasks, my dashboard)                 â”‚
â”‚  â”œâ”€ Real-time data (live WebSocket feeds)                       â”‚
â”‚  â””â”€ Write operations (POST, PUT, DELETE)                        â”‚
â”‚                                                                 â”‚
â”‚  Connection to Week 15: Cloud providers (AWS CloudFront,        â”‚
â”‚  GCP Cloud CDN) offer built-in CDN. It's a config switch,      â”‚
â”‚  not a code change.                                             â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4.3 Application Cache (Your Redis Knowledge)

**You've already built this layer. Let's see where it fits in the big picture.**

> "In Week 10, you added Redis caching to your project. You implemented cache-aside, TTL, and cache invalidation on write. That work wasn't a standalone feature â€” it was building one layer of this caching hierarchy."

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        APPLICATION CACHE IN THE BIG PICTURE                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  YOUR WEEK 10 CACHING:                 ITS ROLE AT SCALE:       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       â”‚
â”‚  Cache-aside pattern          â†’   Reduces DB reads by 80-95%    â”‚
â”‚  TTL-based expiration         â†’   Balances freshness vs load    â”‚
â”‚  Invalidation on write        â†’   Prevents stale data           â”‚
â”‚  Redis as FastAPI dependency  â†’   Shared across all servers     â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  WHY THIS MATTERS AT SCALE:                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚                                                                 â”‚
â”‚  Without cache:   10 servers Ã— 1,000 reads/sec = 10,000 DB     â”‚
â”‚                   reads/sec (DB struggles)                       â”‚
â”‚                                                                 â”‚
â”‚  With 90% hit:    10 servers Ã— 1,000 reads/sec â†’ 9,000 from    â”‚
â”‚                   Redis, 1,000 from DB (DB is relaxed)          â”‚
â”‚                                                                 â”‚
â”‚  Redis handles 100,000 ops/sec. Your database handles 10,000.  â”‚
â”‚  The cache absorbs 90% of the load that would crush your DB.   â”‚
â”‚                                                                 â”‚
â”‚  This is why caching comes BEFORE read replicas in the          â”‚
â”‚  decision framework. It's cheaper, simpler, and often enough.  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**What to cache at the application level (decision guide):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          WHAT TO CACHE (DECISION GUIDE)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚                    How often does it change?                     â”‚
â”‚                    â”‚                                            â”‚
â”‚         Rarely     â”‚             Frequently                     â”‚
â”‚     â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶                         â”‚
â”‚     â”‚              â”‚                  â”‚                         â”‚
â”‚     â”‚              â”‚                  â”‚                         â”‚
â”‚  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”                      â”‚
â”‚  â”‚ LONG TTL     â”‚  â”‚  â”‚ SHORT TTL       â”‚                      â”‚
â”‚  â”‚ (hours/days) â”‚  â”‚  â”‚ (seconds/mins)  â”‚                      â”‚
â”‚  â”‚              â”‚  â”‚  â”‚                 â”‚                       â”‚
â”‚  â”‚ â€¢ App config â”‚  â”‚  â”‚ â€¢ Dashboard     â”‚                       â”‚
â”‚  â”‚ â€¢ Permission â”‚  â”‚  â”‚   aggregations  â”‚                       â”‚
â”‚  â”‚   matrices   â”‚  â”‚  â”‚ â€¢ Search resultsâ”‚                       â”‚
â”‚  â”‚ â€¢ Static     â”‚  â”‚  â”‚ â€¢ User profile  â”‚                       â”‚
â”‚  â”‚   lookups    â”‚  â”‚  â”‚   data          â”‚                       â”‚
â”‚  â”‚              â”‚  â”‚  â”‚                 â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                    â”‚                                            â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚            â”‚  DON'T CACHE    â”‚                                  â”‚
â”‚            â”‚                 â”‚                                  â”‚
â”‚            â”‚ â€¢ Write-heavy   â”‚                                  â”‚
â”‚            â”‚   data          â”‚                                  â”‚
â”‚            â”‚ â€¢ User-unique   â”‚                                  â”‚
â”‚            â”‚   one-time data â”‚                                  â”‚
â”‚            â”‚ â€¢ Security-     â”‚                                  â”‚
â”‚            â”‚   critical data â”‚                                  â”‚
â”‚            â”‚   (balances,    â”‚                                  â”‚
â”‚            â”‚    permissions  â”‚                                  â”‚
â”‚            â”‚    during       â”‚                                  â”‚
â”‚            â”‚    changes)     â”‚                                  â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4.4 Database-Level Caching

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 DATABASE-LEVEL CACHING                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  PostgreSQL has its OWN caching â€” you don't control it          â”‚
â”‚  directly, but you should know it exists.                       â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  1. BUFFER POOL (shared_buffers)                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                               â”‚
â”‚  PostgreSQL keeps frequently accessed data pages in RAM.        â”‚
â”‚  When you query a row, PostgreSQL checks RAM first,             â”‚
â”‚  disk second. This is automatic.                                â”‚
â”‚                                                                 â”‚
â”‚  Tuning: Set shared_buffers to ~25% of server RAM.              â”‚
â”‚  Default is usually too low (128MB).                            â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  2. MATERIALIZED VIEWS                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚
â”‚  A pre-computed query result stored as a "frozen table."        â”‚
â”‚  Your dashboard showing "tasks per project" with complex        â”‚
â”‚  JOINs and aggregations? Compute it once, store the result.     â”‚
â”‚                                                                 â”‚
â”‚  CREATE MATERIALIZED VIEW dashboard_stats AS                    â”‚
â”‚    SELECT org_id, COUNT(*) as total_tasks,                      â”‚
â”‚           COUNT(*) FILTER (WHERE status = 'done') as completed  â”‚
â”‚    FROM tasks                                                   â”‚
â”‚    GROUP BY org_id;                                             â”‚
â”‚                                                                 â”‚
â”‚  -- Reads: blazing fast (pre-computed)                          â”‚
â”‚  -- Must REFRESH periodically:                                  â”‚
â”‚  REFRESH MATERIALIZED VIEW CONCURRENTLY dashboard_stats;        â”‚
â”‚                                                                 â”‚
â”‚  This is like the kitchen pre-making soup stock every morning.  â”‚
â”‚  When a customer orders soup, the base is already done.         â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  3. CONNECTION-LEVEL: PREPARED STATEMENTS                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                       â”‚
â”‚  PostgreSQL caches the query plan for repeated queries.         â”‚
â”‚  SQLAlchemy uses prepared statements by default with asyncpg.   â”‚
â”‚  You've been benefiting from this since Week 6.                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4.5 Cache Invalidation (The Hardest Problem)

> "There are only two hard things in Computer Science: cache invalidation and naming things." â€” Phil Karlton

**You encountered this in Week 10. At scale, it gets worse.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               CACHE INVALIDATION AT SCALE                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  THE PROBLEM:                                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                   â”‚
â”‚  Data in the database changes.                                  â”‚
â”‚  Cached copy is now STALE (outdated).                           â”‚
â”‚  How do you keep caches in sync?                                â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  SINGLE SERVER (Week 10 â€” what you did):                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”‚
â”‚  User updates task â†’ delete cache key â†’ next read refills it    â”‚
â”‚  Simple. One Redis, one server, one point of change.            â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  MULTIPLE LAYERS (at scale):                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                   â”‚
â”‚  User updates task â†’                                            â”‚
â”‚    Delete from Redis?               âœ… (you control this)       â”‚
â”‚    Invalidate CDN edge caches?      âš ï¸  (harder, API call       â”‚
â”‚                                         to CDN provider)        â”‚
â”‚    Clear browser cache?             âŒ (you can't! client-side) â”‚
â”‚    Update read replicas?            âš ï¸  (replication lag)       â”‚
â”‚    Refresh materialized views?      âš ï¸  (background job)       â”‚
â”‚                                                                 â”‚
â”‚  Every cache layer has its own invalidation challenge.          â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  THE RESTAURANT ANALOGY:                                        â”‚
â”‚  The head chef changes a recipe. Now you must:                  â”‚
â”‚  â”œâ”€ Update the daily specials board (app cache)         Easy    â”‚
â”‚  â”œâ”€ Reprint the menus at this location (DB cache)       Medium  â”‚
â”‚  â”œâ”€ Update the outdoor menu board (CDN)                 Medium  â”‚
â”‚  â”œâ”€ Ship new menus to all other locations (replicas)    Hard    â”‚
â”‚  â””â”€ Recall every menu photo a customer saved (browser)  LOL     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Practical strategies:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            INVALIDATION STRATEGIES (REVIEW)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. TIME-BASED (TTL) â€” the simplest and most robust             â”‚
â”‚     Set it and forget it. Data may be stale for up to TTL.      â”‚
â”‚     For many use cases, 30-60 seconds of staleness is fine.     â”‚
â”‚                                                                 â”‚
â”‚  2. EVENT-BASED â€” invalidate when data changes                  â”‚
â”‚     Your Week 10 pattern: write to DB â†’ delete cache key.       â”‚
â”‚     More complex but keeps data fresher.                        â”‚
â”‚     Connection to Week 11: Celery tasks or Redis pub/sub        â”‚
â”‚     can broadcast invalidation events.                          â”‚
â”‚                                                                 â”‚
â”‚  3. VERSIONED KEYS â€” avoid invalidation entirely                â”‚
â”‚     Instead of cache key "user:42:profile",                     â”‚
â”‚     use "user:42:profile:v7"                                    â”‚
â”‚     When data changes, increment version â†’ old key expires      â”‚
â”‚     naturally via TTL. No explicit invalidation needed.         â”‚
â”‚                                                                 â”‚
â”‚  RULE OF THUMB:                                                 â”‚
â”‚  Start with TTL. Add event-based only for data that MUST        â”‚
â”‚  be fresh within seconds. Accept staleness where you can.       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# PART 5: CAP THEOREM & DESIGN THINKING

## 5.1 The CAP Theorem

**The CAP theorem defines the fundamental limits of distributed systems.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    THE CAP THEOREM                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  In a distributed data store, you can only guarantee            â”‚
â”‚  TWO of these three properties simultaneously:                  â”‚
â”‚                                                                 â”‚
â”‚                    CONSISTENCY                                   â”‚
â”‚                        â•±â•²                                       â”‚
â”‚                       â•±  â•²                                      â”‚
â”‚                      â•±    â•²                                     â”‚
â”‚                     â•± PICK â•²                                    â”‚
â”‚                    â•±  TWO   â•²                                   â”‚
â”‚                   â•±          â•²                                  â”‚
â”‚     AVAILABILITY â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•² PARTITION                       â”‚
â”‚                                 TOLERANCE                       â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  C â€” CONSISTENCY                                                â”‚
â”‚  Every read receives the most recent write or an error.         â”‚
â”‚  All nodes see the same data at the same time.                  â”‚
â”‚                                                                 â”‚
â”‚  A â€” AVAILABILITY                                               â”‚
â”‚  Every request receives a response (not an error),              â”‚
â”‚  without guarantee that it contains the most recent write.      â”‚
â”‚                                                                 â”‚
â”‚  P â€” PARTITION TOLERANCE                                        â”‚
â”‚  The system continues to operate despite network failures       â”‚
â”‚  between nodes (messages are lost or delayed).                  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Now here's what most explanations get WRONG:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          THE COMMON MISCONCEPTION ABOUT CAP                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  âŒ WRONG interpretation:                                        â”‚
â”‚  "Pick 2 of 3. You can have CA, CP, or AP."                     â”‚
â”‚                                                                 â”‚
â”‚  âœ… CORRECT interpretation:                                      â”‚
â”‚  Network partitions WILL happen in any distributed system.      â”‚
â”‚  You can't opt out of P. Networks fail. Cables get cut.         â”‚
â”‚  Data centers lose connectivity.                                â”‚
â”‚                                                                 â”‚
â”‚  So the REAL choice is:                                          â”‚
â”‚  When a partition occurs, do you sacrifice C or A?              â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ CP SYSTEM       â”‚         â”‚ AP SYSTEM       â”‚               â”‚
â”‚  â”‚                 â”‚         â”‚                 â”‚               â”‚
â”‚  â”‚ During network  â”‚         â”‚ During network  â”‚               â”‚
â”‚  â”‚ partition:      â”‚         â”‚ partition:      â”‚               â”‚
â”‚  â”‚                 â”‚         â”‚                 â”‚               â”‚
â”‚  â”‚ Refuse requests â”‚         â”‚ Serve requests  â”‚               â”‚
â”‚  â”‚ to guarantee    â”‚         â”‚ but data may be â”‚               â”‚
â”‚  â”‚ data is correct â”‚         â”‚ stale/outdated  â”‚               â”‚
â”‚  â”‚                 â”‚         â”‚                 â”‚               â”‚
â”‚  â”‚ "I'd rather     â”‚         â”‚ "I'd rather     â”‚               â”‚
â”‚  â”‚  give you NO    â”‚         â”‚  give you OLD   â”‚               â”‚
â”‚  â”‚  answer than a  â”‚         â”‚  data than NO   â”‚               â”‚
â”‚  â”‚  WRONG answer"  â”‚         â”‚  answer"        â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                                 â”‚
â”‚  When there's NO partition (most of the time), you can          â”‚
â”‚  have BOTH consistency AND availability. CAP only forces         â”‚
â”‚  a choice during failures.                                      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The restaurant chain analogy for CAP:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                CAP IN THE RESTAURANT CHAIN                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Consistency = Every location has the exact same menu           â”‚
â”‚  Availability = Every location is always open for business      â”‚
â”‚  Partition = Phone line between HQ and Location B goes down     â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  SCENARIO: HQ removes a dish (allergen found).                  â”‚
â”‚            Phone to Location B is down.                         â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  CP CHOICE:                                                     â”‚
â”‚  "Location B, CLOSE your kitchen until we can confirm you       â”‚
â”‚   have the updated menu. We can't risk serving that dish."      â”‚
â”‚                                                                 â”‚
â”‚   âœ… No customer gets the dangerous dish (consistent)            â”‚
â”‚   âŒ Location B loses all business until phones work (not        â”‚
â”‚      available)                                                  â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  AP CHOICE:                                                     â”‚
â”‚  "Location B, stay open. Serve what you have. We'll update      â”‚
â”‚   the menu as soon as phones are back."                         â”‚
â”‚                                                                 â”‚
â”‚   âœ… Location B still serves customers (available)               â”‚
â”‚   âŒ Some customers might order the removed dish (inconsistent)  â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  WHICH IS BETTER? Depends on what you're serving.               â”‚
â”‚  Allergen risk? CP. Minor recipe tweak? AP.                     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5.2 CP vs AP in Practice

**Systems you know, classified:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             REAL SYSTEMS AND THEIR CAP CHOICES                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  CP SYSTEMS (Consistency + Partition Tolerance)                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”‚
â”‚                                                                 â”‚
â”‚  PostgreSQL (with synchronous replication)                       â”‚
â”‚  â”œâ”€ Your capstone's database.                                   â”‚
â”‚  â”œâ”€ Refuses to confirm a write until replica has it.            â”‚
â”‚  â””â”€ If replica is unreachable â†’ write BLOCKS or FAILS.          â”‚
â”‚                                                                 â”‚
â”‚  When CP is right:                                              â”‚
â”‚  â”œâ”€ Financial transactions (bank transfers)                     â”‚
â”‚  â”œâ”€ Inventory management (can't oversell)                       â”‚
â”‚  â”œâ”€ User authentication (security-critical)                     â”‚
â”‚  â””â”€ Anything where WRONG data is worse than NO data             â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  AP SYSTEMS (Availability + Partition Tolerance)                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”‚
â”‚                                                                 â”‚
â”‚  DNS (Domain Name System)                                       â”‚
â”‚  â”œâ”€ Returns cached IP addresses even if root servers are down.  â”‚
â”‚  â”œâ”€ May serve stale records briefly.                            â”‚
â”‚  â””â”€ Better to serve old IP than refuse to resolve entirely.     â”‚
â”‚                                                                 â”‚
â”‚  Redis (default configuration)                                  â”‚
â”‚  â”œâ”€ Your cache layer from Week 10.                              â”‚
â”‚  â”œâ”€ In a Redis cluster, reads succeed even during partition.    â”‚
â”‚  â””â”€ Some reads may return stale data briefly.                   â”‚
â”‚                                                                 â”‚
â”‚  When AP is right:                                              â”‚
â”‚  â”œâ”€ Social media feeds (slightly stale is fine)                 â”‚
â”‚  â”œâ”€ Product catalogs (cached prices, periodic refresh)          â”‚
â”‚  â”œâ”€ Analytics dashboards (eventually consistent)                â”‚
â”‚  â””â”€ Anything where STALE data is better than NO data            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Connection to your capstone:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          YOUR CAPSTONE'S CAP CHOICES (YOU ALREADY MADE THEM)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  FEATURE                NEEDS           YOUR IMPLEMENTATION     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€                â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚  User login/auth        Strong C        PostgreSQL (CP)         â”‚
â”‚  Task creation          Strong C        PostgreSQL (CP)         â”‚
â”‚  Dashboard stats        Eventual C      Redis cache + TTL (AP)  â”‚
â”‚  WebSocket notifs       Availability    Redis pub/sub (AP)      â”‚
â”‚  Audit log              Strong C        PostgreSQL (CP)         â”‚
â”‚  Search results         Eventual C      Cached / tolerate lag   â”‚
â”‚                                                                 â”‚
â”‚  You naturally made different CAP choices for different          â”‚
â”‚  features without knowing the formal framework.                 â”‚
â”‚                                                                 â”‚
â”‚  Auth data goes directly to PostgreSQL (you can't risk stale    â”‚
â”‚  permissions). Dashboard data comes from Redis with a TTL       â”‚
â”‚  (a 30-second-old task count is fine for a dashboard).          â”‚
â”‚                                                                 â”‚
â”‚  SYSTEM DESIGN ISN'T PICKING CP OR AP FOR YOUR WHOLE APP.       â”‚
â”‚  IT'S PICKING CP OR AP PER FEATURE, per data path.              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5.3 Everything is a Tradeoff

**System design is not about finding the "best" architecture. It's about choosing which problems you're willing to have.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               THE TRADEOFF MATRIX                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  DECISION               GAIN                COST                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€               â”€â”€â”€â”€                â”€â”€â”€â”€                â”‚
â”‚                                                                 â”‚
â”‚  Add caching            Lower latency,      Cache invalidation  â”‚
â”‚  (Redis)                reduced DB load     complexity, stale   â”‚
â”‚                                             data risk           â”‚
â”‚                                                                 â”‚
â”‚  Add read               Read throughput,    Replication lag,     â”‚
â”‚  replicas               redundancy          write still limited, â”‚
â”‚                                             operational cost     â”‚
â”‚                                                                 â”‚
â”‚  Shard the              Write throughput,   Cross-shard queries  â”‚
â”‚  database               smaller indexes     hard, operational    â”‚
â”‚                                             nightmare            â”‚
â”‚                                                                 â”‚
â”‚  Add load               Redundancy,         New failure point,   â”‚
â”‚  balancer               horizontal scale    added latency (ms),  â”‚
â”‚                                             complexity           â”‚
â”‚                                                                 â”‚
â”‚  Use CDN                Global low latency, Cache invalidation,  â”‚
â”‚                         reduced bandwidth   cost per GB, only    â”‚
â”‚                                             helps cacheable data â”‚
â”‚                                                                 â”‚
â”‚  Background             Decoupled, async    Eventually consistentâ”‚
â”‚  jobs (Celery)          processing          job failures need    â”‚
â”‚                                             monitoring, debuggingâ”‚
â”‚                                             is harder            â”‚
â”‚                                                                 â”‚
â”‚  EVERY architectural decision gives you something and costs     â”‚
â”‚  you something. The skill is knowing what your system can       â”‚
â”‚  afford to lose.                                                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The question to always ask:**

> "When someone proposes an architectural change, ask: 'What gets worse?' If they can't answer, they don't understand the change. Every improvement has a cost. Find it."

---

## 5.4 Full Architecture â€” Putting It All Together

**This is what your capstone looks like at 10M users. Every component maps to something you've built or learned:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          FULL PRODUCTION ARCHITECTURE (10M Users)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                     CLIENTS                              â”‚   â”‚
â”‚  â”‚            (browsers, mobile apps)                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                     â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚                    â”‚     CDN     â”‚ â† Static assets, public data â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   (Section 4.2)              â”‚
â”‚                           â”‚ (dynamic requests pass through)     â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚                    â”‚    LOAD     â”‚ â† Distributes traffic        â”‚
â”‚                    â”‚  BALANCER   â”‚   (Section 2.4)              â”‚
â”‚                    â””â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”˜                               â”‚
â”‚                       â”‚   â”‚   â”‚                                  â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚              â–¼            â–¼            â–¼                          â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚        â”‚ FastAPI  â”‚ â”‚ FastAPI  â”‚ â”‚ FastAPI  â”‚ â† Your app Ã—N     â”‚
â”‚        â”‚ Server 1 â”‚ â”‚ Server 2 â”‚ â”‚ Server 3 â”‚   (Weeks 3-14)    â”‚
â”‚        â””â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”˜                    â”‚
â”‚           â”‚   â”‚        â”‚   â”‚        â”‚   â”‚                        â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”˜   â””â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”                  â”‚
â”‚     â–¼            â–¼            â–¼               â–¼                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ Redis â”‚  â”‚ Celery   â”‚  â”‚ PostgreSQL  â”‚  â”‚Externalâ”‚           â”‚
â”‚  â”‚ Cache â”‚  â”‚ Workers  â”‚  â”‚             â”‚  â”‚  APIs  â”‚           â”‚
â”‚  â”‚       â”‚  â”‚          â”‚  â”‚  Primary    â”‚  â”‚        â”‚           â”‚
â”‚  â”‚Week 10â”‚  â”‚ Week 11  â”‚  â”‚  â”Œâ”€â”€â”´â”€â”€â”   â”‚  â”‚ Week 8 â”‚           â”‚
â”‚  â”‚       â”‚  â”‚          â”‚  â”‚  R1   R2   â”‚  â”‚        â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â”‚ (replicas) â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                   â”‚       â”‚  Week 5-7  â”‚                        â”‚
â”‚                   â–¼       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                        â”‚
â”‚              â”‚  Redis   â”‚ â† Broker for Celery                   â”‚
â”‚              â”‚  (Queue) â”‚   + pub/sub for WebSockets             â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   (Week 11-12)                         â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚   Everything in this diagram is something you've built,         â”‚
â”‚   configured, or used. System design isn't new technology â€”     â”‚
â”‚   it's arranging known pieces at a larger scale.                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Walk through a single request:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          LIFE OF A REQUEST: "Get my tasks"                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. Client sends GET /api/v1/tasks                              â”‚
â”‚     Header: Authorization: Bearer <JWT>                         â”‚
â”‚                                                                 â”‚
â”‚  2. CDN: "This is a dynamic, authenticated request."            â”‚
â”‚     â†’ Pass through (can't cache user-specific data)             â”‚
â”‚                                                                 â”‚
â”‚  3. Load Balancer: "Server 2 has fewest connections."           â”‚
â”‚     â†’ Forward to Server 2                                       â”‚
â”‚                                                                 â”‚
â”‚  4. Server 2 (FastAPI):                                         â”‚
â”‚     a. Validate JWT (stateless â€” no DB needed) [Week 9]         â”‚
â”‚     b. Check Redis: "tasks:user:42:page:1" â†’ CACHE HIT âœ…       â”‚
â”‚     c. Return cached response. Done! (< 10ms)                   â”‚
â”‚                                                                 â”‚
â”‚  4. (alternate) CACHE MISS:                                     â”‚
â”‚     a. Validate JWT                                             â”‚
â”‚     b. Check Redis â†’ MISS                                       â”‚
â”‚     c. Query PostgreSQL read replica [Week 6 repository]        â”‚
â”‚     d. Store result in Redis with 60s TTL [Week 10]             â”‚
â”‚     e. Return response (< 100ms)                                â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  LIFE OF A REQUEST: "Create a task"                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                           â”‚
â”‚                                                                 â”‚
â”‚  1. Client sends POST /api/v1/tasks with JSON body              â”‚
â”‚  2. CDN: pass through (POST = not cacheable)                    â”‚
â”‚  3. Load Balancer â†’ Server 1                                    â”‚
â”‚  4. Server 1:                                                   â”‚
â”‚     a. Validate JWT [Week 9]                                    â”‚
â”‚     b. Validate body with Pydantic [Week 3]                     â”‚
â”‚     c. Write to PostgreSQL PRIMARY [Week 6]                     â”‚
â”‚     d. Invalidate Redis cache keys [Week 10]                    â”‚
â”‚     e. Dispatch Celery task: send notification [Week 11]        â”‚
â”‚     f. Publish WebSocket event via Redis pub/sub [Week 12]      â”‚
â”‚     g. Return 201 Created                                       â”‚
â”‚                                                                 â”‚
â”‚  EVERY step references something you've implemented.            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Quick Reference Card

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SYSTEM DESIGN QUICK REFERENCE                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  THE FRAMEWORK:                                                 â”‚
â”‚      1. Clarify requirements (functional + non-functional)      â”‚
â”‚      2. Estimate scale (users, RPS, storage, bandwidth)         â”‚
â”‚      3. Draw high-level design (boxes and arrows)               â”‚
â”‚      4. Detail critical components                              â”‚
â”‚      5. Identify tradeoffs and bottlenecks                      â”‚
â”‚                                                                 â”‚
â”‚  SCALING:                                                       â”‚
â”‚      Vertical = bigger machine (simple, limited)                â”‚
â”‚      Horizontal = more machines (complex, unlimited)            â”‚
â”‚      Stateless servers + shared external state = scalable       â”‚
â”‚                                                                 â”‚
â”‚  LOAD BALANCING:                                                â”‚
â”‚      Round Robin        â†’ simple, equal distribution            â”‚
â”‚      Least Connections  â†’ best default for most apps            â”‚
â”‚      IP Hash            â†’ when you need sticky sessions         â”‚
â”‚      Weighted           â†’ mixed server sizes or canary deploys  â”‚
â”‚                                                                 â”‚
â”‚  DATABASE SCALING (in order):                                   â”‚
â”‚      1. Optimize queries + indexes                              â”‚
â”‚      2. Scale up the machine                                    â”‚
â”‚      3. Add caching (Redis)                                     â”‚
â”‚      4. Add read replicas                                       â”‚
â”‚      5. Shard (last resort)                                     â”‚
â”‚                                                                 â”‚
â”‚  CACHING LAYERS (closest to user first):                        â”‚
â”‚      Browser â†’ CDN â†’ Load Balancer â†’ App Cache â†’ DB Cache â†’ DB  â”‚
â”‚                                                                 â”‚
â”‚  CAP THEOREM:                                                   â”‚
â”‚      Partitions are inevitable. Choose per feature:             â”‚
â”‚      CP = correct data or error (financial, auth)               â”‚
â”‚      AP = available data, maybe stale (feeds, dashboards)       â”‚
â”‚                                                                 â”‚
â”‚  GOLDEN RULES:                                                  â”‚
â”‚      â€¢ Measure before optimizing (Week 12 load tests)           â”‚
â”‚      â€¢ Prefer simple over distributed (scale up first)          â”‚
â”‚      â€¢ Every gain has a cost (name the tradeoff)                â”‚
â”‚      â€¢ Design for the common case, handle the edge case         â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Summary: The Key Mental Model

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  SYSTEM DESIGN = SCALING WHAT YOU'VE ALREADY BUILT              â”‚
â”‚                                                                 â”‚
â”‚  You spent 15 weeks building a complete backend system.         â”‚
â”‚  Today you learned that every piece you built has a place       â”‚
â”‚  in a larger architecture.                                      â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚                                                      â”‚       â”‚
â”‚  â”‚  WHAT YOU BUILT           WHERE IT FITS AT SCALE     â”‚       â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚       â”‚
â”‚  â”‚  FastAPI async (W1,3)     Handles 1000s of conns     â”‚       â”‚
â”‚  â”‚  Pydantic (W3)            Validates at every server  â”‚       â”‚
â”‚  â”‚  PostgreSQL (W5-7)        Primary + replicas         â”‚       â”‚
â”‚  â”‚  SQLAlchemy (W6)          Routes reads/writes        â”‚       â”‚
â”‚  â”‚  Alembic (W6)             Migrates all shards        â”‚       â”‚
â”‚  â”‚  JWT auth (W9)            Stateless = scalable       â”‚       â”‚
â”‚  â”‚  Redis cache (W10)        Shared cache layer         â”‚       â”‚
â”‚  â”‚  Celery (W11)             Distributed workers        â”‚       â”‚
â”‚  â”‚  WebSockets (W12)         Scale via Redis pub/sub    â”‚       â”‚
â”‚  â”‚  Load tests (W12)         Prove your design works    â”‚       â”‚
â”‚  â”‚  Docker (W15)             Identical server copies    â”‚       â”‚
â”‚  â”‚  Health checks (W15)      Load balancer integration  â”‚       â”‚
â”‚  â”‚  CI/CD (W15)              Deploy to N servers        â”‚       â”‚
â”‚  â”‚                                                      â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                 â”‚
â”‚  THE RESTAURANT CHAIN:                                          â”‚
â”‚  â”œâ”€ One restaurant â†’ chain of restaurants                       â”‚
â”‚  â”œâ”€ Bigger restaurant â†’ more locations                          â”‚
â”‚  â”œâ”€ Central reservations â†’ load balancer                        â”‚
â”‚  â”œâ”€ Master recipe book + copies â†’ primary + replicas            â”‚
â”‚  â”œâ”€ Split by cuisine â†’ sharding                                 â”‚
â”‚  â”œâ”€ Menu boards â†’ CDN + caches                                  â”‚
â”‚  â””â”€ "Every location, same menu" vs "always open" â†’ CAP         â”‚
â”‚                                                                 â”‚
â”‚  System design isn't about learning new tools.                  â”‚
â”‚  It's about learning to THINK about the tools you already       â”‚
â”‚  know â€” at a scale where one machine isn't enough.              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Connection to Upcoming Lectures

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WHERE THIS LEADS                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  WEEK 16, LECTURE 2 â€” Architecture Patterns:                    â”‚
â”‚  â””â”€ Today you learned the PIECES (load balancers, replicas,     â”‚
â”‚     caching, sharding). Next lecture you'll learn how to        â”‚
â”‚     ARRANGE them: monolith vs microservices, event-driven       â”‚
â”‚     architecture, API gateways, designing for failure.          â”‚
â”‚     Today = components. Next = composition.                     â”‚
â”‚                                                                 â”‚
â”‚  WEEK 16, LECTURE 3 â€” DSA & Interview Prep:                     â”‚
â”‚  â””â”€ The system design framework from today IS the interview     â”‚
â”‚     format. You'll practice applying it to common system        â”‚
â”‚     design problems: "Design a URL shortener", "Design a        â”‚
â”‚     chat app." You'll also learn how to talk about YOUR         â”‚
â”‚     capstone as a system design case study.                     â”‚
â”‚                                                                 â”‚
â”‚  FINAL DELIVERABLE:                                             â”‚
â”‚  â””â”€ Your README's architecture diagram should now show          â”‚
â”‚     WHERE load balancers, caches, and replicas would go         â”‚
â”‚     in a production deployment â€” not just your Docker           â”‚
â”‚     Compose local setup. Show you understand the path           â”‚
â”‚     from your single-machine capstone to a production           â”‚
â”‚     system. That's what separates a student project from        â”‚
â”‚     professional thinking.                                      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```