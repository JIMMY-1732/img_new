# LECTURE DESIGN PHILOSOPHY

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PEDAGOGICAL APPROACH                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  FEEL THE WRONG GUESS FIRST                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚  Students will guess where a bottleneck is. They'll be wrong.   â”‚
â”‚  That failure is the lesson. You can't intuit performance.      â”‚
â”‚                                                                 â”‚
â”‚  DIAGNOSE BEFORE YOU PRESCRIBE                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â”‚
â”‚  The doctor analogy carries this entire lecture.                 â”‚
â”‚  Measurement is not optional â€” it is the FIRST step.            â”‚
â”‚                                                                 â”‚
â”‚  TOOLS SERVE METHODOLOGY, NOT THE REVERSE                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”‚
â”‚  We don't teach Locust for its own sake.                        â”‚
â”‚  We teach a systematic optimization CYCLE that uses tools.      â”‚
â”‚                                                                 â”‚
â”‚  CONNECT TO THE ENTIRE COURSE                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                   â”‚
â”‚  This lecture ties together almost every prior topic:            â”‚
â”‚  Async (W1), FastAPI (W3), SQLAlchemy (W6), EXPLAIN (W7),       â”‚
â”‚  Redis (W10), Celery (W11), WebSockets (W12 L1-2).             â”‚
â”‚  Performance is where it all converges.                         â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# LECTURE OUTLINE

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PERFORMANCE MEASUREMENT & OPTIMIZATION             â”‚
â”‚                      (3â€“4 Hour Lecture)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  PART 1: THE PROBLEM â€” "It Feels Slow" (45 min)                â”‚
â”‚  â”œâ”€ 1.1 The Guessing Game (Demonstration)                       â”‚
â”‚  â”œâ”€ 1.2 Why Intuition Fails                                     â”‚
â”‚  â”œâ”€ 1.3 The Doctor Analogy                                      â”‚
â”‚  â””â”€ 1.4 Anatomy of a Request (Where Time Hides)                â”‚
â”‚                                                                 â”‚
â”‚  PART 2: REQUEST TIMING MIDDLEWARE (40 min)                     â”‚
â”‚  â”œâ”€ 2.1 Middleware vs Dependencies (Brief)                      â”‚
â”‚  â”œâ”€ 2.2 Building a Timing Middleware                            â”‚
â”‚  â”œâ”€ 2.3 Structured Performance Logging                          â”‚
â”‚  â””â”€ 2.4 Server-Timing Header                                   â”‚
â”‚                                                                 â”‚
â”‚  PART 3: DATABASE QUERY PROFILING (45 min)                      â”‚
â”‚  â”œâ”€ 3.1 SQLAlchemy Query Logging                                â”‚
â”‚  â”œâ”€ 3.2 Counting Queries Per Request                            â”‚
â”‚  â”œâ”€ 3.3 Catching N+1 in Production                              â”‚
â”‚  â””â”€ 3.4 Query Count Assertions in Tests                         â”‚
â”‚                                                                 â”‚
â”‚  PART 4: RESPONSE OPTIMIZATION TECHNIQUES (30 min)              â”‚
â”‚  â”œâ”€ 4.1 Response Compression (GzipMiddleware)                   â”‚
â”‚  â”œâ”€ 4.2 Parallel Operations in Endpoints                        â”‚
â”‚  â””â”€ 4.3 The Optimization Toolbox                                â”‚
â”‚                                                                 â”‚
â”‚  PART 5: LOAD TESTING WITH LOCUST (45 min)                      â”‚
â”‚  â”œâ”€ 5.1 Why Load Test? (The Empty Restaurant Problem)           â”‚
â”‚  â”œâ”€ 5.2 Your First Locust Test                                  â”‚
â”‚  â”œâ”€ 5.3 Writing Realistic Scenarios                             â”‚
â”‚  â””â”€ 5.4 Reading Results and the Optimization Cycle              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# PART 1: THE PROBLEM â€” "It Feels Slow"

## 1.1 The Guessing Game

**Start with a piece of code. Make them commit to a wrong answer.**

Show this endpoint on screen. Tell students: this is a dashboard endpoint from a SaaS application like your capstone project. Users are complaining it's slow. **Read it carefully, then tell me: which part is the bottleneck?**

```python
# routes/dashboard.py â€” "Users say this is slow"

@router.get("/organizations/{org_id}/dashboard")
async def get_org_dashboard(
    org_id: int,
    db: AsyncSession = Depends(get_db),
    redis: Redis = Depends(get_redis),
):
    # --- Section A: Load org data ---
    org = await db.get(Organization, org_id)
    if not org:
        raise HTTPException(status_code=404, detail="Org not found")

    # Load all projects for this org
    stmt = select(Project).where(Project.org_id == org_id)
    result = await db.execute(stmt)
    projects = result.scalars().all()

    # For each project, load tasks and their assignees
    project_data = []
    for project in projects:
        tasks_stmt = select(Task).where(Task.project_id == project.id)
        tasks_result = await db.execute(tasks_stmt)
        tasks = tasks_result.scalars().all()

        task_details = []
        for task in tasks:
            assignee = await db.get(User, task.assignee_id)
            task_details.append({
                "id": task.id,
                "title": task.title,
                "status": task.status,
                "assignee": assignee.name if assignee else None,
            })

        project_data.append({
            "project_name": project.name,
            "task_count": len(tasks),
            "tasks": task_details,
        })

    # --- Section B: External enrichment ---
    async with httpx.AsyncClient(timeout=5.0) as client:
        analytics_resp = await client.get(
            f"https://analytics.example.com/api/org/{org_id}/summary"
        )
    async with httpx.AsyncClient(timeout=5.0) as client:
        weather_resp = await client.get(
            f"https://api.weather.example.com/current?city={org.city}"
        )

    # --- Section C: Build response ---
    return {
        "organization": org.name,
        "member_count": org.member_count,
        "projects": project_data,
        "analytics": analytics_resp.json(),
        "weather": weather_resp.json(),
    }
```

**Now poll the class:**

> "Raise your hand: who thinks Section A (database queries) is the bottleneck?"
> "Who thinks Section B (external API calls) is the bottleneck?"
> "Who thinks Section C (building the response) is the bottleneck?"

**Most students will pick Section B** â€” the external API calls. They *look* slow. They go over the network. They have a 5-second timeout. Surely that's the problem.

**Now reveal the actual timing data:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           ACTUAL TIMING BREAKDOWN (10 projects, 8 tasks each)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Section A â€” Database queries:                                  â”‚
â”‚  â”œâ”€ 1 query: get org                           5ms              â”‚
â”‚  â”œâ”€ 1 query: get all projects                  6ms              â”‚
â”‚  â”œâ”€ 10 queries: get tasks per project       10Ã—5ms = 50ms       â”‚
â”‚  â”œâ”€ 80 queries: get assignee per task       80Ã—5ms = 400ms  ğŸ”´  â”‚
â”‚  â”œâ”€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€               â”‚
â”‚  â””â”€ SUBTOTAL: 92 queries                    â‰ˆ 461ms             â”‚
â”‚                                                                 â”‚
â”‚  Section B â€” External API calls:                                â”‚
â”‚  â”œâ”€ Analytics API                             280ms             â”‚
â”‚  â”œâ”€ Weather API                               320ms             â”‚
â”‚  â”œâ”€ (run SEQUENTIALLY)                                          â”‚
â”‚  â”œâ”€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€               â”‚
â”‚  â””â”€ SUBTOTAL: 2 requests                   â‰ˆ 600ms             â”‚
â”‚                                                                 â”‚
â”‚  Section C â€” Response serialization:                            â”‚
â”‚  â””â”€ SUBTOTAL:                               â‰ˆ  40ms             â”‚
â”‚                                                                 â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•             â”‚
â”‚  TOTAL:                                     â‰ˆ 1,101ms           â”‚
â”‚                                                                 â”‚
â”‚  THE REAL BOTTLENECK:                                           â”‚
â”‚  92 database queries.  Not the 2 API calls.                     â”‚
â”‚  (And it gets WORSE with more projects/tasks.)                  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Now ask:**

> "How many of you picked Section B? You were wrong â€” but you were wrong for an interesting reason. The external API calls are *visibly* slow. You can point at them and say 'that's network, that's slow.' But the 92 invisible little database queries each took only 5 milliseconds. They don't *look* dangerous. They don't *feel* slow. But 5ms Ã— 92 = 461ms. **Death by a thousand paper cuts.**"

> "And here's the truly dangerous part: with 10 projects and 8 tasks each, it's 461ms. What happens when a customer has 50 projects and 20 tasks each? That's 1 + 1 + 50 + 1000 = **1,052 queries**. At 5ms each: **5.2 seconds** â€” just from the database. The external APIs are still 600ms. Your 'slow API calls' are now 10% of the total time."

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               SCALING BEHAVIOR                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Projects  Tasks/Project  DB Queries  DB Time   API Time  Total â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”€â”€â”€â”€â”€â”€â”€   â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€ â”‚
â”‚       5            4           27      135ms     600ms    775ms â”‚
â”‚      10            8           92      461ms     600ms   1101ms â”‚
â”‚      20           10          222     1110ms     600ms   1750ms â”‚
â”‚      50           20        1,052     5260ms     600ms   5900ms â”‚
â”‚                                                                 â”‚
â”‚  Section A: grows as O(projects Ã— tasks)  â† QUADRATIC  ğŸ”´      â”‚
â”‚  Section B: constant at ~600ms            â† FLAT       ğŸŸ¢      â”‚
â”‚                                                                 â”‚
â”‚  The "small" problem becomes the DOMINANT problem at scale.     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The lesson:**

> "You cannot intuit performance. You must MEASURE it. Every time someone says 'I think the bottleneck is X,' the correct response is: 'Show me the numbers.' That's what this lecture is about."

---

## 1.2 Why Intuition Fails

**Three reasons your gut feeling about performance is unreliable:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              WHY YOUR INTUITION IS WRONG                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  REASON 1: VISIBILITY BIAS                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚
â”‚  You notice what's OBVIOUS.                                     â”‚
â”‚                                                                 â”‚
â”‚  "External API call" LOOKS slow â†’ you suspect it.               â”‚
â”‚  "92 tiny queries in a loop" looks like normal code.            â”‚
â”‚  The biggest problems often hide in innocent-looking lines.     â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  REASON 2: SINGLE-REQUEST THINKING                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                              â”‚
â”‚  You test with 1 user. Production has 500.                      â”‚
â”‚                                                                 â”‚
â”‚  An endpoint at 200ms with 1 user might be 3,000ms              â”‚
â”‚  with 200 concurrent users (connection pool exhaustion,         â”‚
â”‚  lock contention, Redis pipeline saturation).                   â”‚
â”‚  You'll never see this from your browser.                       â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  REASON 3: AVERAGES LIE                                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                           â”‚
â”‚  "Average response time: 150ms" â€” sounds great!                 â”‚
â”‚                                                                 â”‚
â”‚  Reality:                                                       â”‚
â”‚  â”œâ”€ 95 requests at 50ms                                         â”‚
â”‚  â”œâ”€  4 requests at 500ms                                        â”‚
â”‚  â””â”€  1 request at 5,200ms   â† This user is FURIOUS             â”‚
â”‚                                                                 â”‚
â”‚  Average: (95Ã—50 + 4Ã—500 + 1Ã—5200) / 100 = 119ms               â”‚
â”‚                                                                 â”‚
â”‚  The average represents NOBODY's actual experience.             â”‚
â”‚  We'll learn a better way to measure in Part 5 (percentiles).   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1.3 The Doctor Analogy

**This analogy carries through the rest of the lecture.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 THE DOCTOR ANALOGY                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  BAD DOCTOR (Guess-Based Optimization)                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”‚
â”‚                                                                 â”‚
â”‚  Patient: "I feel tired."                                       â”‚
â”‚  Doctor:  "Here, take these antibiotics."                       â”‚
â”‚  Patient: "But you didn't run any testsâ€”"                       â”‚
â”‚  Doctor:  "Antibiotics fix most things. Trust me."              â”‚
â”‚                                                                 â”‚
â”‚  Outcome: Patient still tired. Now also has side effects.       â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  GOOD DOCTOR (Measurement-Based Optimization)                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                   â”‚
â”‚                                                                 â”‚
â”‚  Patient: "I feel tired."                                       â”‚
â”‚  Doctor:  "Let's run some tests first."                         â”‚
â”‚           â”œâ”€ Blood work      (â†’ timing middleware)              â”‚
â”‚           â”œâ”€ Heart monitor   (â†’ database profiling)             â”‚
â”‚           â””â”€ Stress test     (â†’ load testing)                   â”‚
â”‚  Doctor:  "Your iron is low. Here's the targeted treatment."    â”‚
â”‚                                                                 â”‚
â”‚  Outcome: Root cause found. Targeted fix. Verified recovery.    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Map every tool in this lecture to a diagnostic:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  Medicine                 â”‚  Performance Engineering            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”‚
â”‚  "I feel sick"            â”‚  "The app is slow"                  â”‚
â”‚  Taking temperature       â”‚  Timing middleware (Part 2)         â”‚
â”‚  Blood work               â”‚  Database query profiling (Part 3)  â”‚
â”‚  Stress test (treadmill)  â”‚  Load testing with Locust (Part 5)  â”‚
â”‚  Diagnosis                â”‚  Identifying the bottleneck         â”‚
â”‚  Targeted prescription    â”‚  Specific optimization (Part 4)     â”‚
â”‚  Follow-up visit          â”‚  Measure AGAIN after the fix        â”‚
â”‚                                                                 â”‚
â”‚  THE GOLDEN RULE:                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                                                         â”‚    â”‚
â”‚  â”‚  Never prescribe without a diagnosis.                   â”‚    â”‚
â”‚  â”‚  Never optimize without a measurement.                  â”‚    â”‚
â”‚  â”‚                                                         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The optimization cycle (our "treatment plan"):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               THE OPTIMIZATION CYCLE                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                          â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â–¶â”‚ MEASURE  â”‚â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚    â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚                                   â”‚
â”‚    â”‚                        â–¼                                   â”‚
â”‚    â”‚                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚    â”‚                 â”‚ IDENTIFY   â”‚                              â”‚
â”‚    â”‚                 â”‚ bottleneck â”‚                              â”‚
â”‚    â”‚                 â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚    â”‚                       â”‚                                    â”‚
â”‚    â”‚                       â–¼                                    â”‚
â”‚    â”‚                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚    â”‚                 â”‚   FIX    â”‚                                â”‚
â”‚    â”‚                 â”‚ (target) â”‚                                â”‚
â”‚    â”‚                 â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                â”‚
â”‚    â”‚                       â”‚                                    â”‚
â”‚    â”‚                       â–¼                                    â”‚
â”‚    â”‚                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ MEASURE  â”‚                               â”‚
â”‚                      â”‚  AGAIN   â”‚                               â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                                                                 â”‚
â”‚  "Did it actually help? By how much? Is there a new             â”‚
â”‚   bottleneck now? If yes, go around again."                     â”‚
â”‚                                                                 â”‚
â”‚  EVERY optimization in your Week 12 project MUST have           â”‚
â”‚  before/after numbers. No numbers, no credit.                   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1.4 Anatomy of a Request (Where Time Hides)

**Before we can measure, we need to know WHERE to look.**

When a request hits your FastAPI server, it passes through many layers. Each layer adds latency. Understanding the anatomy tells you where to point your thermometer.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            ANATOMY OF A REQUEST (Time Budget)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Client sends HTTP request                                      â”‚
â”‚       â”‚                                                         â”‚
â”‚       â–¼                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚  â”‚   MIDDLEWARE     â”‚  1-5ms typically                           â”‚
â”‚  â”‚   (CORS, auth,  â”‚  Can spike if middleware does I/O          â”‚
â”‚  â”‚    timing, etc.) â”‚                                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚           â”‚                                                     â”‚
â”‚           â–¼                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚  â”‚  DEPENDENCIES   â”‚  Varies wildly                             â”‚
â”‚  â”‚  (get_db,       â”‚  DB session: <1ms                          â”‚
â”‚  â”‚   get_current_  â”‚  Auth token verify: 1-5ms                  â”‚
â”‚  â”‚   user, etc.)   â”‚  Redis lookup: 1-2ms                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚           â”‚                                                     â”‚
â”‚           â–¼                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚  â”‚  ROUTE HANDLER  â”‚  This is where most time goes              â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                                            â”‚
â”‚  â”‚  â”‚ DB queries â”‚ â”‚  5-500ms per query (depends on query)      â”‚
â”‚  â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚                                            â”‚
â”‚  â”‚  â”‚ Cache ops  â”‚ â”‚  1-5ms (Redis round-trip)                  â”‚
â”‚  â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚                                            â”‚
â”‚  â”‚  â”‚ External   â”‚ â”‚  100-5000ms (network + remote server)      â”‚
â”‚  â”‚  â”‚ API calls  â”‚ â”‚                                            â”‚
â”‚  â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚                                            â”‚
â”‚  â”‚  â”‚ Business   â”‚ â”‚  <1ms (usually), unless CPU-intensive      â”‚
â”‚  â”‚  â”‚ logic      â”‚ â”‚                                            â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚           â”‚                                                     â”‚
â”‚           â–¼                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚  â”‚  SERIALIZATION  â”‚  1-50ms (depends on response size)         â”‚
â”‚  â”‚  (Pydantic â†’    â”‚  Large nested objects = slow               â”‚
â”‚  â”‚   JSON)         â”‚                                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚           â”‚                                                     â”‚
â”‚           â–¼                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚  â”‚  TRANSFER       â”‚  Depends on payload size + network         â”‚
â”‚  â”‚  (network to    â”‚  1KB = instant, 5MB = noticeable           â”‚
â”‚  â”‚   client)       â”‚  Compression helps here (Part 4)           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The performance budget concept:**

> "Think of each request as a budget. Your total budget is the response time your users will tolerate â€” let's say 200ms. Every layer of the request spends some of that budget. Your job is to figure out where the money goes, then cut spending on the most expensive line items."

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              EXAMPLE PERFORMANCE BUDGET                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  BUDGET: 200ms total                                            â”‚
â”‚                                                                 â”‚
â”‚  â”œâ”€ Middleware:        5ms   â–ˆâ–ˆ                                  â”‚
â”‚  â”œâ”€ Dependencies:      8ms   â–ˆâ–ˆâ–ˆ                                â”‚
â”‚  â”œâ”€ DB queries:       82ms   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      â”‚
â”‚  â”œâ”€ Redis cache:       3ms   â–ˆ                                  â”‚
â”‚  â”œâ”€ Business logic:    2ms   â–ˆ                                  â”‚
â”‚  â”œâ”€ Serialization:    15ms   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                             â”‚
â”‚  â””â”€ Transfer:         10ms   â–ˆâ–ˆâ–ˆâ–ˆ                               â”‚
â”‚                      â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚                      125ms   âœ… Under budget (75ms headroom)    â”‚
â”‚                                                                 â”‚
â”‚  If DB queries grow to 400ms, you're at 525ms.                  â”‚
â”‚  The DB line item is where you need to cut.                     â”‚
â”‚  Don't waste time optimizing serialization (15ms â†’ 10ms         â”‚
â”‚  saves you almost nothing).                                     â”‚
â”‚                                                                 â”‚
â”‚  ALWAYS OPTIMIZE THE BIGGEST LINE ITEM FIRST.                   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> "Now we know what to measure and where to look. Let's build the tools."

---

# PART 2: REQUEST TIMING MIDDLEWARE

## 2.1 Middleware vs Dependencies (Brief)

**Quick distinction â€” you know both concepts, but they serve different purposes here:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          MIDDLEWARE VS DEPENDENCIES FOR PERFORMANCE              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  MIDDLEWARE (@app.middleware)                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                    â”‚
â”‚  Wraps EVERY request, before AND after the route handler.       â”‚
â”‚  Perfect for cross-cutting concerns: timing, logging, headers.  â”‚
â”‚                                                                 â”‚
â”‚  Request â”€â”€â–¶ [Middleware BEFORE] â”€â”€â–¶ Route â”€â”€â–¶ [Middleware AFTER]â”‚
â”‚                    â”‚                              â”‚              â”‚
â”‚                    â””â”€ Start timer                  â””â”€ Stop timer â”‚
â”‚                                                                 â”‚
â”‚  You've already used middleware: CORSMiddleware (Week 9).       â”‚
â”‚  Now you'll BUILD one.                                          â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  DEPENDENCY (Depends())                                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                         â”‚
â”‚  Runs per-endpoint. Can be selective. Has access to params.     â”‚
â”‚  Better for endpoint-specific profiling or conditional logic.   â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  FOR TIMING: Use middleware. You want EVERY request timed,      â”‚
â”‚  not just specific endpoints.                                   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2.2 Building a Timing Middleware

**The `@app.middleware("http")` pattern:**

A middleware function in FastAPI receives two things: the incoming `request` object, and a `call_next` function. You call `call_next(request)` to pass the request to the next layer (eventually reaching your route handler), and it returns the `response`. Everything *before* `call_next` runs on the way in. Everything *after* runs on the way out.

```python
# middleware/timing.py

import time
from fastapi import Request, Response
from starlette.middleware.base import BaseHTTPMiddleware

# Approach 1: Using the @app.middleware decorator (simplest)
# You register this on your app object directly.

async def add_timing_middleware(request: Request, call_next) -> Response:
    """Measure and log the duration of every request."""
    
    start_time = time.perf_counter()
    # â–² time.perf_counter() â€” NOT time.time()
    # perf_counter is monotonic and high-resolution.
    # time.time() can jump forward/backward (NTP adjustments).
    # For measuring durations, always use perf_counter.

    response: Response = await call_next(request)
    # â–² This is where your route handler runs.
    # Everything between start and here IS the request duration.

    duration_ms = (time.perf_counter() - start_time) * 1000

    # Attach timing info to response header (visible in DevTools)
    response.headers["X-Process-Time-Ms"] = f"{duration_ms:.2f}"

    return response
```

**Register it on your app:**

```python
# main.py

from fastapi import FastAPI
from middleware.timing import add_timing_middleware

app = FastAPI()

# Register the middleware
app.middleware("http")(add_timing_middleware)

# Or equivalently, using the decorator directly:
#
# @app.middleware("http")
# async def timing_middleware(request: Request, call_next):
#     ...  (same body as above)
```

**What this gives you:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                WHAT TIMING MIDDLEWARE CAPTURES                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚                    start_time                                   â”‚
â”‚                        â”‚                                        â”‚
â”‚  Request in â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚                                        â”‚
â”‚                        â–¼                                        â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚              â”‚  await call_next  â”‚  â† entire handler + deps     â”‚
â”‚              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                               â”‚
â”‚              â”‚  â”‚ Depends()   â”‚  â”‚                               â”‚
â”‚              â”‚  â”‚ Route logic â”‚  â”‚                               â”‚
â”‚              â”‚  â”‚ DB queries  â”‚  â”‚                               â”‚
â”‚              â”‚  â”‚ API calls   â”‚  â”‚                               â”‚
â”‚              â”‚  â”‚ Serialize   â”‚  â”‚                               â”‚
â”‚              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                               â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                        â”‚                                        â”‚
â”‚                        â–¼                                        â”‚
â”‚                    end_time                                     â”‚
â”‚                                                                 â”‚
â”‚  duration = end_time - start_time                               â”‚
â”‚                                                                 â”‚
â”‚  This captures EVERYTHING from the moment the request           â”‚
â”‚  enters your application to the moment the response is ready.   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why `time.perf_counter()` and not `time.time()`?**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  time.time()                                                    â”‚
â”‚  â”œâ”€ Wall-clock time (seconds since epoch)                       â”‚
â”‚  â”œâ”€ CAN GO BACKWARDS (NTP sync, leap seconds, DST)             â”‚
â”‚  â”œâ”€ Resolution: ~1ms on most systems                            â”‚
â”‚  â””â”€ Use for: timestamps ("when did this happen?")               â”‚
â”‚                                                                 â”‚
â”‚  time.perf_counter()                                            â”‚
â”‚  â”œâ”€ Monotonic high-resolution counter                           â”‚
â”‚  â”œâ”€ NEVER GOES BACKWARDS                                        â”‚
â”‚  â”œâ”€ Resolution: nanoseconds on most systems                     â”‚
â”‚  â””â”€ Use for: measuring DURATIONS ("how long did this take?")    â”‚
â”‚                                                                 â”‚
â”‚  For performance measurement, ALWAYS use perf_counter().        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2.3 Structured Performance Logging

**Printing to console isn't enough. You need structured, searchable logs.**

You were introduced to structlog in Week 3. Now we use it for performance data. Structured logs produce JSON that can be filtered, searched, and aggregated by log management tools in production.

```python
# middleware/timing.py (enhanced with structured logging)

import time
import structlog
from fastapi import Request, Response

logger = structlog.get_logger()


async def add_timing_middleware(request: Request, call_next) -> Response:
    start_time = time.perf_counter()

    response: Response = await call_next(request)

    duration_ms = (time.perf_counter() - start_time) * 1000

    # Structured log â€” every field is searchable/filterable
    await logger.ainfo(
        "request_completed",
        method=request.method,
        path=request.url.path,
        status_code=response.status_code,
        duration_ms=round(duration_ms, 2),
        # Tag slow requests so they're easy to find
        slow=duration_ms > 500,
    )

    # Warn on truly slow requests
    if duration_ms > 1000:
        await logger.awarn(
            "slow_request",
            method=request.method,
            path=request.url.path,
            duration_ms=round(duration_ms, 2),
        )

    response.headers["X-Process-Time-Ms"] = f"{duration_ms:.2f}"
    return response
```

**What this produces in your logs:**

```json
{
  "event": "request_completed",
  "method": "GET",
  "path": "/organizations/42/dashboard",
  "status_code": 200,
  "duration_ms": 1101.34,
  "slow": true,
  "timestamp": "2026-02-14T10:23:45.123Z"
}
```

```json
{
  "event": "slow_request",
  "method": "GET",
  "path": "/organizations/42/dashboard",
  "duration_ms": 1101.34,
  "timestamp": "2026-02-14T10:23:45.123Z",
  "level": "warning"
}
```

**Why structured JSON logs matter:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             UNSTRUCTURED VS STRUCTURED LOGS                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  UNSTRUCTURED (print / basic logging):                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”‚
â”‚  INFO: GET /dashboard completed in 1101ms                       â”‚
â”‚                                                                 â”‚
â”‚  âŒ How do you find all requests slower than 500ms?             â”‚
â”‚  âŒ How do you calculate average time for /dashboard?           â”‚
â”‚  âŒ How do you alert on 5xx responses?                          â”‚
â”‚  Answer: painful regex parsing.                                 â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  STRUCTURED (structlog â†’ JSON):                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                 â”‚
â”‚  {"event":"request_completed","path":"/dashboard",              â”‚
â”‚   "duration_ms":1101.34,"status_code":200}                      â”‚
â”‚                                                                 â”‚
â”‚  âœ… Find slow requests: filter where duration_ms > 500          â”‚
â”‚  âœ… Average time: aggregate duration_ms where path="/dashboard" â”‚
â”‚  âœ… Alert on 5xx: filter where status_code >= 500               â”‚
â”‚  Answer: simple queries.                                        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Filtering slow requests (the doctor reading blood work results):**

```python
# In production, you'd use a log aggregation tool (Datadog, ELK, etc.)
# For development, you can filter your JSON logs with jq:

# Find all requests slower than 500ms:
#   cat logs.json | jq 'select(.duration_ms > 500)'

# Find the 10 slowest endpoints:
#   cat logs.json | jq -s 'sort_by(-.duration_ms) | .[0:10]'

# Average response time per endpoint:
#   cat logs.json | jq -s 'group_by(.path) | map({
#     path: .[0].path,
#     avg_ms: (map(.duration_ms) | add / length)
#   })'
```

---

## 2.4 Server-Timing Header

**A standard HTTP mechanism for reporting backend timing to the browser.**

The `Server-Timing` header is part of the W3C specification. Browsers (Chrome DevTools â†’ Network tab â†’ Timing section) can read it and display a breakdown of where time was spent on the server. This means your frontend colleagues (or you, debugging) can see the backend's timing breakdown without reading logs.

```python
# middleware/timing.py (with Server-Timing header)

import time
from contextvars import ContextVar
from fastapi import Request, Response

# Context variable to collect timing data from anywhere in the request
# (We'll use this in Part 3 for database timing too)
request_timings: ContextVar[dict[str, float]] = ContextVar(
    "request_timings", default={}
)


async def add_timing_middleware(request: Request, call_next) -> Response:
    # Reset timings for this request
    timings: dict[str, float] = {}
    request_timings.set(timings)

    start_time = time.perf_counter()

    response: Response = await call_next(request)

    total_ms = (time.perf_counter() - start_time) * 1000
    timings["total"] = total_ms

    # Build Server-Timing header
    # Format: metric;desc="Description";dur=123.45
    timing_parts = []
    for name, duration in timings.items():
        timing_parts.append(f'{name};dur={duration:.2f}')

    response.headers["Server-Timing"] = ", ".join(timing_parts)
    response.headers["X-Process-Time-Ms"] = f"{total_ms:.2f}"
    return response
```

**Adding timing from inside your route handler:**

```python
# Now from ANYWHERE in the request lifecycle, you can record timings:

import time
from middleware.timing import request_timings

async def get_org_dashboard(
    org_id: int,
    db: AsyncSession = Depends(get_db),
):
    timings = request_timings.get()

    # Time the database work
    db_start = time.perf_counter()
    org = await db.get(Organization, org_id)
    projects = await fetch_projects(db, org_id)
    timings["db"] = (time.perf_counter() - db_start) * 1000

    # Time the external API calls
    api_start = time.perf_counter()
    analytics = await fetch_analytics(org_id)
    timings["external_api"] = (time.perf_counter() - api_start) * 1000

    # Time serialization
    serial_start = time.perf_counter()
    result = build_dashboard_response(org, projects, analytics)
    timings["serialization"] = (time.perf_counter() - serial_start) * 1000

    return result
```

**What the browser sees:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        SERVER-TIMING IN BROWSER DEVTOOLS                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Response Headers:                                              â”‚
â”‚  Server-Timing: db;dur=461.23, external_api;dur=600.45,         â”‚
â”‚                 serialization;dur=12.30, total;dur=1101.34      â”‚
â”‚                                                                 â”‚
â”‚  Chrome DevTools â†’ Network â†’ select request â†’ Timing:           â”‚
â”‚                                                                 â”‚
â”‚  Server Timing                                                  â”‚
â”‚  â”œâ”€ db                 461.23ms  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          â”‚
â”‚  â”œâ”€ external_api       600.45ms  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    â”‚
â”‚  â”œâ”€ serialization       12.30ms  â–ˆ                              â”‚
â”‚  â””â”€ total             1101.34ms                                 â”‚
â”‚                                                                 â”‚
â”‚  Now the BROWSER tells you where the time went.                 â”‚
â”‚  No log searching needed for quick debugging.                   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key detail: `ContextVar` for request-scoped state**

> "Notice we used `ContextVar` (from Python's `contextvars` module), not a global variable. Why? In async code, multiple requests are in-flight concurrently on the same thread. A global dictionary would be shared by ALL concurrent requests â€” total chaos. `ContextVar` gives each async task chain its own isolated copy. Think of it as a variable that 'follows' the request through all the `await` calls without leaking between concurrent requests."

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   WHY ContextVar?                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  âŒ GLOBAL DICT:                                                â”‚
â”‚                                                                 â”‚
â”‚  timings = {}   â† shared by ALL concurrent requests!            â”‚
â”‚                                                                 â”‚
â”‚  Request A writes: timings["db"] = 50ms                         â”‚
â”‚  Request B writes: timings["db"] = 300ms   â† overwrites A!     â”‚
â”‚  Request A reads:  timings["db"] â†’ 300ms   â† WRONG             â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  âœ… ContextVar:                                                 â”‚
â”‚                                                                 â”‚
â”‚  request_timings: ContextVar[dict] = ContextVar(...)            â”‚
â”‚                                                                 â”‚
â”‚  Request A sees: {"db": 50ms}      â† its own copy              â”‚
â”‚  Request B sees: {"db": 300ms}     â† its own copy              â”‚
â”‚  No interference.                                               â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# PART 3: DATABASE QUERY PROFILING

> "The timing middleware tells you which ENDPOINTS are slow. But it doesn't tell you WHY. For database-heavy applications â€” which is nearly every backend â€” the next diagnostic is query profiling. This is the blood work."

## 3.1 SQLAlchemy Query Logging

**The simplest diagnostic: see every SQL query that runs.**

You've used `echo=True` during development (Week 6). That prints every query to the console. But in production-like profiling, we need something more targeted. SQLAlchemy provides an **event system** that lets us hook into query execution.

```python
# db/profiling.py

import time
import logging
from sqlalchemy import event
from sqlalchemy.ext.asyncio import AsyncEngine

logger = logging.getLogger("sqlalchemy.profiling")


def setup_query_logging(engine: AsyncEngine) -> None:
    """Attach profiling listeners to a SQLAlchemy engine."""

    sync_engine = engine.sync_engine  
    # â–² Event listeners attach to the sync engine underneath
    # the async wrapper. This is a SQLAlchemy implementation detail.

    @event.listens_for(sync_engine, "before_cursor_execute")
    def before_cursor_execute(
        conn, cursor, statement, parameters, context, executemany
    ):
        # Store the start time on the connection object
        conn.info["query_start_time"] = time.perf_counter()

    @event.listens_for(sync_engine, "after_cursor_execute")
    def after_cursor_execute(
        conn, cursor, statement, parameters, context, executemany
    ):
        duration_ms = (
            time.perf_counter() - conn.info["query_start_time"]
        ) * 1000

        # Log every query with its duration
        logger.debug(
            "Query executed: duration=%.2fms | %s",
            duration_ms,
            statement[:200],  # Truncate long queries
        )

        # Warn on slow queries
        if duration_ms > 100:
            logger.warning(
                "SLOW QUERY: duration=%.2fms | %s",
                duration_ms,
                statement[:500],
            )
```

**Register it when creating your engine:**

```python
# db/session.py

from sqlalchemy.ext.asyncio import create_async_engine
from db.profiling import setup_query_logging

engine = create_async_engine(settings.DATABASE_URL)
setup_query_logging(engine)  # â† Attach the profiling listeners
```

**What you see in your logs:**

```
DEBUG: Query executed: duration=4.23ms | SELECT org.id, org.name ... WHERE org.id = $1
DEBUG: Query executed: duration=5.67ms | SELECT project.id, ... WHERE project.org_id = $1
DEBUG: Query executed: duration=4.12ms | SELECT task.id, ... WHERE task.project_id = $1
DEBUG: Query executed: duration=3.89ms | SELECT user.id, ... WHERE user.id = $1
DEBUG: Query executed: duration=4.01ms | SELECT user.id, ... WHERE user.id = $1
DEBUG: Query executed: duration=3.95ms | SELECT user.id, ... WHERE user.id = $1
... (89 more lines)

WARNING: 92 queries in this request!  â† Now the N+1 is VISIBLE
```

---

## 3.2 Counting Queries Per Request

**Knowing individual query times isn't enough. You need to know how many queries each request triggers.**

This is the single most important diagnostic for database performance. Combine the timing middleware from Part 2 with a query counter using `ContextVar`:

```python
# db/profiling.py (enhanced with per-request counting)

import time
from contextvars import ContextVar
from dataclasses import dataclass, field
from sqlalchemy import event
from sqlalchemy.ext.asyncio import AsyncEngine


@dataclass
class QueryStats:
    """Track query statistics for a single request."""
    count: int = 0
    total_duration_ms: float = 0.0
    queries: list[dict] = field(default_factory=list)

    def record(self, statement: str, duration_ms: float) -> None:
        self.count += 1
        self.total_duration_ms += duration_ms
        self.queries.append({
            "sql": statement[:200],
            "duration_ms": round(duration_ms, 2),
        })


# ContextVar: each request gets its own QueryStats
request_query_stats: ContextVar[QueryStats | None] = ContextVar(
    "request_query_stats", default=None
)


def setup_query_profiling(engine: AsyncEngine) -> None:
    sync_engine = engine.sync_engine

    @event.listens_for(sync_engine, "before_cursor_execute")
    def before_cursor_execute(
        conn, cursor, statement, parameters, context, executemany
    ):
        conn.info["query_start_time"] = time.perf_counter()

    @event.listens_for(sync_engine, "after_cursor_execute")
    def after_cursor_execute(
        conn, cursor, statement, parameters, context, executemany
    ):
        duration_ms = (
            time.perf_counter() - conn.info["query_start_time"]
        ) * 1000

        # Record to the current request's stats (if tracked)
        stats = request_query_stats.get()
        if stats is not None:
            stats.record(statement, duration_ms)
```

**Integrate with your timing middleware:**

```python
# middleware/timing.py (enhanced with query stats)

import structlog
from db.profiling import QueryStats, request_query_stats
from middleware.timing import request_timings

logger = structlog.get_logger()


async def add_performance_middleware(request: Request, call_next) -> Response:
    # Initialize per-request tracking
    timings: dict[str, float] = {}
    request_timings.set(timings)

    stats = QueryStats()
    request_query_stats.set(stats)  # â† Start counting queries

    start_time = time.perf_counter()

    response: Response = await call_next(request)

    total_ms = (time.perf_counter() - start_time) * 1000

    # Log with query count information
    await logger.ainfo(
        "request_completed",
        method=request.method,
        path=request.url.path,
        status_code=response.status_code,
        duration_ms=round(total_ms, 2),
        query_count=stats.count,                          # â† NEW
        query_total_ms=round(stats.total_duration_ms, 2), # â† NEW
        slow=total_ms > 500,
    )

    # Warn on high query count â€” the N+1 alarm
    if stats.count > 10:
        await logger.awarn(
            "high_query_count",
            path=request.url.path,
            query_count=stats.count,
            query_total_ms=round(stats.total_duration_ms, 2),
            queries=stats.queries,  # Full list for debugging
        )

    # Add to Server-Timing header
    response.headers["Server-Timing"] = (
        f'db;dur={stats.total_duration_ms:.2f},'
        f'total;dur={total_ms:.2f}'
    )
    response.headers["X-Query-Count"] = str(stats.count)
    response.headers["X-Process-Time-Ms"] = f"{total_ms:.2f}"

    return response
```

**What you get in your logs now:**

```json
{
  "event": "request_completed",
  "path": "/organizations/42/dashboard",
  "duration_ms": 1101.34,
  "query_count": 92,
  "query_total_ms": 461.23,
  "slow": true
}
```

```json
{
  "event": "high_query_count",
  "path": "/organizations/42/dashboard",
  "query_count": 92,
  "query_total_ms": 461.23,
  "queries": [
    {"sql": "SELECT org.id, ...", "duration_ms": 4.23},
    {"sql": "SELECT project.id, ...", "duration_ms": 5.67},
    "... (90 more)"
  ]
}
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  NOW YOU CAN SEE:                                               â”‚
â”‚                                                                 â”‚
â”‚  1. Which endpoints are slow        (duration_ms)               â”‚
â”‚  2. Whether the DB is the cause     (query_total_ms / total)    â”‚
â”‚  3. Whether N+1 is the pattern      (query_count > 10)          â”‚
â”‚  4. Exactly which queries ran       (queries list)              â”‚
â”‚                                                                 â”‚
â”‚  This is your blood work report. Now you can diagnose.          â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3.3 Catching N+1 in Production

You learned about N+1 in Week 6 and how to fix it with `joinedload` and `selectinload`. The problem isn't that you don't know the fix â€” it's that **N+1 sneaks back in** every time someone writes a new query or modifies an endpoint. You need a way to CATCH it automatically.

**The pattern: recognize N+1 from query logs.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             HOW TO SPOT N+1 IN QUERY LOGS                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  N+1 has a FINGERPRINT:                                         â”‚
â”‚  The same query structure repeated many times with              â”‚
â”‚  different parameter values.                                    â”‚
â”‚                                                                 â”‚
â”‚  NORMAL (2 queries):                                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                             â”‚
â”‚  SELECT project.* FROM project WHERE project.org_id = 42        â”‚
â”‚  SELECT task.* FROM task WHERE task.project_id IN (1,2,3,4,5)   â”‚
â”‚                                                                 â”‚
â”‚  N+1 (6 queries â€” 1 + 5):                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚
â”‚  SELECT project.* FROM project WHERE project.org_id = 42        â”‚
â”‚  SELECT task.* FROM task WHERE task.project_id = 1   â† same     â”‚
â”‚  SELECT task.* FROM task WHERE task.project_id = 2   â† query    â”‚
â”‚  SELECT task.* FROM task WHERE task.project_id = 3   â† repeats  â”‚
â”‚  SELECT task.* FROM task WHERE task.project_id = 4   â† with     â”‚
â”‚  SELECT task.* FROM task WHERE task.project_id = 5   â† diff id  â”‚
â”‚                                                                 â”‚
â”‚  THE FIX (Week 6 refresher â€” use eager loading):                â”‚
â”‚                                                                 â”‚
â”‚  # Before (N+1):                                                â”‚
â”‚  stmt = select(Project).where(Project.org_id == org_id)         â”‚
â”‚                                                                 â”‚
â”‚  # After (2 queries with selectinload):                         â”‚
â”‚  stmt = (                                                       â”‚
â”‚      select(Project)                                            â”‚
â”‚      .where(Project.org_id == org_id)                           â”‚
â”‚      .options(selectinload(Project.tasks))                      â”‚
â”‚  )                                                              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Demonstration â€” before and after with real numbers:**

```python
# BEFORE: N+1 (from Part 1's dashboard endpoint)
# 10 projects, 8 tasks each = 92 queries, ~461ms

@router.get("/organizations/{org_id}/dashboard")
async def get_org_dashboard(org_id: int, db: AsyncSession = Depends(get_db)):
    stmt = select(Project).where(Project.org_id == org_id)
    result = await db.execute(stmt)
    projects = result.scalars().all()

    for project in projects:  # â† N+1 STARTS HERE
        tasks_stmt = select(Task).where(Task.project_id == project.id)
        tasks = (await db.execute(tasks_stmt)).scalars().all()

        for task in tasks:  # â† NESTED N+1
            assignee = await db.get(User, task.assignee_id)
            ...
```

```python
# AFTER: Eager loading (2 queries, ~15ms)

@router.get("/organizations/{org_id}/dashboard")
async def get_org_dashboard(org_id: int, db: AsyncSession = Depends(get_db)):
    stmt = (
        select(Project)
        .where(Project.org_id == org_id)
        .options(
            selectinload(Project.tasks)       # Load tasks in 1 batch query
            .selectinload(Task.assignee)       # Load assignees in 1 batch query
        )
    )
    result = await db.execute(stmt)
    projects = result.scalars().unique().all()
    # â–² .unique() is needed when using joined/selectin loading
    #   to deduplicate parent rows. You saw this in Week 6.

    # Now project.tasks and task.assignee are already loaded.
    # No additional queries needed.
    for project in projects:
        for task in project.tasks:
            assignee_name = task.assignee.name  # â† No query! Already loaded.
            ...
```

**The results (doctor's follow-up):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               BEFORE vs AFTER (N+1 fix)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  10 projects, 8 tasks each:                                     â”‚
â”‚                                                                 â”‚
â”‚                    BEFORE              AFTER                    â”‚
â”‚  Queries:          92                  3                        â”‚
â”‚  DB time:          461ms               15ms                     â”‚
â”‚  Total endpoint:   1,101ms             655ms                    â”‚
â”‚  Improvement:                          30Ã— fewer queries        â”‚
â”‚                                        ~40% faster overall      â”‚
â”‚                                                                 â”‚
â”‚  50 projects, 20 tasks each:                                    â”‚
â”‚                                                                 â”‚
â”‚                    BEFORE              AFTER                    â”‚
â”‚  Queries:          1,052               3                        â”‚
â”‚  DB time:          5,260ms             42ms                     â”‚
â”‚  Total endpoint:   5,900ms             682ms                    â”‚
â”‚  Improvement:                          350Ã— fewer queries       â”‚
â”‚                                        ~88% faster overall      â”‚
â”‚                                                                 â”‚
â”‚  The fix was ONE LINE (adding .options(selectinload(...))).     â”‚
â”‚  But you could only justify and verify it because you           â”‚
â”‚  MEASURED the query count before and after.                     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3.4 Query Count Assertions in Tests

**The permanent safeguard: make N+1 regressions fail your test suite.**

This is the most powerful technique in this entire lecture for long-term health. You write a test that asserts: "this endpoint must not execute more than N queries." If someone adds a loop that causes N+1, the test fails in CI before it reaches production.

```python
# tests/conftest.py

import pytest
from db.profiling import QueryStats, request_query_stats


@pytest.fixture
def query_counter():
    """Fixture that tracks query count during a test."""
    stats = QueryStats()
    request_query_stats.set(stats)
    yield stats
    # After test, stats.count contains the total queries executed
```

**Using it in your tests:**

```python
# tests/test_dashboard.py

import pytest
from httpx import AsyncClient


@pytest.mark.asyncio
async def test_dashboard_query_count(
    async_client: AsyncClient,
    query_counter: QueryStats,
    seed_org_with_projects,   # Fixture: creates org with 10 projects, 8 tasks each
):
    """Dashboard endpoint must not trigger N+1 queries."""
    response = await async_client.get("/organizations/1/dashboard")
    assert response.status_code == 200

    # THE ASSERTION THAT CATCHES N+1:
    assert query_counter.count <= 5, (
        f"Dashboard executed {query_counter.count} queries! "
        f"Expected â‰¤5. Likely N+1 regression.\n"
        f"Queries:\n"
        + "\n".join(
            f"  {q['sql'][:100]}" for q in query_counter.queries
        )
    )


@pytest.mark.asyncio
async def test_dashboard_with_many_projects(
    async_client: AsyncClient,
    query_counter: QueryStats,
    seed_org_with_many_projects,  # 50 projects, 20 tasks each
):
    """Query count must NOT scale with data volume."""
    response = await async_client.get("/organizations/1/dashboard")
    assert response.status_code == 200

    # Same budget as the small test â€” that's the point!
    # If this fails, queries scale with data volume = N+1.
    assert query_counter.count <= 5, (
        f"Query count scales with data! Got {query_counter.count} queries."
    )
```

**Why this is so powerful:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         QUERY COUNT ASSERTIONS IN CI                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Without query count tests:                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚  1. Developer adds new field to dashboard                       â”‚
â”‚  2. Adds a loop to fetch related data                           â”‚
â”‚  3. Tests pass (correctness is fine)                            â”‚
â”‚  4. Code review doesn't catch it (the code looks fine)          â”‚
â”‚  5. Deployed to production                                      â”‚
â”‚  6. 2 weeks later: "Why is the dashboard slow?"                 â”‚
â”‚  7. Debug, find N+1, fix, deploy, apologize                     â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  With query count tests:                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                        â”‚
â”‚  1. Developer adds new field to dashboard                       â”‚
â”‚  2. Adds a loop to fetch related data                           â”‚
â”‚  3. CI FAILS: "Dashboard executed 47 queries! Expected â‰¤5."     â”‚
â”‚  4. Developer sees the problem immediately                      â”‚
â”‚  5. Adds selectinload, test passes                              â”‚
â”‚  6. Deployed with zero performance regression                   â”‚
â”‚                                                                 â”‚
â”‚  The test caught the bug before a human had to.                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# PART 4: RESPONSE OPTIMIZATION TECHNIQUES

> "Parts 2 and 3 were the diagnosis. Now we prescribe. But remember: **targeted treatments only.** We know exactly where the time goes. We fix exactly those things."

## 4.1 Response Compression (GzipMiddleware)

**Reduce what you send over the wire.**

JSON responses from APIs can be large, especially for list endpoints that return many records. Gzip compression typically reduces JSON payloads by 70â€“90%. The CPU cost of compression is almost always worth the reduced transfer time, especially for clients on slower networks.

```python
# main.py

from starlette.middleware.gzip import GzipMiddleware

app = FastAPI()

# Add gzip compression â€” responses larger than 500 bytes get compressed
app.add_middleware(GzipMiddleware, minimum_size=500)
# â–² minimum_size: don't bother compressing tiny responses.
#   The compression overhead isn't worth it for small payloads.
```

That's it. Two lines. Starlette handles it.

**How it works:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  GZIP COMPRESSION                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  WITHOUT COMPRESSION:                                           â”‚
â”‚                                                                 â”‚
â”‚  Server â”€â”€â”€â”€ 250KB JSON â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Client        â”‚
â”‚              â–²                                                  â”‚
â”‚              â”‚ Full payload over the wire                        â”‚
â”‚              â”‚ Slow on mobile/weak connections                   â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  WITH GZIP:                                                     â”‚
â”‚                                                                 â”‚
â”‚  Server â”€â”¬â”€â”€ Compress â”€â”€â”€â”€ 35KB gzipped â”€â”€â”€â”€â–¶ Client            â”‚
â”‚          â”‚   (~2ms CPU)    â–²                   â”‚                 â”‚
â”‚          â”‚                 â”‚ 86% smaller!      â”œâ”€â”€ Decompress    â”‚
â”‚          â”‚                 â”‚                   â”‚   (browser      â”‚
â”‚          â”‚                 â”‚                   â”‚    does this     â”‚
â”‚          â”‚                 â”‚                   â”‚    automatically)â”‚
â”‚                                                                 â”‚
â”‚  TRADEOFF:                                                      â”‚
â”‚  â”œâ”€ Cost:   ~2-5ms CPU per response (compression)               â”‚
â”‚  â”œâ”€ Saving: 70-90% less data transferred                        â”‚
â”‚  â””â”€ Net:    Almost always a win for JSON payloads > 1KB         â”‚
â”‚                                                                 â”‚
â”‚  WHEN IT DOESN'T HELP:                                          â”‚
â”‚  â”œâ”€ Tiny responses (< 500 bytes) â€” overhead > savings           â”‚
â”‚  â”œâ”€ Already compressed content (images, binary files)           â”‚
â”‚  â””â”€ Internal microservice calls on fast networks                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Verifying it works â€” check response headers:**

```python
# In a test or curl:
# curl -H "Accept-Encoding: gzip" http://localhost:8000/organizations/1/dashboard -v
#
# Response headers should include:
#   Content-Encoding: gzip
#   Content-Length: 35412  (vs 250000 uncompressed)

# Or in your test suite:
@pytest.mark.asyncio
async def test_gzip_compression(async_client: AsyncClient):
    response = await async_client.get(
        "/organizations/1/dashboard",
        headers={"Accept-Encoding": "gzip"},
    )
    assert response.status_code == 200
    # httpx automatically decompresses, but we can check
    # the raw response headers were set
    assert response.headers.get("content-encoding") == "gzip"
```

---

## 4.2 Parallel Operations in Endpoints

**You learned `asyncio.gather` in Week 1. Here's where it pays off.**

Look at Section B from the opening demonstration again:

```python
# BEFORE: Sequential external calls (600ms)

async with httpx.AsyncClient(timeout=5.0) as client:
    analytics_resp = await client.get(f"https://analytics.example.com/...")
    # â–² Waits 280ms. CPU idle. Nothing else happening.
    
async with httpx.AsyncClient(timeout=5.0) as client:
    weather_resp = await client.get(f"https://api.weather.example.com/...")
    # â–² Waits 320ms AFTER analytics finishes. Total: 600ms.
    
# Also: creating a new AsyncClient per call is wasteful.
# Each one opens a new connection pool. Use a shared client.
```

```python
# AFTER: Parallel external calls + shared client (320ms)

# Shared client (injected via Depends, or module-level)
# You learned httpx.AsyncClient in Week 8.

async def get_org_dashboard(
    org_id: int,
    db: AsyncSession = Depends(get_db),
    http_client: httpx.AsyncClient = Depends(get_http_client),
):
    # ... DB queries (already optimized) ...

    # Fetch external data IN PARALLEL
    analytics_resp, weather_resp = await asyncio.gather(
        http_client.get(f"https://analytics.example.com/org/{org_id}/summary"),
        http_client.get(f"https://api.weather.example.com/current?city={org.city}"),
    )
    # â–² Both requests start at the same time.
    # Total time = max(280ms, 320ms) = 320ms, not 600ms.
```

**Visualize the difference:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  SEQUENTIAL:                                                    â”‚
â”‚                                                                 â”‚
â”‚  Time: 0ms     280ms          600ms                             â”‚
â”‚        â”‚        â”‚               â”‚                               â”‚
â”‚  Analytics:  [â•â•â•â•â•â•â•â•â•â•]                                       â”‚
â”‚  Weather:                [â•â•â•â•â•â•â•â•â•â•]                            â”‚
â”‚                                                                 â”‚
â”‚  Total: 600ms                                                   â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  PARALLEL (asyncio.gather):                                     â”‚
â”‚                                                                 â”‚
â”‚  Time: 0ms          320ms                                       â”‚
â”‚        â”‚              â”‚                                         â”‚
â”‚  Analytics:  [â•â•â•â•â•â•â•â•]                                         â”‚
â”‚  Weather:    [â•â•â•â•â•â•â•â•â•â•]                                       â”‚
â”‚                                                                 â”‚
â”‚  Total: 320ms (time of the slower call)                         â”‚
â”‚                                                                 â”‚
â”‚  Savings: 280ms (47% faster)                                    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**When can you parallelize?**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          CAN I RUN THESE IN PARALLEL?                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  âœ… YES â€” if operations are INDEPENDENT:                        â”‚
â”‚  â”œâ”€ Fetch analytics + Fetch weather (no dependency)             â”‚
â”‚  â”œâ”€ Cache lookup + DB query (if you don't need cache to skip    â”‚
â”‚  â”‚   the DB query â€” in that case they ARE dependent!)           â”‚
â”‚  â”œâ”€ Send notification + Log audit event                         â”‚
â”‚  â””â”€ Fetch from 3 different external APIs                        â”‚
â”‚                                                                 â”‚
â”‚  âŒ NO â€” if one operation DEPENDS on another's result:          â”‚
â”‚  â”œâ”€ Get user â†’ then get user's permissions (need user_id first) â”‚
â”‚  â”œâ”€ Check cache â†’ if miss, THEN query DB (conditional)          â”‚
â”‚  â””â”€ Validate input â†’ then process (process needs valid input)   â”‚
â”‚                                                                 â”‚
â”‚  THE RULE:                                                      â”‚
â”‚  "If operation B does NOT need the result of operation A,       â”‚
â”‚   they can run in parallel."                                    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Combining parallel I/O with error handling:**

```python
# Production pattern: parallel calls with individual error handling

async def get_org_dashboard(
    org_id: int,
    db: AsyncSession = Depends(get_db),
    http_client: httpx.AsyncClient = Depends(get_http_client),
):
    projects = await fetch_projects_optimized(db, org_id)

    # Parallel external calls with graceful degradation
    analytics_resp, weather_resp = await asyncio.gather(
        http_client.get(f"https://analytics.example.com/org/{org_id}"),
        http_client.get(f"https://api.weather.example.com/?city={org.city}"),
        return_exceptions=True,  # â† Don't crash if one fails
    )

    # Handle individual failures gracefully
    analytics = (
        analytics_resp.json()
        if isinstance(analytics_resp, httpx.Response)
           and analytics_resp.status_code == 200
        else None  # Degrade gracefully: dashboard still works
    )

    weather = (
        weather_resp.json()
        if isinstance(weather_resp, httpx.Response)
           and weather_resp.status_code == 200
        else None
    )

    return {
        "projects": projects,
        "analytics": analytics,   # null if analytics service was down
        "weather": weather,        # null if weather service was down
    }
```

---

## 4.3 The Optimization Toolbox

**A quick reference of every technique available to you after this course:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           THE OPTIMIZATION TOOLBOX                              â”‚
â”‚           (ordered by: try this first â†’ try this last)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. FIX N+1 QUERIES (Week 6 + this lecture)                     â”‚
â”‚     Effort: Low  â”‚  Impact: Massive (10x-100x fewer queries)    â”‚
â”‚     How: selectinload / joinedload / subqueryload               â”‚
â”‚     Always try this FIRST. It's almost always the biggest win.  â”‚
â”‚                                                                 â”‚
â”‚  2. ADD DATABASE INDEXES (Week 7)                               â”‚
â”‚     Effort: Low  â”‚  Impact: High (10x-1000x on filtered reads) â”‚
â”‚     How: EXPLAIN ANALYZE â†’ find seq scans â†’ add index           â”‚
â”‚     Second thing to check. You already know how.                â”‚
â”‚                                                                 â”‚
â”‚  3. ADD CACHING (Week 10)                                       â”‚
â”‚     Effort: Medium  â”‚  Impact: High (eliminate repeated work)   â”‚
â”‚     How: Redis cache-aside for expensive/repeated queries       â”‚
â”‚     Third: if the same data is requested often, cache it.       â”‚
â”‚                                                                 â”‚
â”‚  4. PARALLELIZE I/O (Week 1 + this lecture)                     â”‚
â”‚     Effort: Low  â”‚  Impact: Medium (depends on # of operations) â”‚
â”‚     How: asyncio.gather for independent operations              â”‚
â”‚     Quick win when you have multiple independent I/O calls.     â”‚
â”‚                                                                 â”‚
â”‚  5. COMPRESS RESPONSES (this lecture)                            â”‚
â”‚     Effort: Minimal  â”‚  Impact: Low-Medium (network-bound)      â”‚
â”‚     How: GzipMiddleware, 2 lines                                â”‚
â”‚     Easy, helps most for large JSON responses.                  â”‚
â”‚                                                                 â”‚
â”‚  6. OPTIMIZE QUERIES (Week 7)                                   â”‚
â”‚     Effort: High  â”‚  Impact: Varies                             â”‚
â”‚     How: Rewrite slow queries, denormalize, materialized views  â”‚
â”‚     Only after the above are exhausted.                         â”‚
â”‚                                                                 â”‚
â”‚  7. SCALE INFRASTRUCTURE (Week 16)                              â”‚
â”‚     Effort: High  â”‚  Impact: High (but expensive)               â”‚
â”‚     How: Read replicas, horizontal scaling, CDN                 â”‚
â”‚     Last resort. You'll learn this in system design.            â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ RULE: Exhaust the cheap optimizations before reaching   â”‚    â”‚
â”‚  â”‚ for the expensive ones. A missing index (5 minutes to   â”‚    â”‚
â”‚  â”‚ add) often beats adding a cache layer (2 days of work). â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# PART 5: LOAD TESTING WITH LOCUST

## 5.1 Why Load Test? (The Empty Restaurant Problem)

**Everything so far measures one request at a time. Production has hundreds.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            THE EMPTY RESTAURANT PROBLEM                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  You test your new restaurant with ONE customer.                â”‚
â”‚                                                                 â”‚
â”‚  Customer sits down. Waiter comes immediately.                  â”‚
â”‚  Food arrives in 10 minutes. Customer is happy. â­â­â­â­â­          â”‚
â”‚                                                                 â”‚
â”‚  "Our restaurant is fast! Ready for opening night!"             â”‚
â”‚                                                                 â”‚
â”‚  Opening night: 200 customers arrive.                           â”‚
â”‚                                                                 â”‚
â”‚  â”œâ”€ 3 waiters for 200 people (understaffed)                     â”‚
â”‚  â”œâ”€ Kitchen can only cook 5 meals at a time (bottleneck)        â”‚
â”‚  â”œâ”€ Tables too close together, movement is slow (contention)    â”‚
â”‚  â”œâ”€ Customer #150 waits 45 minutes. Leaves a 1-star review.    â”‚
â”‚  â””â”€ Customer #200 can't even get in (connection refused).       â”‚
â”‚                                                                 â”‚
â”‚  WHAT WENT WRONG:                                               â”‚
â”‚  You tested with 1 customer. Your system performed under        â”‚
â”‚  ZERO CONTENTION. Real performance only shows under LOAD.       â”‚
â”‚                                                                 â”‚
â”‚  WHAT LOAD TESTING REVEALS:                                     â”‚
â”‚  â”œâ”€ Connection pool exhaustion (all DB connections in use)      â”‚
â”‚  â”œâ”€ Lock contention (multiple requests hitting same rows)       â”‚
â”‚  â”œâ”€ Memory leaks (usage growing with each request)              â”‚
â”‚  â”œâ”€ Event loop blocking (one slow sync call freezes everyone)   â”‚
â”‚  â””â”€ Cascading failures (one slow service backs up everything)   â”‚
â”‚                                                                 â”‚
â”‚  These problems are INVISIBLE to single-request testing.        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5.2 Your First Locust Test

**Locust is a Python-based load testing tool. You write test scenarios as Python code.**

That matters: it's not a config file or a GUI tool. It's Python. You already know Python. You can use logic, loops, conditionals, and everything you know.

**Install it:**

```bash
pip install locust
```

**Write your first locustfile:**

```python
# locustfile.py â€” place in your project root

from locust import HttpUser, task, between


class DashboardUser(HttpUser):
    """Simulates a user who logs in and views dashboards."""

    # Wait 1-3 seconds between tasks (simulates think time)
    # Real users don't click every millisecond.
    wait_time = between(1, 3)

    # â”€â”€â”€ TASKS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @task(3)  # Weight: 3x more likely than weight-1 tasks
    def view_dashboard(self):
        """Most common action: view the org dashboard."""
        self.client.get(
            "/organizations/1/dashboard",
            headers=self.auth_headers,
            name="/organizations/{id}/dashboard",
            # â–² 'name' groups URLs with different IDs into
            #   one stat line. Without it, /orgs/1/dashboard
            #   and /orgs/2/dashboard would be separate entries.
        )

    @task(2)
    def list_projects(self):
        """Second most common: browse projects."""
        self.client.get(
            "/organizations/1/projects",
            headers=self.auth_headers,
            name="/organizations/{id}/projects",
        )

    @task(1)
    def create_task(self):
        """Least common: create a new task."""
        self.client.post(
            "/organizations/1/projects/1/tasks",
            json={
                "title": "Load test task",
                "description": "Created during load testing",
                "status": "todo",
            },
            headers=self.auth_headers,
            name="/organizations/{id}/projects/{id}/tasks",
        )

    # â”€â”€â”€ LIFECYCLE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def on_start(self):
        """Called when a simulated user starts. Log in once."""
        response = self.client.post(
            "/auth/login",
            json={"email": "loadtest@example.com", "password": "testpass123"},
        )
        token = response.json()["access_token"]
        self.auth_headers = {"Authorization": f"Bearer {token}"}
```

**Anatomy of a locustfile:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  LOCUST ANATOMY                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  class DashboardUser(HttpUser):                                 â”‚
â”‚  â–²                    â–²                                         â”‚
â”‚  â”‚                    â”‚                                         â”‚
â”‚  Your user type       Built-in base class with HTTP client      â”‚
â”‚                                                                 â”‚
â”‚  wait_time = between(1, 3)                                      â”‚
â”‚  â–²                                                              â”‚
â”‚  How long a "user" waits between actions.                       â”‚
â”‚  Simulates real human think time.                               â”‚
â”‚  Without this, locust hammers your API unrealistically.         â”‚
â”‚                                                                 â”‚
â”‚  @task(3)                                                       â”‚
â”‚  â–²     â–²                                                        â”‚
â”‚  â”‚     Weight: this task is picked 3x more often                â”‚
â”‚  Marks this method as a user action                             â”‚
â”‚                                                                 â”‚
â”‚  self.client.get(...)                                           â”‚
â”‚  â–²                                                              â”‚
â”‚  Built-in HTTP client (similar to httpx/requests).              â”‚
â”‚  Locust automatically tracks timing and success/failure.        â”‚
â”‚                                                                 â”‚
â”‚  on_start(self):                                                â”‚
â”‚  â–²                                                              â”‚
â”‚  Runs once when a virtual user spawns.                          â”‚
â”‚  Use it for login, setup, getting tokens.                       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Run it:**

```bash
# Start locust (assumes your FastAPI app is running on :8000)
locust -f locustfile.py --host=http://localhost:8000

# Locust starts a web UI at http://localhost:8089
# From the web UI, you configure:
#   - Number of users (e.g., 50)
#   - Spawn rate (e.g., 5 users/second)
#   - Then click "Start swarming"
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                LOCUST WEB UI                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  Number of users: [50    ]                        â”‚          â”‚
â”‚  â”‚  Spawn rate:      [5     ] users/sec              â”‚          â”‚
â”‚  â”‚  Host:            http://localhost:8000            â”‚          â”‚
â”‚  â”‚                                                   â”‚          â”‚
â”‚  â”‚  [ Start swarming ]                               â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                 â”‚
â”‚  This means:                                                    â”‚
â”‚  - 50 simulated users will be active                            â”‚
â”‚  - They spawn at 5 per second (takes 10 seconds to reach 50)   â”‚
â”‚  - Each user runs tasks in a loop with random wait_time         â”‚
â”‚  - Locust tracks every request's timing and status              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5.3 Writing Realistic Scenarios

**A bad load test uses fake patterns. A good one models real behavior.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             REALISTIC VS UNREALISTIC LOAD TESTS                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  âŒ UNREALISTIC:                                                â”‚
â”‚  â”œâ”€ All users hit the same endpoint                             â”‚
â”‚  â”œâ”€ No think time (machine-gun requests)                        â”‚
â”‚  â”œâ”€ No authentication (skips auth overhead)                     â”‚
â”‚  â”œâ”€ No write operations (read-only is easier to scale)          â”‚
â”‚  â””â”€ All same data (unrealistic cache hit rate)                  â”‚
â”‚                                                                 â”‚
â”‚  âœ… REALISTIC:                                                  â”‚
â”‚  â”œâ”€ Mix of endpoints weighted by real usage                     â”‚
â”‚  â”œâ”€ Think time between actions (between(1, 3))                  â”‚
â”‚  â”œâ”€ Authenticated requests (includes token validation cost)     â”‚
â”‚  â”œâ”€ Mix of reads and writes (80/20 is typical for SaaS)         â”‚
â”‚  â””â”€ Varied data (different org IDs, project IDs)                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**A more realistic scenario with multiple user types:**

```python
# locustfile.py â€” realistic multi-user scenario

import random
from locust import HttpUser, task, between


class RegularMember(HttpUser):
    """80% of traffic: regular team members browsing and updating tasks."""
    weight = 8  # 8 out of 10 users will be this type

    wait_time = between(2, 5)  # Casual browsing pace

    def on_start(self):
        resp = self.client.post("/auth/login", json={
            "email": f"member{random.randint(1, 50)}@example.com",
            "password": "testpass123",
        })
        self.auth_headers = {
            "Authorization": f"Bearer {resp.json()['access_token']}"
        }
        self.org_id = random.choice([1, 2, 3])  # Spread across orgs

    @task(5)
    def browse_tasks(self):
        project_id = random.randint(1, 10)
        self.client.get(
            f"/organizations/{self.org_id}/projects/{project_id}/tasks",
            headers=self.auth_headers,
            name="/orgs/{id}/projects/{id}/tasks",
        )

    @task(3)
    def view_task_detail(self):
        task_id = random.randint(1, 100)
        self.client.get(
            f"/tasks/{task_id}",
            headers=self.auth_headers,
            name="/tasks/{id}",
        )

    @task(1)
    def update_task_status(self):
        task_id = random.randint(1, 100)
        self.client.patch(
            f"/tasks/{task_id}",
            json={"status": random.choice(["todo", "in_progress", "done"])},
            headers=self.auth_headers,
            name="/tasks/{id}",
        )


class AdminUser(HttpUser):
    """20% of traffic: admins checking dashboards and managing users."""
    weight = 2  # 2 out of 10 users will be this type

    wait_time = between(3, 8)  # Admins spend more time reading

    def on_start(self):
        resp = self.client.post("/auth/login", json={
            "email": "admin@example.com",
            "password": "adminpass123",
        })
        self.auth_headers = {
            "Authorization": f"Bearer {resp.json()['access_token']}"
        }

    @task(3)
    def view_dashboard(self):
        self.client.get(
            "/organizations/1/dashboard",
            headers=self.auth_headers,
            name="/orgs/{id}/dashboard",
        )

    @task(1)
    def list_members(self):
        self.client.get(
            "/organizations/1/members",
            headers=self.auth_headers,
            name="/orgs/{id}/members",
        )
```

**How `weight` works:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  If you spawn 100 simulated users:                              â”‚
â”‚                                                                 â”‚
â”‚  RegularMember (weight=8): ~80 users browsing and updating      â”‚
â”‚  AdminUser     (weight=2): ~20 users viewing dashboards         â”‚
â”‚                                                                 â”‚
â”‚  This models a real SaaS app where most traffic is              â”‚
â”‚  regular users, with a smaller portion of admin activity.       â”‚
â”‚                                                                 â”‚
â”‚  Combined with @task weights WITHIN each user class:            â”‚
â”‚  RegularMember does browse(5):detail(3):update(1) â‰ˆ 56%:33%:11%â”‚
â”‚  AdminUser does dashboard(3):members(1) â‰ˆ 75%:25%              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5.4 Reading Results and the Optimization Cycle

**Locust gives you a statistics table and real-time charts. Here's how to read them.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           LOCUST RESULTS TABLE (example)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Name                           Reqs  Fails  Avg  Med  p95  p99â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€  â”€â”€â”€â”€â”€  â”€â”€â”€  â”€â”€â”€  â”€â”€â”€  â”€â”€â”€â”‚
â”‚  GET  /orgs/{id}/dashboard        892   12    683  520  1800 3200â”‚
â”‚  GET  /orgs/{id}/projects/{id}   1847    3    145  102   380  820â”‚
â”‚  GET  /tasks/{id}                2104    1     52   45    95  180â”‚
â”‚  PATCH /tasks/{id}                523    8    210  180   450  900â”‚
â”‚  POST /auth/login                  50    0    320  310   380  410â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€  â”€â”€â”€â”€â”€  â”€â”€â”€  â”€â”€â”€  â”€â”€â”€  â”€â”€â”€â”‚
â”‚  Total                           5416   24    198  105   680 1400â”‚
â”‚                                                                 â”‚
â”‚  All times in milliseconds.                                     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**What do these columns mean?**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    UNDERSTANDING PERCENTILES                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Imagine sorting ALL response times from fastest to slowest.    â”‚
â”‚                                                                 â”‚
â”‚  892 requests to /dashboard, sorted:                            â”‚
â”‚  [23ms, 25ms, 30ms, ... ... ... 1800ms, 2200ms, 3200ms]        â”‚
â”‚   â–²                       â–²             â–²               â–²       â”‚
â”‚   fastest               middle          â”‚               slowest â”‚
â”‚                           â”‚             â”‚                       â”‚
â”‚                                                                 â”‚
â”‚  Avg (Average): 683ms                                           â”‚
â”‚  â”œâ”€ Sum of all times / count                                    â”‚
â”‚  â”œâ”€ MISLEADING: pulled up by a few very slow requests           â”‚
â”‚  â””â”€ Does not represent any typical user experience              â”‚
â”‚                                                                 â”‚
â”‚  Med (Median / p50): 520ms                                      â”‚
â”‚  â”œâ”€ The MIDDLE value: 50% of requests were faster than this     â”‚
â”‚  â”œâ”€ "The typical user experience"                               â”‚
â”‚  â””â”€ More useful than average for skewed distributions           â”‚
â”‚                                                                 â”‚
â”‚  p95: 1800ms                                                    â”‚
â”‚  â”œâ”€ 95% of requests were faster than this                       â”‚
â”‚  â”œâ”€ "The bad experience that 1 in 20 users has"                 â”‚
â”‚  â””â”€ This is the SLA target most teams use                       â”‚
â”‚                                                                 â”‚
â”‚  p99: 3200ms                                                    â”‚
â”‚  â”œâ”€ 99% of requests were faster than this                       â”‚
â”‚  â”œâ”€ "The worst experience except true outliers"                 â”‚
â”‚  â””â”€ At 10,000 requests/day, 100 users hit this. That matters.  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why averages lie â€” visually:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  Imagine 100 requests:                                          â”‚
â”‚                                                                 â”‚
â”‚   Fast â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Slow      â”‚
â”‚                                                                 â”‚
â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–“â–“â–“â–ˆâ–ˆ            â”‚
â”‚   â–²                                      â–²    â–²   â–²            â”‚
â”‚   Most requests                          p50  p95 p99          â”‚
â”‚   clustered here                                               â”‚
â”‚   (40-80ms)                              â”‚    â”‚   â”‚            â”‚
â”‚                                         52ms 380 820ms         â”‚
â”‚                                                                 â”‚
â”‚   Average: 145ms â† WHERE IS THIS? It's in the GAP              â”‚
â”‚   between the cluster and the tail. NOBODY is at 145ms.         â”‚
â”‚                                                                 â”‚
â”‚   The average is a number that describes NO ACTUAL USER.        â”‚
â”‚   The median (p50) describes the TYPICAL user.                  â”‚
â”‚   The p95 describes the UNLUCKY user (but not rare).            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**How to read the Locust results from our example:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           DIAGNOSING FROM LOCUST RESULTS                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  /orgs/{id}/dashboard:  p50=520ms, p95=1800ms, p99=3200ms      â”‚
â”‚  â””â”€ ğŸ”´ PROBLEM: p95 is 1.8 seconds. 1 in 20 users waits >1.8s â”‚
â”‚     p99 at 3.2s means some users are having a terrible time.    â”‚
â”‚     The gap between p50 (520ms) and p95 (1800ms) suggests       â”‚
â”‚     the endpoint degrades badly under contention.               â”‚
â”‚     INVESTIGATE: connection pool exhaustion? Lock contention?   â”‚
â”‚                                                                 â”‚
â”‚  /orgs/{id}/projects/{id}:  p50=102ms, p95=380ms               â”‚
â”‚  â””â”€ ğŸŸ¡ ACCEPTABLE but watch: p95 is 3.7Ã— the median.           â”‚
â”‚     Some variance, probably normal for DB queries.              â”‚
â”‚                                                                 â”‚
â”‚  /tasks/{id}:  p50=45ms, p95=95ms                               â”‚
â”‚  â””â”€ ğŸŸ¢ HEALTHY: low latency, small variance. No action needed. â”‚
â”‚                                                                 â”‚
â”‚  PATCH /tasks/{id}:  8 failures out of 523                      â”‚
â”‚  â””â”€ ğŸ”´ PROBLEM: 1.5% failure rate under load.                  â”‚
â”‚     Writes are failing. Possible causes: lock contention,       â”‚
â”‚     unique constraint violations under concurrency,             â”‚
â”‚     connection pool exhaustion.                                 â”‚
â”‚                                                                 â”‚
â”‚  POST /auth/login:  0 failures, p95=380ms                       â”‚
â”‚  â””â”€ ğŸŸ¢ FINE: Only runs once per user (on_start). Stable.       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Headless mode for CI/automation (no web UI needed):**

```bash
# Run locust without the web UI â€” useful in CI pipelines
locust \
  -f locustfile.py \
  --host=http://localhost:8000 \
  --headless \
  --users 50 \
  --spawn-rate 5 \
  --run-time 2m \
  --csv=results/loadtest

# This produces CSV files:
#   results/loadtest_stats.csv        â€” summary statistics
#   results/loadtest_stats_history.csv â€” time-series data
#   results/loadtest_failures.csv     â€” failed request details
```

**The complete optimization cycle (putting it all together):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          THE COMPLETE OPTIMIZATION CYCLE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  STEP 1: BASELINE MEASUREMENT                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â”‚
â”‚  Run Locust with your current code. Record the numbers.         â”‚
â”‚  This is your "before."                                         â”‚
â”‚                                                                 â”‚
â”‚  Example: /dashboard p95=1800ms, 12 failures, 92 queries/req    â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  STEP 2: IDENTIFY BOTTLENECK                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â”‚
â”‚  Use timing middleware â†’ find slow endpoints                    â”‚
â”‚  Use query profiling  â†’ find N+1 and slow queries               â”‚
â”‚  Use Server-Timing    â†’ find which layer is expensive           â”‚
â”‚                                                                 â”‚
â”‚  Finding: 92 queries per request. N+1 on tasks â†’ assignees.     â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  STEP 3: TARGETED FIX                                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                           â”‚
â”‚  Apply ONE optimization. Not five at once.                      â”‚
â”‚  If you change five things and it improves, you don't know      â”‚
â”‚  WHICH change helped. One change at a time.                     â”‚
â”‚                                                                 â”‚
â”‚  Fix: Added selectinload(Task.assignee). 92 queries â†’ 3.        â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  STEP 4: MEASURE AGAIN                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚
â”‚  Run Locust with IDENTICAL configuration.                       â”‚
â”‚  Compare before/after.                                          â”‚
â”‚                                                                 â”‚
â”‚  Result: /dashboard p95=480ms (was 1800ms), 0 failures          â”‚
â”‚  Improvement: 73% reduction in p95 latency, failures eliminated â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  STEP 5: DOCUMENT                                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                               â”‚
â”‚  Write it down. Your Week 12 project requires this.             â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ OPTIMIZATION #1: Fix N+1 in dashboard endpoint      â”‚        â”‚
â”‚  â”‚                                                     â”‚        â”‚
â”‚  â”‚ Problem: 92 DB queries per request due to N+1       â”‚        â”‚
â”‚  â”‚ Fix: selectinload(Project.tasks.assignee)           â”‚        â”‚
â”‚  â”‚ Before: p95=1800ms, 12 failures/892 requests        â”‚        â”‚
â”‚  â”‚ After:  p95=480ms,   0 failures/940 requests        â”‚        â”‚
â”‚  â”‚ Impact: 73% p95 reduction, 100% failure elimination â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  STEP 6: IS IT GOOD ENOUGH?                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚  Compare against your target (e.g., p95 < 200ms).              â”‚
â”‚  If not â†’ go back to Step 2. There's a new bottleneck now.     â”‚
â”‚  If yes â†’ move on. Don't over-optimize.                         â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Quick Reference Card

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PERFORMANCE QUICK REFERENCE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  GOLDEN RULE:                                                   â”‚
â”‚      Never optimize without measuring first.                    â”‚
â”‚      Never claim an improvement without before/after numbers.   â”‚
â”‚                                                                 â”‚
â”‚  TIMING MIDDLEWARE:                                              â”‚
â”‚      @app.middleware("http")                                    â”‚
â”‚      â†’ time.perf_counter() before and after call_next()         â”‚
â”‚      â†’ Log duration_ms, query_count with structlog              â”‚
â”‚      â†’ Add Server-Timing header for browser visibility          â”‚
â”‚                                                                 â”‚
â”‚  DATABASE PROFILING:                                            â”‚
â”‚      @event.listens_for(engine, "before_cursor_execute")        â”‚
â”‚      @event.listens_for(engine, "after_cursor_execute")         â”‚
â”‚      â†’ ContextVar[QueryStats] for per-request counting          â”‚
â”‚      â†’ Warn when query_count > 10                               â”‚
â”‚      â†’ Assert query budgets in tests                            â”‚
â”‚                                                                 â”‚
â”‚  RESPONSE OPTIMIZATION:                                         â”‚
â”‚      app.add_middleware(GzipMiddleware, minimum_size=500)        â”‚
â”‚      asyncio.gather(call_a(), call_b()) for parallel I/O        â”‚
â”‚                                                                 â”‚
â”‚  LOAD TESTING:                                                  â”‚
â”‚      locust -f locustfile.py --host=http://localhost:8000       â”‚
â”‚      â†’ HttpUser, @task(weight), wait_time=between(a, b)         â”‚
â”‚      â†’ Read p50, p95, p99 â€” NOT averages                        â”‚
â”‚      â†’ Use --headless --csv for CI automation                   â”‚
â”‚                                                                 â”‚
â”‚  PERCENTILES:                                                   â”‚
â”‚      p50 (median) = typical user experience                     â”‚
â”‚      p95 = worst experience for 1 in 20 users (SLA target)     â”‚
â”‚      p99 = worst experience for 1 in 100 users (tail latency)  â”‚
â”‚                                                                 â”‚
â”‚  THE CYCLE:                                                     â”‚
â”‚      MEASURE â†’ IDENTIFY â†’ FIX (one thing) â†’ MEASURE AGAIN      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Summary: The Key Mental Model

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  PERFORMANCE = DIAGNOSIS, NOT GUESSING                          â”‚
â”‚                                                                 â”‚
â”‚  You are a doctor, not a fortune teller.                        â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚  Symptom  â”‚â”€â”€â”€â”€â–¶â”‚ Diagnosticâ”‚â”€â”€â”€â”€â–¶â”‚ Targeted  â”‚              â”‚
â”‚  â”‚  "Slow"   â”‚     â”‚  Tools    â”‚     â”‚    Fix    â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚       â”‚                 â”‚                  â”‚                     â”‚
â”‚       â”‚            â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”             â”‚                     â”‚
â”‚       â”‚            â”‚ Timing  â”‚             â”‚                     â”‚
â”‚       â”‚            â”‚ Query   â”‚             â”‚                     â”‚
â”‚       â”‚            â”‚ Locust  â”‚             â”‚                     â”‚
â”‚       â”‚            â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜             â”‚                     â”‚
â”‚       â”‚                 â”‚                  â”‚                     â”‚
â”‚       â”‚                 â–¼                  â”‚                     â”‚
â”‚       â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚                     â”‚
â”‚       â”‚          â”‚  Measure    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚       â”‚          â”‚  AGAIN      â”‚                                â”‚
â”‚       â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚       â”‚                 â”‚                                       â”‚
â”‚       â”‚                 â–¼                                       â”‚
â”‚       â”‚          Did it work?                                   â”‚
â”‚       â”‚          YES â†’ document, move on                        â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€ NO  â†’ new bottleneck, go around again          â”‚
â”‚                                                                 â”‚
â”‚                                                                 â”‚
â”‚  THREE TOOLS YOU BUILT TODAY:                                   â”‚
â”‚  â”œâ”€ Timing middleware     â†’ "taking the patient's temperature"  â”‚
â”‚  â”œâ”€ Query profiling       â†’ "running blood work"                â”‚
â”‚  â””â”€ Locust load testing   â†’ "stress test on the treadmill"     â”‚
â”‚                                                                 â”‚
â”‚  ONE RULE TO REMEMBER:                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                                                         â”‚    â”‚
â”‚  â”‚         MEASURE, DON'T GUESS.                           â”‚    â”‚
â”‚  â”‚                                                         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Connection to Upcoming Lectures and Projects

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WHERE THIS LEADS                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  WEEK 12 LECTURE 4 (next):                                      â”‚
â”‚  â””â”€ Rate limiting with slowapi                                  â”‚
â”‚     Uses timing middleware to understand request patterns.      â”‚
â”‚     Uses p95/p99 to set rate limit thresholds.                  â”‚
â”‚     Adds performance regression tests to your CI pipeline.      â”‚
â”‚                                                                 â”‚
â”‚  WEEK 12 PROJECT:                                               â”‚
â”‚  â””â”€ "At least 3 documented optimizations with                   â”‚
â”‚      before/after metrics. Load test report."                   â”‚
â”‚     You now have every tool to produce this deliverable.        â”‚
â”‚     Use the optimization cycle from Part 5 for each one.        â”‚
â”‚                                                                 â”‚
â”‚  WEEK 13-14 CAPSTONE:                                           â”‚
â”‚  â””â”€ "Load tested with documented results"                       â”‚
â”‚     Apply these tools from day one of the capstone.             â”‚
â”‚     Build with the timing middleware already in place.           â”‚
â”‚     Write query count tests as you write endpoints.             â”‚
â”‚                                                                 â”‚
â”‚  WEEK 15 (CI/CD):                                               â”‚
â”‚  â””â”€ Locust headless mode in your CI pipeline                    â”‚
â”‚     Automatically catch performance regressions                 â”‚
â”‚     before they reach production.                               â”‚
â”‚                                                                 â”‚
â”‚  WEEK 16 (System Design):                                       â”‚
â”‚  â””â”€ Understanding bottlenecks informs scaling decisions.        â”‚
â”‚     "Should we add a cache or a read replica?"                  â”‚
â”‚     The answer depends on WHERE the bottleneck is â€”             â”‚
â”‚     and now you know how to find out.                           â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```